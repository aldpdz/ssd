{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from models.keras_ssd300 import ssd_300\n",
    "# from models.keras_ssd300_vgg_13_bn import ssd_300\n",
    "# from models.keras_ssd300_mobilenetv1_imagenet import ssd_300\n",
    "# from models.keras_ssd300_mobilenetv1_imagenet import ssd_300\n",
    "# from models.keras_ssdlite320_mobilenetv1 import ssd_300\n",
    "# from models.keras_ssdlite320_mobilenetv2 import ssd_300\n",
    "# from models.keras_ssdlite320_mobilenetv2_conv13_17 import ssd_300\n",
    "from models.keras_ssdlite320PPN_mobilenetv2 import ssd_300\n",
    "\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/vgg_16_2'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/vgg_16_20'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/vgg_16_20'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/mobilenetv1'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1'\n",
    "# path_models = '/home/aldo/Documents/data-cic/tflite_models/13_17'\n",
    "path_models = '/home/aldo/Documents/data-cic/tflite_models/PPN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, height, width):\n",
    "    # 1: Build the Keras model\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "#     scales = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # pascal\n",
    "#     scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # coco\n",
    "    scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05] # mobilenet\n",
    "\n",
    "#     scales = [0.2, 0.61, 1.05]\n",
    "\n",
    "    \n",
    "#     swap_channels = [2, 1, 0]\n",
    "    swap_channels = False\n",
    "#     mean = [123, 117, 104]\n",
    "#     mean = [127, 127, 127]\n",
    "    mean = [1., 1., 1.]\n",
    "    divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "#     divide_by_stddev = None\n",
    "    \n",
    "#     steps = [8, 16, 32, 64, 100, 300]\n",
    "    steps = [16, 30, 60, 100, 150, 300]\n",
    "#     steps = [16, 32, 64, 107, 160, 320]\n",
    "#     steps = [16, 32]\n",
    "#     classes = 20\n",
    "    classes = 1\n",
    "    \n",
    "    if height == 300 or height == 320:\n",
    "        model = ssd_300(image_size=(height, width, 3),\n",
    "                        n_classes=classes,\n",
    "                        alpha = 1.0,\n",
    "                        expansion = 1, \n",
    "                        mode='inference',\n",
    "#                         l2_regularization=0.0005,\n",
    "                        scales=scales,\n",
    "#                         aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "#                                                  [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "#                                                  [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "#                                                  [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "#                                                  [1.0, 2.0, 0.5],\n",
    "#                                                  [1.0, 2.0, 0.5]],\n",
    "                        aspect_ratios_per_layer=[[1.0, 0.5, 2.0/3.0],\n",
    "                                                 [1.0, 0.5, 2.0/3.0, 1.0/3.0, 3.0/4.0],\n",
    "                                                 [1.0, 0.5, 2.0/3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 2.0/3.0, 1.0/3.0]],\n",
    "                        two_boxes_for_ar1=True,\n",
    "                        steps=steps,\n",
    "                        offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "#                         offsets=[0.5, 0.5],\n",
    "                        clip_boxes=False,\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        normalize_coords=True,\n",
    "                        subtract_mean=mean,\n",
    "                        swap_channels=False, # set to false otherwise funtion not implemented\n",
    "                        confidence_thresh=0.15,\n",
    "                        iou_threshold=0.45,\n",
    "                        top_k=200,\n",
    "                        nms_max_output_size=400,\n",
    "                        divide_by_stddev=divide_by_stddev)\n",
    "    elif height == 512:\n",
    "        model = ssd_512(image_size=(height, width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=False,\n",
    "               confidence_thresh=0.15,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "    # 2: Load the trained weights into the model.\n",
    "    # TODO: Set the path of the trained weights.\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    '''\n",
    "    Load a frozen graph\n",
    "    frozen_grapth_filename: path in the disk\n",
    "    return: tensorflow graph\n",
    "    '''\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph\n",
    "\n",
    "def save_graph(name):\n",
    "    '''\n",
    "    Save grapth to load with tensorboard\n",
    "    '''\n",
    "    graph = load_graph(name)\n",
    "\n",
    "    # save data from a grapth to display on tensorboard\n",
    "    # tensorboard --logdir=wholepath\n",
    "    # the path has to be absolute\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.summary.FileWriter('../logs_ssd', sess.graph)\n",
    "\n",
    "def show_operations_graph(graph):\n",
    "    '''\n",
    "    Print operations contained in a graph\n",
    "    '''\n",
    "    for op in graph.get_operations():\n",
    "        print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and weights\n",
    "# model_path = '../weights/pascal_voc/pascal_voc_07_12_coco_300x300.h5'\n",
    "# model_path = '../weights/models/ssd300_sgd/ssd300_fine_tunning_epoch-89_loss-2.6171_val_loss-3.0580.h5'\n",
    "# model_path = '../weights/models/ssd300_adam_vgg16/ssd300_pascal_cic.h5'\n",
    "# model_path = '../weights/models/ssd300_adam_vgg13_bn/ssd300_vgg_13_bn_pascal_cic.h5'\n",
    "# model_path = '../weights/models/ssd_mobilenetv1/ssd300_mobilenetv1_imagenet_cic.h5'\n",
    "# model_path = '../weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5'\n",
    "\n",
    "# model_path = '../weights/models/tradeoff/ssdlite320_mobilenetv2_pascal_cic_0.35_exp_1.h5'\n",
    "# model_path = '../weights/models/tradeoff/ssdlite320_mobilenetv2_pascal_cic_f1_0.35_exp_1.h5'\n",
    "model_path = '../weights/models/new_net/new_share_conv_conf_cic.h5'\n",
    "\n",
    "model = load_model(model_path, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aldo/Documents/data-cic/tflite_models/PPN/ssd_model.pb'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models as .pbtxt or pb\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pbtxt\", as_text=True)\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph(path_models + '/ssd_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "sess = keras.backend.get_session()\n",
    "save_path = saver.save(sess, path_models + \"/ssd_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the Graph\n",
    "In order to convert the graph to tflite we need to freeze it, in this case we'll use the tools provided by tensorflow to do so.\n",
    "\n",
    "We need to specify the graph, the checkpoints, the output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aldo/Documents/data-cic/tflite_models/PPN/ssd_model.ckpt\n",
      "INFO:tensorflow:Froze 282 variables.\n",
      "INFO:tensorflow:Converted 282 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "input_graph_path = path_models + '/ssd_model.pb'\n",
    "checkpoint_path = path_models + '/ssd_model.ckpt'\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = True\n",
    "output_node_names = \"decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_frozen_graph_name = path_models + '/ssd_frozen_model.pb'\n",
    "clear_devices = True\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          output_frozen_graph_name, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for inference\n",
    "\n",
    "Optimize for inference will help us to remove those parts of the graph that were used during training.\n",
    "\n",
    "We need the input and output names and the frozen model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# compile graph_transforms once\n",
    "# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/\n",
    "bazel build tensorflow/tools/graph_transforms:transform_graph\n",
    "!touch WORKSPACE # bazel needs it to work\n",
    "    \n",
    "bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n",
    "--in_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_frozen_model.pb \\\n",
    "--out_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_trans_model.pb \\\n",
    "--inputs='input_1' \\\n",
    "--outputs='predictions/concat' \\\n",
    "--transforms='\n",
    "  strip_unused_nodes(type=float, shape=\"1,512,512,3\")\n",
    "  remove_nodes(op=Identity, op=CheckNumerics)\n",
    "  fold_constants(ignore_errors=true)\n",
    "  fold_batch_norms\n",
    "  fold_old_batch_norms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input graph file './extra_files/models/ssd_frozen_model.pb' does not exist!\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "--input=./extra_files/models/ssd_frozen_model.pb \\\n",
    "--output=./extra_files/models/ssd_opt_model.pb \\\n",
    "--frozen_graph=True --input_names=input_1 \\\n",
    "--output_names=predictions/concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (32,), for node model_1/bn_Conv1/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/bn_Conv1/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/expanded_conv_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/expanded_conv_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (16,), for node model_1/expanded_conv_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/expanded_conv_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (96,), for node model_1/block_1_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_1_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_1_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_1_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (24,), for node model_1/block_1_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_1_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (144,), for node model_1/block_2_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_2_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_2_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_2_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (24,), for node model_1/block_2_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_2_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (144,), for node model_1/block_3_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_3_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_3_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_3_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (32,), for node model_1/block_3_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_3_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (192,), for node model_1/block_4_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_4_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_4_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_4_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (32,), for node model_1/block_4_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_4_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (192,), for node model_1/block_5_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_5_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_5_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_5_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (32,), for node model_1/block_5_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_5_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (192,), for node model_1/block_6_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_6_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_6_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_6_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (64,), for node model_1/block_6_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_6_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (384,), for node model_1/block_7_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_7_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_7_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_7_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (64,), for node model_1/block_7_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_7_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (384,), for node model_1/block_8_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_8_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_8_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_8_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (64,), for node model_1/block_8_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_8_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (384,), for node model_1/block_9_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_9_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_9_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_9_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (64,), for node model_1/block_9_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_9_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (384,), for node model_1/block_10_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_10_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_10_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_10_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (96,), for node model_1/block_10_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_10_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (576,), for node model_1/block_11_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_11_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_11_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_11_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (96,), for node model_1/block_11_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_11_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (576,), for node model_1/block_12_expand_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_12_expand_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_12_depthwise_BN/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_12_depthwise_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (96,), for node model_1/block_12_project_BN/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'model_1/block_12_project_BN/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (96,), for node bn13_conv_bn_expand/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn13_conv_bn_expand/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn13_conv_depthwise/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn13_conv_depthwise/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn13_conv_bn_project/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn13_conv_bn_project/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn14_conv_bn_expand/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn14_conv_bn_expand/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn14_conv_depthwise/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn14_conv_depthwise/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn14_conv_bn_project/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn14_conv_bn_project/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn15_conv_bn_expand/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn15_conv_bn_expand/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn15_conv_depthwise/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn15_conv_depthwise/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn15_conv_bn_project/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn15_conv_bn_project/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (160,), for node bn16_conv_bn_expand/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn16_conv_bn_expand/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn16_conv_depthwise/FusedBatchNorm'\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn16_conv_depthwise/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (320,), for node bn16_conv_bn_project/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn16_conv_bn_project/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (1280,), for node Conv_1_bn_1/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'Conv_1_bn_1/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (256,), for node bn_features/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn_features/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (512,), for node bn_tower/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn_tower/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (512,), for node bn_tower_1/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn_tower_1/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (512,), for node bn_tower_2/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn_tower_2/cond/FusedBatchNorm'\n",
      "WARNING:tensorflow:Incorrect shape for mean, found (0,), expected (512,), for node bn_tower_3/FusedBatchNorm\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'bn_tower_3/cond/FusedBatchNorm'\n"
     ]
    }
   ],
   "source": [
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/vgg_16_20/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/vgg_16_20/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/vgg_16_2/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/vgg_16_2/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/mobilenetv1/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/mobilenetv1/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv2/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv2/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/13_17/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/13_17/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "# !python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "# --input=/home/aldo/Documents/data-cic/tflite_models/trade-off/ssd_frozen_model.pb \\\n",
    "# --output=/home/aldo/Documents/data-cic/tflite_models/trade-off/ssd_opt_model.pb \\\n",
    "# --frozen_graph=True --input_names=input_1 \\\n",
    "# --output_names=predictions/concat\n",
    "\n",
    "!python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "--input=/home/aldo/Documents/data-cic/tflite_models/PPN/ssd_frozen_model.pb \\\n",
    "--output=/home/aldo/Documents/data-cic/tflite_models/PPN/ssd_opt_model.pb \\\n",
    "--frozen_graph=True --input_names=input_1 \\\n",
    "--output_names=predictions/concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite model\n",
    "Finally we conver the model to tflite format, we need a frozen model in the same way the input and output name are required, and all the operations in the model need to be conpatible with tflite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_file = \"/home/aldopedraza/Documentos/models/ssd_frozen_model.pb\"\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = [\"decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3\"]\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays, input_shapes={\"input_1\" : [1, 300, 300, 3]})\n",
    "tflite_model = converter.convert()\n",
    "open(\"/home/aldopedraza/Documentos/models/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### THIS WORKS\n",
    "tflite_convert --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,512,512,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-06 18:38:53.679403: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-03-06 18:38:53.791560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-06 18:38:53.792072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 7.92GiB freeMemory: 6.95GiB\n",
      "2019-03-06 18:38:53.792088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2019-03-06 18:38:53.981024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-06 18:38:53.981061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2019-03-06 18:38:53.981070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2019-03-06 18:38:53.981219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6702 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aldo/anaconda3/envs/test2/bin/toco\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 401, in main\n",
      "    app.run(main=run_main, argv=sys.argv[:1])\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 397, in run_main\n",
      "    _convert_model(tflite_flags)\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 159, in _convert_model\n",
      "    output_data = converter.convert()\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 439, in convert\n",
      "    **converter_kwargs)\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 309, in toco_convert_impl\n",
      "    input_data.SerializeToString())\n",
      "  File \"/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 109, in toco_convert_protos\n",
      "    (stdout, stderr))\n",
      "RuntimeError: TOCO failed see console for info.\n",
      "b\"2019-03-06 18:38:56.911986: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1275 operators, 2395 arrays (0 quantized)\\n2019-03-06 18:38:56.951715: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1275 operators, 2395 arrays (0 quantized)\\n2019-03-06 18:38:57.010664: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 237 operators, 535 arrays (1 quantized)\\n2019-03-06 18:38:57.014773: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.016380: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.017305: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.018566: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before default min-max range propagation graph transformations: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.019580: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After default min-max range propagation graph transformations pass 1: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.020801: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 121 operators, 303 arrays (1 quantized)\\n2019-03-06 18:38:57.020828: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array Conv1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020858: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array expanded_conv_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020881: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array expanded_conv_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020902: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_1_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020933: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_1_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020957: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_1_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.020983: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_2_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021011: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_2_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021038: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_2_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021070: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_3_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021102: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_3_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021128: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_3_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021157: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_4_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021200: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_4_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021229: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_4_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021270: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_5_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021306: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_5_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021335: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_5_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021376: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_6_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021416: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_6_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021445: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_6_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021485: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_7_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021539: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_7_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021571: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_7_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021629: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_8_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021683: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_8_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021715: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_8_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021773: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_9_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021828: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_9_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021860: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_9_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021917: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_10_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.021970: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_10_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022003: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_10_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022064: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_11_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022145: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_11_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022182: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_11_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022322: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_12_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022405: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_12_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022442: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array block_12_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022525: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl13_conv_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022564: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array bn13_conv_bn_expand/cond/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022583: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array bn13_conv_bn_expand/cond/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022602: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl13_conv_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022629: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl13_conv_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022682: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl14_conv_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022763: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl14_conv_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022793: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl14_conv_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022877: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl15_conv_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022958: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl15_conv_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.022988: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl15_conv_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.023072: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl16_conv_expand/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.023148: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl16_conv_depthwise/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.023178: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array mobl16_conv_project/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.023313: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array Conv_1_1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.024604: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array Conv_1_bn_1/cond/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.024638: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array Conv_1_bn_1/cond/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.024666: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 18_pwconv1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.025690: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 18_dwconv2/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.025719: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 18_pwconv3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.025880: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 18_pwconv3_bn/cond/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.025901: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 18_pwconv3_bn/cond/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.025920: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 19_pwconv1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026010: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 19_dwconv2/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026033: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 19_pwconv3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026088: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 19_pwconv3_bn/cond/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026108: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 19_pwconv3_bn/cond/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026130: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 20_pwconv1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026185: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 20_dwconv2/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026225: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 20_pwconv3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026374: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 20_pwconv3_bn/cond/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026396: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 20_pwconv3_bn/cond/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026419: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 21_pwconv1/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026456: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 21_dwconv2/depthwise_kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026480: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array 21_pwconv3/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026512: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv13_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.026577: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv17_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.027884: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv18_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.028088: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv19_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.028216: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv20_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.028392: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv21_2_mbox_conf/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.028531: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv13_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.028643: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv17_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.031941: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv18_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.032467: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv19_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.032746: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv20_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.032950: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:100] Constant array conv21_2_mbox_loc/kernel lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\\n2019-03-06 18:38:57.033490: F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:474] Unimplemented: this graph contains an operator of type Div for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).\\nAborted (core dumped)\\n\"\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !toco \\\n",
    "#   --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb \\\n",
    "#   --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite \\\n",
    "#   --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n",
    "#   --inference_type=QUANTIZED_UINT8 \\\n",
    "#   --input_shape=\"1,512,512,3\" \\\n",
    "#   --input_array=input_1 \\\n",
    "#   --output_array=predictions/concat \\\n",
    "#   --std_dev_values=127.5 --mean_value=127.5\n",
    "\n",
    "!toco \\\n",
    "--output_file=/home/aldopedraza/Downloads/tflite_model.tflite \\\n",
    "--graph_def_file=/home/aldo/Downloads/prueba/ssd_opt_model.pb \\\n",
    "--output_format=TFLITE \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--inference_input_type=QUANTIZED_UINT8 \\\n",
    "--input_arrays=input_1 \\\n",
    "--output_arrays=predictions/concat \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--mean_values=128 \\\n",
    "--std_dev_values=128 \\\n",
    "--default_ranges_min=0 \\\n",
    "--default_ranges_max=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-22 13:29:16.409932: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-03-22 13:29:16.509713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-03-22 13:29:16.510118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 7.92GiB freeMemory: 7.00GiB\n",
      "2019-03-22 13:29:16.510141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2019-03-22 13:29:16.693400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-03-22 13:29:16.693439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2019-03-22 13:29:16.693454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2019-03-22 13:29:16.693651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6749 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "### THIS WORKS\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/vgg_16_20/tflite_vgg16_20.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/vgg_16_20/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,300,300,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/vgg_16_2/tflite_vgg16_2.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/vgg_16_2/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,300,300,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/tflite_vgg13_bn.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,300,300,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/mobilenetv1/tflite_mobilenetv1.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/mobilenetv1/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,300,300,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1/ssdlitemnetv1.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,320,320,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv2/ssdlitemnetv2.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv2/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,320,320,3\n",
    "# !tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/13_17/conv13_17.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/13_17/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,320,320,3\n",
    "\n",
    "# !tflite_convert \\\n",
    "# --output_file=/home/aldo/Documents/data-cic/tflite_models/trade-off/tflite_files/alpha_35_exp_1_f1.tflite \\\n",
    "# --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/trade-off/ssd_opt_model.pb \\\n",
    "# --input_arrays=input_1 \\\n",
    "# --output_arrays=predictions/concat \\\n",
    "# --input_shapes=1,320,320,3\n",
    "\n",
    "!tflite_convert \\\n",
    "--output_file=/home/aldo/Documents/data-cic/tflite_models/PPN/PPN_alpha_1_exp_1_f1.tflite \\\n",
    "--graph_def_file=/home/aldo/Documents/data-cic/tflite_models/PPN/ssd_opt_model.pb \\\n",
    "--input_arrays=input_1 \\\n",
    "--output_arrays=predictions/concat \\\n",
    "--input_shapes=1,300,300,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model to see if it's compatible with tflite\n",
    "\n",
    "In order to be sure that the model works correctly what we can do it's to use the interpreter to load the model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n",
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.98484194e-01  1.51586067e-03  1.39730918e+00  8.92679989e-01\n",
      "  -4.07404137e+00 -5.81618249e-01  9.33333337e-01  3.46666664e-01\n",
      "   1.50000006e-01  1.50000006e-01  1.00000001e-01  1.00000001e-01\n",
      "   2.00000003e-01  2.00000003e-01]\n",
      " [ 9.98233438e-01  1.76650845e-03  1.70205861e-01  3.97505909e-02\n",
      "  -1.91881573e+00  1.40886414e+00  9.33333337e-01  3.46666664e-01\n",
      "   2.22485960e-01  2.22485960e-01  1.00000001e-01  1.00000001e-01\n",
      "   2.00000003e-01  2.00000003e-01]\n",
      " [ 9.97911990e-01  2.08804966e-03  3.00758898e-01  4.28533614e-01\n",
      "   7.22486794e-01  1.19467163e+00  9.33333337e-01  3.46666664e-01\n",
      "   1.06066018e-01  2.12132037e-01  1.00000001e-01  1.00000001e-01\n",
      "   2.00000003e-01  2.00000003e-01]\n",
      " [ 9.97967303e-01  2.03263457e-03  1.13933110e+00  1.12009835e+00\n",
      "  -1.39048755e+00  1.22335780e+00  9.33333337e-01  3.46666664e-01\n",
      "   1.22474484e-01  1.83711737e-01  1.00000001e-01  1.00000001e-01\n",
      "   2.00000003e-01  2.00000003e-01]\n",
      " [ 9.98313308e-01  1.68675557e-03 -8.49301666e-02 -1.06040180e+00\n",
      "   1.33137360e-01  5.92550337e-01  2.66666673e-02  4.00000006e-01\n",
      "   1.50000006e-01  1.50000006e-01  1.00000001e-01  1.00000001e-01\n",
      "   2.00000003e-01  2.00000003e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "# Read image\n",
    "image_test = misc.imread('./image_test.jpg')\n",
    "image_test = misc.imresize(image_test, size=(300, 300))\n",
    "misc.imsave('./resize_image.jpg', image_test)\n",
    "image_test = image_test.reshape(1, 300, 300, 3)\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/vgg_16_20/tflite_vgg16_20.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/vgg_16_2/tflite_vgg16_2.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/tflite_vgg13_bn.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/mobilenetv1/tflite_mobilenetv1.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv1/ssdlitemnetv1.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/ssdlitemnetv2/ssdlitemnetv2.tflite')\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/13_17/conv13_17.tflite')\n",
    "\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/trade-off/tflite_files/alpha_35_exp_1_f1.tflite')\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/PPN/PPN_alpha_1_exp_1_f1.tflite')\n",
    "\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "# input_shape = input_details[0]['shape']\n",
    "input_data = np.array(image_test, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data[0][500:505])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
