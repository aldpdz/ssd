{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSD300 trained with mobilenet backbone trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300_mobilenetv1 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales_coco = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05] # The anchor box scaling factors used in the original SSD300 for the MS COCO datasets\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = scales_pascal\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                alpha=1.0,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "\n",
    "# TODO: Set the path to the weights you want to load.\n",
    "weights_path = '/home/aldo/Documents/weights/classifiers/mobilnetv1_alpha_0.75.h5'\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             1363648     input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv__11 (Conv2D)               (None, 18, 18, 512)  262144      model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_bn (BatchNormalization) (None, 18, 18, 512)  2048        conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_relu (Activation)       (None, 18, 18, 512)  0           conv_11_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)     (None, 20, 20, 512)  0           conv_11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D)    (None, 9, 9, 512)    4608        conv_pad_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormalizati (None, 9, 9, 512)    2048        conv_dw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_relu (Activation)    (None, 9, 9, 512)    0           conv_dw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12 (Conv2D)             (None, 9, 9, 1024)   524288      conv_dw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormalizati (None, 9, 9, 1024)   4096        conv_pw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_relu (Activation)    (None, 9, 9, 1024)   0           conv_pw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)     (None, 11, 11, 1024) 0           conv_pw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D)    (None, 9, 9, 1024)   9216        conv_pad_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormalizati (None, 9, 9, 1024)   4096        conv_dw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 9, 9, 1024)   0           conv_dw_13_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv__13 (Conv2D)               (None, 9, 9, 1024)   1048576     conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_bn (BatchNormalization) (None, 9, 9, 1024)   4096        conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 9, 9, 1024)   0           conv_13_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_14_1 (ZeroPadding2D)   (None, 11, 11, 1024) 0           conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__14_1 (Conv2D)             (None, 11, 11, 256)  262144      conv_pad_14_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_bn_1 (BatchNormalizatio (None, 11, 11, 256)  1024        conv__14_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu_1 (Activation)     (None, 11, 11, 256)  0           conv_14_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__14_2 (Conv2D)             (None, 5, 5, 512)    1179648     conv_14_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_bn_2 (BatchNormalizatio (None, 5, 5, 512)    2048        conv__14_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu_2 (Activation)     (None, 5, 5, 512)    0           conv_14_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_15_1 (ZeroPadding2D)   (None, 7, 7, 512)    0           conv_14_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__15_1 (Conv2D)             (None, 7, 7, 128)    65536       conv_pad_15_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_bn_1 (BatchNormalizatio (None, 7, 7, 128)    512         conv__15_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu_1 (Activation)     (None, 7, 7, 128)    0           conv_15_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__15_2 (Conv2D)             (None, 3, 3, 256)    294912      conv_15_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_bn_2 (BatchNormalizatio (None, 3, 3, 256)    1024        conv__15_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu_2 (Activation)     (None, 3, 3, 256)    0           conv_15_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_16_1 (ZeroPadding2D)   (None, 5, 5, 256)    0           conv_15_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__16_1 (Conv2D)             (None, 5, 5, 128)    32768       conv_pad_16_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_bn_1 (BatchNormalizatio (None, 5, 5, 128)    512         conv__16_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu_1 (Activation)     (None, 5, 5, 128)    0           conv_16_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__16_2 (Conv2D)             (None, 2, 2, 256)    294912      conv_16_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_bn_2 (BatchNormalizatio (None, 2, 2, 256)    1024        conv__16_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu_2 (Activation)     (None, 2, 2, 256)    0           conv_16_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_17_1 (ZeroPadding2D)   (None, 4, 4, 256)    0           conv_16_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__17_1 (Conv2D)             (None, 4, 4, 64)     16384       conv_pad_17_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_17_bn_1 (BatchNormalizatio (None, 4, 4, 64)     256         conv__17_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_17_relu_1 (Activation)     (None, 4, 4, 64)     0           conv_17_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__17_2 (Conv2D)             (None, 1, 1, 128)    73728       conv_17_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf (Conv2D)       (None, 18, 18, 8)    36872       conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 9, 9, 12)     110604      conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf (Conv2D)     (None, 5, 5, 12)     55308       conv__14_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf (Conv2D)     (None, 3, 3, 12)     27660       conv__15_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf (Conv2D)     (None, 2, 2, 8)      18440       conv__16_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf (Conv2D)     (None, 1, 1, 8)      9224        conv__17_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc (Conv2D)        (None, 18, 18, 16)   73744       conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 9, 9, 24)     221208      conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc (Conv2D)      (None, 5, 5, 24)     110616      conv__14_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc (Conv2D)      (None, 3, 3, 24)     55320       conv__15_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc (Conv2D)      (None, 2, 2, 16)     36880       conv__16_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc (Conv2D)      (None, 1, 1, 16)     18448       conv__17_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1296, 2)      0           conv11_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 486, 2)       0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 150, 2)       0           conv14_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 54, 2)        0           conv15_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 16, 2)        0           conv16_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 4, 2)         0           conv17_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_priorbox (AnchorBox (None, 18, 18, 4, 8) 0           conv11_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 9, 9, 6, 8)   0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_priorbox (AnchorB (None, 5, 5, 6, 8)   0           conv14_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_priorbox (AnchorB (None, 3, 3, 6, 8)   0           conv15_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_priorbox (AnchorB (None, 2, 2, 4, 8)   0           conv16_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_priorbox (AnchorB (None, 1, 1, 4, 8)   0           conv17_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 2006, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1296, 4)      0           conv11_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 486, 4)       0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 150, 4)       0           conv14_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 54, 4)        0           conv15_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 16, 4)        0           conv16_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 4, 4)         0           conv17_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_priorbox_reshape (R (None, 1296, 8)      0           conv11_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 486, 8)       0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_priorbox_reshape  (None, 150, 8)       0           conv14_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_priorbox_reshape  (None, 54, 8)        0           conv15_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_priorbox_reshape  (None, 16, 8)        0           conv16_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_priorbox_reshape  (None, 4, 8)         0           conv17_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 2006, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 2006, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 2006, 8)      0           conv11_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv14_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv15_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv16_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv17_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2006, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,229,620\n",
      "Trainable params: 6,204,532\n",
      "Non-trainable params: 25,088\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:09<00:00, 22.45it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 23.38it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "# images_dir = data_path + 'pascal_dataset'\n",
    "images_dir = data_path + 'images'\n",
    "# images_dir = data_path + 'pascal_dataset_coco'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/pascal_coco.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv11_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv14_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv15_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv16_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 100:\n",
    "        return 0.0001\n",
    "    elif epoch < 200:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val.npy')\n",
    "val_images_300 = np.load('../data-cic/preprocess_data/images_val_300x300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "# model_checkpoint.best = 2.567152314715915\n",
    "\n",
    "csv_logger = CSVLogger(filename='/home/aldo/Downloads/ssd300_mobilenet_imagent2_cic.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=8,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.00001)\n",
    "\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_300,\n",
    "                      label_val, \n",
    "                      (1, 2006, 14),\n",
    "                      '/home/aldo/Downloads/ssd300_mobilenet_imagent-coco2_f1_2_cic.csv')\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "#              learning_rate_scheduler]\n",
    "             reduce_learning_rate,\n",
    "             f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "15/15 [==============================] - 83s 6s/step - loss: 3.3798 - val_loss: 2.9475\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.94750, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6374\n",
      "Recall: 0.546\n",
      "F1 score: 0.5882\n",
      "Improve F1 score from -inf to 0.5881648271371442\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 74s 5s/step - loss: 2.9220 - val_loss: 2.7095\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.94750 to 2.70950, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6753\n",
      "Recall: 0.5643\n",
      "F1 score: 0.6148\n",
      "Improve F1 score from 0.5881648271371442 to 0.6148497638256843\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 79s 5s/step - loss: 2.7114 - val_loss: 2.7096\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.70950\n",
      "Number of images: 45\n",
      "Presicion: 0.6483\n",
      "Recall: 0.5485\n",
      "F1 score: 0.5942\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 79s 5s/step - loss: 2.6738 - val_loss: 2.5350\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.70950 to 2.53498, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6344\n",
      "Recall: 0.6041\n",
      "F1 score: 0.6189\n",
      "Improve F1 score from 0.6148497638256843 to 0.6188710073763872\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 77s 5s/step - loss: 2.3925 - val_loss: 2.4869\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.53498 to 2.48692, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6437\n",
      "Recall: 0.5947\n",
      "F1 score: 0.6182\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.5592 - val_loss: 2.5214\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.48692\n",
      "Number of images: 45\n",
      "Presicion: 0.6336\n",
      "Recall: 0.6072\n",
      "F1 score: 0.6201\n",
      "Improve F1 score from 0.6188710073763872 to 0.6200957662436073\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.6638 - val_loss: 2.4676\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.48692 to 2.46762, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6599\n",
      "Recall: 0.5977\n",
      "F1 score: 0.6273\n",
      "Improve F1 score from 0.6200957662436073 to 0.6272585736159343\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 75s 5s/step - loss: 2.3850 - val_loss: 2.4299\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.46762 to 2.42989, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6503\n",
      "Recall: 0.5881\n",
      "F1 score: 0.6177\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 75s 5s/step - loss: 2.1364 - val_loss: 2.4652\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.42989\n",
      "Number of images: 45\n",
      "Presicion: 0.6833\n",
      "Recall: 0.5593\n",
      "F1 score: 0.6152\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.2693 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.42989\n",
      "Number of images: 45\n",
      "Presicion: 0.686\n",
      "Recall: 0.5758\n",
      "F1 score: 0.6261\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 70s 5s/step - loss: 2.2928 - val_loss: 2.3906\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.42989 to 2.39056, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6945\n",
      "Recall: 0.6019\n",
      "F1 score: 0.6449\n",
      "Improve F1 score from 0.6272585736159343 to 0.6449072393387879\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 75s 5s/step - loss: 2.3085 - val_loss: 2.3571\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.39056 to 2.35705, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6924\n",
      "Recall: 0.6083\n",
      "F1 score: 0.6476\n",
      "Improve F1 score from 0.6449072393387879 to 0.6476301854008324\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.2114 - val_loss: 2.3468\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.35705 to 2.34678, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7\n",
      "Recall: 0.5862\n",
      "F1 score: 0.6381\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 75s 5s/step - loss: 2.2530 - val_loss: 2.4531\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.34678\n",
      "Number of images: 45\n",
      "Presicion: 0.6876\n",
      "Recall: 0.6015\n",
      "F1 score: 0.6417\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.2267 - val_loss: 2.3229\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.34678 to 2.32294, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6938\n",
      "Recall: 0.6067\n",
      "F1 score: 0.6473\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 80s 5s/step - loss: 2.1501 - val_loss: 2.3568\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.32294\n",
      "Number of images: 45\n",
      "Presicion: 0.6911\n",
      "Recall: 0.604\n",
      "F1 score: 0.6446\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 81s 5s/step - loss: 2.1570 - val_loss: 2.2993\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.32294 to 2.29928, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7079\n",
      "Recall: 0.5971\n",
      "F1 score: 0.6478\n",
      "Improve F1 score from 0.6476301854008324 to 0.6477960978610937\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 79s 5s/step - loss: 2.2163 - val_loss: 2.2904\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.29928 to 2.29040, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.703\n",
      "Recall: 0.6092\n",
      "F1 score: 0.6528\n",
      "Improve F1 score from 0.6477960978610937 to 0.6527665915983514\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0518 - val_loss: 2.2213\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.29040 to 2.22128, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7018\n",
      "Recall: 0.6213\n",
      "F1 score: 0.6591\n",
      "Improve F1 score from 0.6527665915983514 to 0.659097370200737\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.0840 - val_loss: 2.2409\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.22128\n",
      "Number of images: 45\n",
      "Presicion: 0.7045\n",
      "Recall: 0.612\n",
      "F1 score: 0.655\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.0078 - val_loss: 2.2586\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.22128\n",
      "Number of images: 45\n",
      "Presicion: 0.7086\n",
      "Recall: 0.6111\n",
      "F1 score: 0.6562\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.0639 - val_loss: 2.2328\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.22128\n",
      "Number of images: 45\n",
      "Presicion: 0.7091\n",
      "Recall: 0.6119\n",
      "F1 score: 0.6569\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.0283 - val_loss: 2.2323\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.22128\n",
      "Number of images: 45\n",
      "Presicion: 0.7143\n",
      "Recall: 0.5928\n",
      "F1 score: 0.6479\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1649 - val_loss: 2.1292\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.22128 to 2.12917, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7112\n",
      "Recall: 0.611\n",
      "F1 score: 0.6573\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 1.9561 - val_loss: 2.2040\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.7029\n",
      "Recall: 0.5845\n",
      "F1 score: 0.6383\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 1.9646 - val_loss: 2.2470\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.6924\n",
      "Recall: 0.6177\n",
      "F1 score: 0.6529\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.0155 - val_loss: 2.2187\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.6828\n",
      "Recall: 0.6211\n",
      "F1 score: 0.6505\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0090 - val_loss: 2.1542\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.7052\n",
      "Recall: 0.6198\n",
      "F1 score: 0.6598\n",
      "Improve F1 score from 0.659097370200737 to 0.6597781519625099\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.8727 - val_loss: 2.1924\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.6892\n",
      "Recall: 0.5903\n",
      "F1 score: 0.6359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 1.9691 - val_loss: 2.2277\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.6987\n",
      "Recall: 0.6108\n",
      "F1 score: 0.6518\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 1.9970 - val_loss: 2.2255\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.7042\n",
      "Recall: 0.6014\n",
      "F1 score: 0.6487\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 1.9814 - val_loss: 2.2766\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.12917\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Number of images: 45\n",
      "Presicion: 0.6857\n",
      "Recall: 0.6194\n",
      "F1 score: 0.6509\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.8557 - val_loss: 2.2094\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.7105\n",
      "Recall: 0.5993\n",
      "F1 score: 0.6502\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 1.8369 - val_loss: 2.1871\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.12917\n",
      "Number of images: 45\n",
      "Presicion: 0.6807\n",
      "Recall: 0.6232\n",
      "F1 score: 0.6507\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 15\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "400/400 [==============================] - 285s 714ms/step - loss: 5.7344 - val_loss: 4.3089\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.30886, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.1642\n",
      "Recall: 0.3727\n",
      "F1 score: 0.228\n",
      "Improve F1 score from -inf to 0.22796904630155468\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 275s 689ms/step - loss: 3.8789 - val_loss: 3.5886\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.30886 to 3.58863, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.3585\n",
      "Recall: 0.4205\n",
      "F1 score: 0.387\n",
      "Improve F1 score from 0.22796904630155468 to 0.3870405885130862\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 277s 692ms/step - loss: 3.7142 - val_loss: 3.8271\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.58863\n",
      "Number of images: 45\n",
      "Presicion: 0.2641\n",
      "Recall: 0.3965\n",
      "F1 score: 0.317\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 278s 695ms/step - loss: 3.6260 - val_loss: 3.4252\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.58863 to 3.42521, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.4165\n",
      "Recall: 0.3747\n",
      "F1 score: 0.3945\n",
      "Improve F1 score from 0.3870405885130862 to 0.39448942587857017\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 245s 611ms/step - loss: 3.5299 - val_loss: 3.4547\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.42521\n",
      "Number of images: 45\n",
      "Presicion: 0.4968\n",
      "Recall: 0.3872\n",
      "F1 score: 0.4352\n",
      "Improve F1 score from 0.39448942587857017 to 0.43520091690672263\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 254s 635ms/step - loss: 3.4708 - val_loss: 3.4871\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.42521\n",
      "Number of images: 45\n",
      "Presicion: 0.548\n",
      "Recall: 0.4245\n",
      "F1 score: 0.4784\n",
      "Improve F1 score from 0.43520091690672263 to 0.47844059014850127\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 242s 605ms/step - loss: 3.3693 - val_loss: 3.3781\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.42521 to 3.37805, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.4472\n",
      "Recall: 0.433\n",
      "F1 score: 0.44\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 3.3752 - val_loss: 3.2534\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.37805 to 3.25337, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5022\n",
      "Recall: 0.3854\n",
      "F1 score: 0.4361\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 3.3503 - val_loss: 3.3664\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.416\n",
      "Recall: 0.3692\n",
      "F1 score: 0.3912\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 241s 603ms/step - loss: 11.3891 - val_loss: 7.2941\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.3311\n",
      "Recall: 0.3226\n",
      "F1 score: 0.3268\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 7.6551 - val_loss: 5.5050\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.4818\n",
      "Recall: 0.3837\n",
      "F1 score: 0.4272\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 4.5520 - val_loss: 3.7702\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.1063\n",
      "Recall: 0.4855\n",
      "F1 score: 0.1745\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 4.1492 - val_loss: 4.0973\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.4385\n",
      "Recall: 0.4096\n",
      "F1 score: 0.4236\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.5462 - val_loss: 3.2650\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.5141\n",
      "Recall: 0.3675\n",
      "F1 score: 0.4286\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.3225 - val_loss: 3.2570\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.25337\n",
      "Number of images: 45\n",
      "Presicion: 0.3767\n",
      "Recall: 0.4711\n",
      "F1 score: 0.4187\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 237s 594ms/step - loss: 3.3867 - val_loss: 3.2058\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.25337 to 3.20585, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5455\n",
      "Recall: 0.4126\n",
      "F1 score: 0.4698\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.2942 - val_loss: 3.2323\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.20585\n",
      "Number of images: 45\n",
      "Presicion: 0.4101\n",
      "Recall: 0.463\n",
      "F1 score: 0.435\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 3.1924 - val_loss: 3.3014\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.20585\n",
      "Number of images: 45\n",
      "Presicion: 0.3444\n",
      "Recall: 0.4143\n",
      "F1 score: 0.3761\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 3.1906 - val_loss: 3.1195\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.20585 to 3.11947, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.595\n",
      "Recall: 0.4116\n",
      "F1 score: 0.4866\n",
      "Improve F1 score from 0.47844059014850127 to 0.4865992257195874\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 3.1662 - val_loss: 3.1737\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.11947\n",
      "Number of images: 45\n",
      "Presicion: 0.5387\n",
      "Recall: 0.4194\n",
      "F1 score: 0.4716\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 3.1136 - val_loss: 3.2747\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.11947\n",
      "Number of images: 45\n",
      "Presicion: 0.5998\n",
      "Recall: 0.4134\n",
      "F1 score: 0.4894\n",
      "Improve F1 score from 0.4865992257195874 to 0.4894261336322589\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 3.1245 - val_loss: 3.0424\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.11947 to 3.04237, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5918\n",
      "Recall: 0.4017\n",
      "F1 score: 0.4786\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 3.0997 - val_loss: 3.0773\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.04237\n",
      "Number of images: 45\n",
      "Presicion: 0.5872\n",
      "Recall: 0.4246\n",
      "F1 score: 0.4928\n",
      "Improve F1 score from 0.4894261336322589 to 0.49284809429666265\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.0619 - val_loss: 3.0818\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.04237\n",
      "Number of images: 45\n",
      "Presicion: 0.558\n",
      "Recall: 0.411\n",
      "F1 score: 0.4733\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 3.0378 - val_loss: 2.9963\n",
      "\n",
      "Epoch 00025: val_loss improved from 3.04237 to 2.99629, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5389\n",
      "Recall: 0.4322\n",
      "F1 score: 0.4797\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.0510 - val_loss: 3.0282\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.99629\n",
      "Number of images: 45\n",
      "Presicion: 0.558\n",
      "Recall: 0.455\n",
      "F1 score: 0.5013\n",
      "Improve F1 score from 0.49284809429666265 to 0.5012968995704836\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.0309 - val_loss: 3.0535\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.99629\n",
      "Number of images: 45\n",
      "Presicion: 0.5664\n",
      "Recall: 0.4291\n",
      "F1 score: 0.4883\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 3.0109 - val_loss: 3.0898\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.99629\n",
      "Number of images: 45\n",
      "Presicion: 0.5842\n",
      "Recall: 0.4225\n",
      "F1 score: 0.4903\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 3.1208 - val_loss: 3.4032\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.99629\n",
      "Number of images: 45\n",
      "Presicion: 0.3619\n",
      "Recall: 0.4638\n",
      "F1 score: 0.4066\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 241s 602ms/step - loss: 3.0298 - val_loss: 3.0046\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.99629\n",
      "Number of images: 45\n",
      "Presicion: 0.5193\n",
      "Recall: 0.4649\n",
      "F1 score: 0.4906\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 2.9827 - val_loss: 2.9769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss improved from 2.99629 to 2.97694, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5705\n",
      "Recall: 0.4608\n",
      "F1 score: 0.5099\n",
      "Improve F1 score from 0.5012968995704836 to 0.5098513603318768\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 236s 591ms/step - loss: 3.2574 - val_loss: 3.1336\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.97694\n",
      "Number of images: 45\n",
      "Presicion: 0.4784\n",
      "Recall: 0.4668\n",
      "F1 score: 0.4726\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 3.0224 - val_loss: 2.9468\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.97694 to 2.94683, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5107\n",
      "Recall: 0.4572\n",
      "F1 score: 0.4824\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 2.9555 - val_loss: 3.0345\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.94683\n",
      "Number of images: 45\n",
      "Presicion: 0.6068\n",
      "Recall: 0.4206\n",
      "F1 score: 0.4968\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.9290 - val_loss: 2.9723\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.94683\n",
      "Number of images: 45\n",
      "Presicion: 0.5838\n",
      "Recall: 0.4346\n",
      "F1 score: 0.4983\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 2.9066 - val_loss: 2.9263\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.94683 to 2.92634, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5371\n",
      "Recall: 0.47\n",
      "F1 score: 0.5013\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.9047 - val_loss: 2.9193\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.92634 to 2.91930, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5899\n",
      "Recall: 0.4354\n",
      "F1 score: 0.501\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 241s 602ms/step - loss: 2.8926 - val_loss: 2.9259\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.91930\n",
      "Number of images: 45\n",
      "Presicion: 0.5674\n",
      "Recall: 0.4611\n",
      "F1 score: 0.5088\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 239s 596ms/step - loss: 2.8735 - val_loss: 3.0038\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.91930\n",
      "Number of images: 45\n",
      "Presicion: 0.5976\n",
      "Recall: 0.4493\n",
      "F1 score: 0.5129\n",
      "Improve F1 score from 0.5098513603318768 to 0.5129265830150963\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.8818 - val_loss: 2.9611\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.91930\n",
      "Number of images: 45\n",
      "Presicion: 0.5613\n",
      "Recall: 0.4708\n",
      "F1 score: 0.5121\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 2.8858 - val_loss: 2.9364\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.91930\n",
      "Number of images: 45\n",
      "Presicion: 0.549\n",
      "Recall: 0.4529\n",
      "F1 score: 0.4963\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.8601 - val_loss: 2.9146\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.91930 to 2.91458, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5848\n",
      "Recall: 0.4599\n",
      "F1 score: 0.5149\n",
      "Improve F1 score from 0.5129265830150963 to 0.5148830033096179\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 241s 603ms/step - loss: 2.8985 - val_loss: 2.9732\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.91458\n",
      "Number of images: 45\n",
      "Presicion: 0.5532\n",
      "Recall: 0.4705\n",
      "F1 score: 0.5085\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 2.8349 - val_loss: 2.9434\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.91458\n",
      "Number of images: 45\n",
      "Presicion: 0.5768\n",
      "Recall: 0.4528\n",
      "F1 score: 0.5073\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.8330 - val_loss: 2.9075\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.91458 to 2.90750, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5847\n",
      "Recall: 0.4452\n",
      "F1 score: 0.5055\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.8073 - val_loss: 2.9500\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.90750\n",
      "Number of images: 45\n",
      "Presicion: 0.5965\n",
      "Recall: 0.3964\n",
      "F1 score: 0.4763\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.7987 - val_loss: 2.8924\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.90750 to 2.89239, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5896\n",
      "Recall: 0.4173\n",
      "F1 score: 0.4887\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 237s 594ms/step - loss: 2.7746 - val_loss: 2.9031\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.89239\n",
      "Number of images: 45\n",
      "Presicion: 0.5247\n",
      "Recall: 0.4527\n",
      "F1 score: 0.486\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.8038 - val_loss: 2.9621\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.89239\n",
      "Number of images: 45\n",
      "Presicion: 0.5669\n",
      "Recall: 0.4685\n",
      "F1 score: 0.513\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.7549 - val_loss: 2.8655\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.89239 to 2.86553, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5948\n",
      "Recall: 0.406\n",
      "F1 score: 0.4826\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.8074 - val_loss: 3.0097\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.5603\n",
      "Recall: 0.393\n",
      "F1 score: 0.462\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 239s 596ms/step - loss: 2.7735 - val_loss: 2.9431\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.4957\n",
      "Recall: 0.4785\n",
      "F1 score: 0.487\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.7774 - val_loss: 2.9298\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.5547\n",
      "Recall: 0.482\n",
      "F1 score: 0.5158\n",
      "Improve F1 score from 0.5148830033096179 to 0.5158160672648185\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.7698 - val_loss: 2.9117\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.5336\n",
      "Recall: 0.4906\n",
      "F1 score: 0.5112\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 2.7403 - val_loss: 2.8708\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.5682\n",
      "Recall: 0.4463\n",
      "F1 score: 0.4999\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.7509 - val_loss: 2.8811\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.86553\n",
      "Number of images: 45\n",
      "Presicion: 0.5558\n",
      "Recall: 0.4245\n",
      "F1 score: 0.4813\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.6960 - val_loss: 2.8541\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.86553 to 2.85410, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5516\n",
      "Recall: 0.4244\n",
      "F1 score: 0.4797\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.7174 - val_loss: 2.9740\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.85410\n",
      "Number of images: 45\n",
      "Presicion: 0.5666\n",
      "Recall: 0.3999\n",
      "F1 score: 0.4688\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 2.7033 - val_loss: 2.8748\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.85410\n",
      "Number of images: 45\n",
      "Presicion: 0.5791\n",
      "Recall: 0.491\n",
      "F1 score: 0.5315\n",
      "Improve F1 score from 0.5158160672648185 to 0.5314528680741626\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.6978 - val_loss: 2.8001\n",
      "\n",
      "Epoch 00060: val_loss improved from 2.85410 to 2.80007, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5698\n",
      "Recall: 0.4613\n",
      "F1 score: 0.5098\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 2.6873 - val_loss: 2.8576\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.5917\n",
      "Recall: 0.4558\n",
      "F1 score: 0.5149\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 2.6738 - val_loss: 2.8145\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.80007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 45\n",
      "Presicion: 0.5774\n",
      "Recall: 0.4677\n",
      "F1 score: 0.5168\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 2.7002 - val_loss: 2.9453\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.5995\n",
      "Recall: 0.4215\n",
      "F1 score: 0.495\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.6822 - val_loss: 2.8263\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.5468\n",
      "Recall: 0.4676\n",
      "F1 score: 0.5041\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.6679 - val_loss: 2.8928\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.6084\n",
      "Recall: 0.4039\n",
      "F1 score: 0.4855\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.6429 - val_loss: 2.8493\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.562\n",
      "Recall: 0.4571\n",
      "F1 score: 0.5041\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.7491 - val_loss: 3.0464\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.80007\n",
      "Number of images: 45\n",
      "Presicion: 0.5592\n",
      "Recall: 0.4161\n",
      "F1 score: 0.4771\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.6520 - val_loss: 2.8531\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.80007\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Number of images: 45\n",
      "Presicion: 0.623\n",
      "Recall: 0.4764\n",
      "F1 score: 0.54\n",
      "Improve F1 score from 0.5314528680741626 to 0.5399589968751345\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.5488 - val_loss: 2.7539\n",
      "\n",
      "Epoch 00069: val_loss improved from 2.80007 to 2.75391, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5885\n",
      "Recall: 0.4842\n",
      "F1 score: 0.5313\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 2.5030 - val_loss: 2.7378\n",
      "\n",
      "Epoch 00070: val_loss improved from 2.75391 to 2.73777, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6078\n",
      "Recall: 0.4484\n",
      "F1 score: 0.5161\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 2.4670 - val_loss: 2.7299\n",
      "\n",
      "Epoch 00071: val_loss improved from 2.73777 to 2.72994, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.612\n",
      "Recall: 0.4429\n",
      "F1 score: 0.5139\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.4855 - val_loss: 2.7918\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.72994\n",
      "Number of images: 45\n",
      "Presicion: 0.604\n",
      "Recall: 0.4876\n",
      "F1 score: 0.5396\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.4605 - val_loss: 2.7556\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.72994\n",
      "Number of images: 45\n",
      "Presicion: 0.6062\n",
      "Recall: 0.4424\n",
      "F1 score: 0.5115\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 2.4716 - val_loss: 2.7150\n",
      "\n",
      "Epoch 00074: val_loss improved from 2.72994 to 2.71500, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5966\n",
      "Recall: 0.4648\n",
      "F1 score: 0.5225\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 241s 602ms/step - loss: 2.4432 - val_loss: 2.7631\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.6033\n",
      "Recall: 0.4608\n",
      "F1 score: 0.5225\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.4705 - val_loss: 2.7422\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.5918\n",
      "Recall: 0.4327\n",
      "F1 score: 0.4999\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.4378 - val_loss: 2.7330\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.6106\n",
      "Recall: 0.4683\n",
      "F1 score: 0.5301\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.4256 - val_loss: 2.7407\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.594\n",
      "Recall: 0.4599\n",
      "F1 score: 0.5184\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.4121 - val_loss: 2.7785\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.5855\n",
      "Recall: 0.4615\n",
      "F1 score: 0.5161\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 235s 588ms/step - loss: 2.4150 - val_loss: 2.7231\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.6229\n",
      "Recall: 0.4561\n",
      "F1 score: 0.5266\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.4195 - val_loss: 2.7446\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.71500\n",
      "Number of images: 45\n",
      "Presicion: 0.6219\n",
      "Recall: 0.4559\n",
      "F1 score: 0.5261\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.3830 - val_loss: 2.7692\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.71500\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Number of images: 45\n",
      "Presicion: 0.622\n",
      "Recall: 0.4435\n",
      "F1 score: 0.5178\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.3361 - val_loss: 2.7055\n",
      "\n",
      "Epoch 00083: val_loss improved from 2.71500 to 2.70550, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.631\n",
      "Recall: 0.4649\n",
      "F1 score: 0.5354\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 237s 594ms/step - loss: 2.3213 - val_loss: 2.7053\n",
      "\n",
      "Epoch 00084: val_loss improved from 2.70550 to 2.70529, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6252\n",
      "Recall: 0.4403\n",
      "F1 score: 0.5167\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.3191 - val_loss: 2.6840\n",
      "\n",
      "Epoch 00085: val_loss improved from 2.70529 to 2.68395, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6084\n",
      "Recall: 0.4576\n",
      "F1 score: 0.5223\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.3170 - val_loss: 2.6894\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6068\n",
      "Recall: 0.447\n",
      "F1 score: 0.5148\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.2907 - val_loss: 2.7132\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6063\n",
      "Recall: 0.4488\n",
      "F1 score: 0.5158\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 235s 588ms/step - loss: 2.2911 - val_loss: 2.6930\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6243\n",
      "Recall: 0.4508\n",
      "F1 score: 0.5236\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.3068 - val_loss: 2.6930\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6239\n",
      "Recall: 0.4704\n",
      "F1 score: 0.5364\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 2.2901 - val_loss: 2.6966\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6189\n",
      "Recall: 0.4449\n",
      "F1 score: 0.5176\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.3120 - val_loss: 2.7138\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6262\n",
      "Recall: 0.4582\n",
      "F1 score: 0.5292\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.2746 - val_loss: 2.6914\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.68395\n",
      "Number of images: 45\n",
      "Presicion: 0.6111\n",
      "Recall: 0.4633\n",
      "F1 score: 0.5271\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 235s 587ms/step - loss: 2.2646 - val_loss: 2.6931\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.68395\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Number of images: 45\n",
      "Presicion: 0.5992\n",
      "Recall: 0.4644\n",
      "F1 score: 0.5233\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.2649 - val_loss: 2.6798\n",
      "\n",
      "Epoch 00094: val_loss improved from 2.68395 to 2.67979, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 45\n",
      "Presicion: 0.6117\n",
      "Recall: 0.4661\n",
      "F1 score: 0.5291\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 235s 586ms/step - loss: 2.2309 - val_loss: 2.6823\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.67979\n",
      "Number of images: 45\n",
      "Presicion: 0.6071\n",
      "Recall: 0.455\n",
      "F1 score: 0.5202\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 238s 596ms/step - loss: 2.2211 - val_loss: 2.6692\n",
      "\n",
      "Epoch 00096: val_loss improved from 2.67979 to 2.66922, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6081\n",
      "Recall: 0.4521\n",
      "F1 score: 0.5186\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 238s 594ms/step - loss: 2.2216 - val_loss: 2.6768\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.615\n",
      "Recall: 0.4574\n",
      "F1 score: 0.5246\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 2.2154 - val_loss: 2.6812\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.626\n",
      "Recall: 0.465\n",
      "F1 score: 0.5336\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.2051 - val_loss: 2.6966\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6164\n",
      "Recall: 0.4701\n",
      "F1 score: 0.5334\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.2015 - val_loss: 2.7044\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6189\n",
      "Recall: 0.45\n",
      "F1 score: 0.5211\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.2090 - val_loss: 2.6901\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6303\n",
      "Recall: 0.454\n",
      "F1 score: 0.5278\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 241s 603ms/step - loss: 2.2202 - val_loss: 2.6842\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6246\n",
      "Recall: 0.4519\n",
      "F1 score: 0.5244\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.1927 - val_loss: 2.6832\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6257\n",
      "Recall: 0.4548\n",
      "F1 score: 0.5267\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.1977 - val_loss: 2.6859\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2.66922\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6295\n",
      "Recall: 0.4509\n",
      "F1 score: 0.5254\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 236s 591ms/step - loss: 2.1985 - val_loss: 2.6775\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.66922\n",
      "Number of images: 45\n",
      "Presicion: 0.6334\n",
      "Recall: 0.4451\n",
      "F1 score: 0.5228\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.2010 - val_loss: 2.6619\n",
      "\n",
      "Epoch 00106: val_loss improved from 2.66922 to 2.66193, saving model to /home/aldo/Downloads/ssd300_mobilenetv1_imagenet.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6183\n",
      "Recall: 0.4472\n",
      "F1 score: 0.519\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.2007 - val_loss: 2.6720\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6259\n",
      "Recall: 0.4398\n",
      "F1 score: 0.5166\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.1867 - val_loss: 2.6700\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6168\n",
      "Recall: 0.4673\n",
      "F1 score: 0.5317\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 242s 605ms/step - loss: 2.2017 - val_loss: 2.6641\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6294\n",
      "Recall: 0.4385\n",
      "F1 score: 0.5168\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.1813 - val_loss: 2.6711\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6276\n",
      "Recall: 0.4554\n",
      "F1 score: 0.5278\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 2.1791 - val_loss: 2.6694\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6216\n",
      "Recall: 0.4491\n",
      "F1 score: 0.5215\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.1839 - val_loss: 2.6729\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.623\n",
      "Recall: 0.4411\n",
      "F1 score: 0.5165\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.1805 - val_loss: 2.6657\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.62\n",
      "Recall: 0.4501\n",
      "F1 score: 0.5216\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 236s 591ms/step - loss: 2.1556 - val_loss: 2.6803\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.66193\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6234\n",
      "Recall: 0.443\n",
      "F1 score: 0.518\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.1663 - val_loss: 2.6723\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6248\n",
      "Recall: 0.4403\n",
      "F1 score: 0.5166\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.1766 - val_loss: 2.6645\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.66193\n",
      "Number of images: 45\n",
      "Presicion: 0.6277\n",
      "Recall: 0.4592\n",
      "F1 score: 0.5304\n",
      "Epoch 00116: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 400\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'history/ssd300_adam_vgg13_bn/ssd300_vgg_13_pascal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['epoch'], df['loss'])\n",
    "plt.plot(df['epoch'], df['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint.best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
