{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSDLite300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssdlite320_mobilenetv1 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 320 # Height of the model input images\n",
    "img_width = 320 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [-1., -1., -1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = new_scales\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 32, 64, 107, 160, 320] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "\n",
    "# TODO: Set the path to the weights you want to load.\n",
    "# weights_path = '../weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5'\n",
    "# model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 320, 320, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 320, 320, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 320, 320, 3)  0           input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             1363648     input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv__11 (Conv2D)               (None, 20, 20, 512)  262144      model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_bn (BatchNormalization) (None, 20, 20, 512)  2048        conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_11_relu (Activation)       (None, 20, 20, 512)  0           conv_11_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)     (None, 22, 22, 512)  0           conv_11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D)    (None, 10, 10, 512)  4608        conv_pad_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormalizati (None, 10, 10, 512)  2048        conv_dw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_relu (Activation)    (None, 10, 10, 512)  0           conv_dw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12 (Conv2D)             (None, 10, 10, 1024) 524288      conv_dw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormalizati (None, 10, 10, 1024) 4096        conv_pw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_relu (Activation)    (None, 10, 10, 1024) 0           conv_pw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)     (None, 12, 12, 1024) 0           conv_pw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D)    (None, 10, 10, 1024) 9216        conv_pad_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormalizati (None, 10, 10, 1024) 4096        conv_dw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 10, 10, 1024) 0           conv_dw_13_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv__13 (Conv2D)               (None, 10, 10, 1024) 1048576     conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_bn (BatchNormalization) (None, 10, 10, 1024) 4096        conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 10, 10, 1024) 0           conv_13_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv1 (Conv2D)             (None, 10, 10, 256)  262144      conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv1_bn (BatchNormalizati (None, 10, 10, 256)  1024        14_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv1_act (Activation)     (None, 10, 10, 256)  0           14_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "14_dwconv2 (DepthwiseConv2D)    (None, 5, 5, 256)    2304        14_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "14_sepconv2_bn (BatchNormalizat (None, 5, 5, 256)    1024        14_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "14_sepconv2_act (Activation)    (None, 5, 5, 256)    0           14_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv3 (Conv2D)             (None, 5, 5, 512)    131072      14_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv3_bn (BatchNormalizati (None, 5, 5, 512)    2048        14_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "14_pwconv3_act (Activation)     (None, 5, 5, 512)    0           14_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv1 (Conv2D)             (None, 5, 5, 128)    65536       14_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv1_bn (BatchNormalizati (None, 5, 5, 128)    512         15_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv1_act (Activation)     (None, 5, 5, 128)    0           15_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "15_dwconv2 (DepthwiseConv2D)    (None, 3, 3, 128)    1152        15_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "15_sepconv2_bn (BatchNormalizat (None, 3, 3, 128)    512         15_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "15_sepconv2_act (Activation)    (None, 3, 3, 128)    0           15_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv3 (Conv2D)             (None, 3, 3, 256)    32768       15_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv3_bn (BatchNormalizati (None, 3, 3, 256)    1024        15_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "15_pwconv3_act (Activation)     (None, 3, 3, 256)    0           15_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv1 (Conv2D)             (None, 3, 3, 128)    32768       15_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv1_bn (BatchNormalizati (None, 3, 3, 128)    512         16_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv1_act (Activation)     (None, 3, 3, 128)    0           16_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "16_dwconv2 (DepthwiseConv2D)    (None, 2, 2, 128)    1152        16_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "16_sepconv2_bn (BatchNormalizat (None, 2, 2, 128)    512         16_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "16_sepconv2_act (Activation)    (None, 2, 2, 128)    0           16_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv3 (Conv2D)             (None, 2, 2, 256)    32768       16_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv3_bn (BatchNormalizati (None, 2, 2, 256)    1024        16_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "16_pwconv3_act (Activation)     (None, 2, 2, 256)    0           16_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "17_pwconv1 (Conv2D)             (None, 2, 2, 64)     16384       16_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "17_pwconv1_bn (BatchNormalizati (None, 2, 2, 64)     256         17_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "17_pwconv1_act (Activation)     (None, 2, 2, 64)     0           17_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "17_dwconv2 (DepthwiseConv2D)    (None, 1, 1, 64)     576         17_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "17_sepconv2_bn (BatchNormalizat (None, 1, 1, 64)     256         17_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "17_sepconv2_act (Activation)    (None, 1, 1, 64)     0           17_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "17_pwconv3 (Conv2D)             (None, 1, 1, 128)    8192        17_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf (Conv2D)       (None, 20, 20, 8)    36872       conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 10, 10, 12)   110604      conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf (Conv2D)     (None, 5, 5, 12)     55308       14_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf (Conv2D)     (None, 3, 3, 12)     27660       15_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf (Conv2D)     (None, 2, 2, 8)      18440       16_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf (Conv2D)     (None, 1, 1, 8)      9224        17_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc (Conv2D)        (None, 20, 20, 16)   73744       conv__11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 10, 10, 24)   221208      conv__13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc (Conv2D)      (None, 5, 5, 24)     110616      14_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc (Conv2D)      (None, 3, 3, 24)     55320       15_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc (Conv2D)      (None, 2, 2, 16)     36880       16_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc (Conv2D)      (None, 1, 1, 16)     18448       17_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1600, 2)      0           conv11_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 600, 2)       0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 150, 2)       0           conv14_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 54, 2)        0           conv15_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 16, 2)        0           conv16_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 4, 2)         0           conv17_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_priorbox (AnchorBox (None, 20, 20, 4, 8) 0           conv11_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 10, 10, 6, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_priorbox (AnchorB (None, 5, 5, 6, 8)   0           conv14_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_priorbox (AnchorB (None, 3, 3, 6, 8)   0           conv15_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_priorbox (AnchorB (None, 2, 2, 4, 8)   0           conv16_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_priorbox (AnchorB (None, 1, 1, 4, 8)   0           conv17_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 2424, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1600, 4)      0           conv11_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 600, 4)       0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 150, 4)       0           conv14_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 54, 4)        0           conv15_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 16, 4)        0           conv16_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 4, 4)         0           conv17_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_priorbox_reshape (R (None, 1600, 8)      0           conv11_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 600, 8)       0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_priorbox_reshape  (None, 150, 8)       0           conv14_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_priorbox_reshape  (None, 54, 8)        0           conv15_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_priorbox_reshape  (None, 16, 8)        0           conv16_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_priorbox_reshape  (None, 4, 8)         0           conv17_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 2424, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 2424, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 2424, 8)      0           conv11_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv14_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv15_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv16_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv17_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2424, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,598,708\n",
      "Trainable params: 4,572,468\n",
      "Non-trainable params: 26,240\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:32<00:00, 201.85it/s]\n",
      "Loading images into memory: 100%|██████████| 2097/2097 [00:09<00:00, 228.57it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "images_dir = data_path + 'pascal_dataset'\n",
    "# images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv11_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv14_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv15_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv16_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 100:\n",
    "        return 0.0001\n",
    "    elif epoch < 200:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val_320.npy')\n",
    "val_images_320 = np.load('../data-cic/preprocess_data/images_val_320x320.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "# model_checkpoint.best = 2.567152314715915\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=8,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.00001)\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_320, \n",
    "                      label_val, \n",
    "                      (1, 2424, 14),\n",
    "                      data_path + 'history/ssdlite320_mobilenetv1.csv')\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "#              learning_rate_scheduler]\n",
    "             reduce_learning_rate,\n",
    "             f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "400/400 [==============================] - 251s 626ms/step - loss: 5.9266 - val_loss: 3.9159\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.91585, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.324\n",
      "Recall: 0.3405\n",
      "F1 score: 0.332\n",
      "Improve F1 score from -inf to 0.3320208689643018\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 232s 580ms/step - loss: 3.8324 - val_loss: 3.9328\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.91585\n",
      "Number of images: 45\n",
      "Presicion: 0.5336\n",
      "Recall: 0.2961\n",
      "F1 score: 0.3808\n",
      "Improve F1 score from 0.3320208689643018 to 0.3808280776621683\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 235s 589ms/step - loss: 3.6732 - val_loss: 3.5133\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.91585 to 3.51327, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.4501\n",
      "Recall: 0.3965\n",
      "F1 score: 0.4216\n",
      "Improve F1 score from 0.3808280776621683 to 0.4215617664036014\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 231s 578ms/step - loss: 3.5649 - val_loss: 3.7082\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.51327\n",
      "Number of images: 45\n",
      "Presicion: 0.3849\n",
      "Recall: 0.4136\n",
      "F1 score: 0.3987\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 235s 587ms/step - loss: 3.5091 - val_loss: 3.7240\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.51327\n",
      "Number of images: 45\n",
      "Presicion: 0.4435\n",
      "Recall: 0.3548\n",
      "F1 score: 0.3942\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 233s 584ms/step - loss: 3.4140 - val_loss: 3.2776\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.51327 to 3.27759, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.455\n",
      "Recall: 0.4594\n",
      "F1 score: 0.4572\n",
      "Improve F1 score from 0.4215617664036014 to 0.4571896189026499\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 236s 589ms/step - loss: 3.3898 - val_loss: 3.4777\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.4925\n",
      "Recall: 0.376\n",
      "F1 score: 0.4265\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 3.3410 - val_loss: 4.1017\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.5655\n",
      "Recall: 0.2556\n",
      "F1 score: 0.3521\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 235s 587ms/step - loss: 11.4883 - val_loss: 4.9045\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.4178\n",
      "Recall: 0.3781\n",
      "F1 score: 0.397\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 235s 587ms/step - loss: 4.6005 - val_loss: 3.6768\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.5092\n",
      "Recall: 0.427\n",
      "F1 score: 0.4645\n",
      "Improve F1 score from 0.4571896189026499 to 0.4644677548916992\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 236s 591ms/step - loss: 3.7146 - val_loss: 3.5007\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.5425\n",
      "Recall: 0.3818\n",
      "F1 score: 0.4482\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 234s 585ms/step - loss: 3.3608 - val_loss: 3.3925\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.4593\n",
      "Recall: 0.4465\n",
      "F1 score: 0.4528\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 237s 592ms/step - loss: 3.4724 - val_loss: 3.3237\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.27759\n",
      "Number of images: 45\n",
      "Presicion: 0.5142\n",
      "Recall: 0.4192\n",
      "F1 score: 0.4618\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 234s 585ms/step - loss: 3.2551 - val_loss: 3.4109\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.27759\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Number of images: 45\n",
      "Presicion: 0.4382\n",
      "Recall: 0.4405\n",
      "F1 score: 0.4393\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 239s 599ms/step - loss: 3.1016 - val_loss: 3.0635\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.27759 to 3.06350, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5598\n",
      "Recall: 0.4339\n",
      "F1 score: 0.4889\n",
      "Improve F1 score from 0.4644677548916992 to 0.48888254594403546\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 241s 603ms/step - loss: 3.0135 - val_loss: 2.9644\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.06350 to 2.96440, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5571\n",
      "Recall: 0.4755\n",
      "F1 score: 0.5131\n",
      "Improve F1 score from 0.48888254594403546 to 0.5130661082287571\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 234s 586ms/step - loss: 2.9717 - val_loss: 2.9481\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.96440 to 2.94812, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5723\n",
      "Recall: 0.4514\n",
      "F1 score: 0.5047\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 250s 626ms/step - loss: 3.0146 - val_loss: 2.9539\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.94812\n",
      "Number of images: 45\n",
      "Presicion: 0.5782\n",
      "Recall: 0.4335\n",
      "F1 score: 0.4955\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 250s 625ms/step - loss: 2.9445 - val_loss: 2.9308\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.94812 to 2.93081, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5964\n",
      "Recall: 0.4418\n",
      "F1 score: 0.5076\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 269s 674ms/step - loss: 2.9278 - val_loss: 2.9876\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.93081\n",
      "Number of images: 45\n",
      "Presicion: 0.6043\n",
      "Recall: 0.4585\n",
      "F1 score: 0.5214\n",
      "Improve F1 score from 0.5130661082287571 to 0.5213928289804416\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 256s 639ms/step - loss: 2.8951 - val_loss: 2.8832\n",
      "\n",
      "Epoch 00021: val_loss improved from 2.93081 to 2.88318, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5897\n",
      "Recall: 0.4721\n",
      "F1 score: 0.5244\n",
      "Improve F1 score from 0.5213928289804416 to 0.5244107735870636\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 237s 593ms/step - loss: 2.8957 - val_loss: 2.9424\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.628\n",
      "Recall: 0.4234\n",
      "F1 score: 0.5058\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 245s 612ms/step - loss: 2.9039 - val_loss: 2.9179\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.5977\n",
      "Recall: 0.424\n",
      "F1 score: 0.4961\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.8623 - val_loss: 2.8956\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.6124\n",
      "Recall: 0.4489\n",
      "F1 score: 0.518\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 238s 595ms/step - loss: 2.8475 - val_loss: 2.9458\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.5675\n",
      "Recall: 0.4597\n",
      "F1 score: 0.5079\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 247s 617ms/step - loss: 2.8494 - val_loss: 2.9198\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.55\n",
      "Recall: 0.4792\n",
      "F1 score: 0.5122\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 248s 620ms/step - loss: 2.8249 - val_loss: 3.0029\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.4801\n",
      "Recall: 0.404\n",
      "F1 score: 0.4388\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 243s 607ms/step - loss: 2.8126 - val_loss: 2.9036\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.88318\n",
      "Number of images: 45\n",
      "Presicion: 0.5814\n",
      "Recall: 0.4786\n",
      "F1 score: 0.525\n",
      "Improve F1 score from 0.5244107735870636 to 0.5250069284435084\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 248s 621ms/step - loss: 2.7731 - val_loss: 2.9256\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.88318\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 45\n",
      "Presicion: 0.628\n",
      "Recall: 0.4681\n",
      "F1 score: 0.5364\n",
      "Improve F1 score from 0.5250069284435084 to 0.5364296532961951\n",
      "Epoch 30/1000\n",
      "400/400 [==============================] - 251s 629ms/step - loss: 2.7228 - val_loss: 2.7778\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.88318 to 2.77777, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6122\n",
      "Recall: 0.4774\n",
      "F1 score: 0.5364\n",
      "Improve F1 score from 0.5364296532961951 to 0.5364368726527592\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 255s 637ms/step - loss: 2.6554 - val_loss: 2.8062\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.77777\n",
      "Number of images: 45\n",
      "Presicion: 0.6162\n",
      "Recall: 0.4567\n",
      "F1 score: 0.5246\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 265s 661ms/step - loss: 2.6606 - val_loss: 2.8013\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.77777\n",
      "Number of images: 45\n",
      "Presicion: 0.6456\n",
      "Recall: 0.4611\n",
      "F1 score: 0.538\n",
      "Improve F1 score from 0.5364368726527592 to 0.5379619575129936\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 264s 659ms/step - loss: 2.6484 - val_loss: 2.8455\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.77777\n",
      "Number of images: 45\n",
      "Presicion: 0.6348\n",
      "Recall: 0.46\n",
      "F1 score: 0.5334\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 264s 660ms/step - loss: 2.6346 - val_loss: 2.7541\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.77777 to 2.75409, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6167\n",
      "Recall: 0.4853\n",
      "F1 score: 0.5432\n",
      "Improve F1 score from 0.5379619575129936 to 0.5432041875033127\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 258s 644ms/step - loss: 2.6416 - val_loss: 2.7703\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.75409\n",
      "Number of images: 45\n",
      "Presicion: 0.6302\n",
      "Recall: 0.4603\n",
      "F1 score: 0.532\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 261s 651ms/step - loss: 2.6342 - val_loss: 2.7514\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.75409 to 2.75139, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6336\n",
      "Recall: 0.4795\n",
      "F1 score: 0.5459\n",
      "Improve F1 score from 0.5432041875033127 to 0.5458885766522056\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 239s 598ms/step - loss: 2.6180 - val_loss: 2.7636\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6313\n",
      "Recall: 0.4636\n",
      "F1 score: 0.5346\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 253s 632ms/step - loss: 2.6156 - val_loss: 2.8086\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6103\n",
      "Recall: 0.4666\n",
      "F1 score: 0.5289\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 249s 622ms/step - loss: 2.6017 - val_loss: 2.7625\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6175\n",
      "Recall: 0.4776\n",
      "F1 score: 0.5386\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 236s 589ms/step - loss: 2.5877 - val_loss: 2.7698\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6098\n",
      "Recall: 0.4742\n",
      "F1 score: 0.5335\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 245s 611ms/step - loss: 2.5692 - val_loss: 2.7945\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6226\n",
      "Recall: 0.4872\n",
      "F1 score: 0.5466\n",
      "Improve F1 score from 0.5458885766522056 to 0.5466251852592886\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 271s 678ms/step - loss: 2.5804 - val_loss: 2.7745\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.6196\n",
      "Recall: 0.4778\n",
      "F1 score: 0.5395\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 272s 681ms/step - loss: 2.5676 - val_loss: 2.7692\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.75139\n",
      "Number of images: 45\n",
      "Presicion: 0.5999\n",
      "Recall: 0.4731\n",
      "F1 score: 0.529\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 268s 669ms/step - loss: 2.5750 - val_loss: 2.8015\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.75139\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Number of images: 45\n",
      "Presicion: 0.6121\n",
      "Recall: 0.498\n",
      "F1 score: 0.5492\n",
      "Improve F1 score from 0.5466251852592886 to 0.5491615332879887\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 245s 613ms/step - loss: 2.5167 - val_loss: 2.7067\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.75139 to 2.70673, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6343\n",
      "Recall: 0.4852\n",
      "F1 score: 0.5498\n",
      "Improve F1 score from 0.5491615332879887 to 0.549805565432105\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 246s 615ms/step - loss: 2.4956 - val_loss: 2.7196\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.638\n",
      "Recall: 0.4885\n",
      "F1 score: 0.5533\n",
      "Improve F1 score from 0.549805565432105 to 0.55331875002351\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 239s 597ms/step - loss: 2.4586 - val_loss: 2.7108\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.64\n",
      "Recall: 0.4857\n",
      "F1 score: 0.5522\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 236s 591ms/step - loss: 2.4886 - val_loss: 2.7136\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.6329\n",
      "Recall: 0.4867\n",
      "F1 score: 0.5502\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 235s 589ms/step - loss: 2.4604 - val_loss: 2.7488\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.6181\n",
      "Recall: 0.4775\n",
      "F1 score: 0.5388\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 242s 605ms/step - loss: 2.4731 - val_loss: 2.7191\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.6284\n",
      "Recall: 0.4905\n",
      "F1 score: 0.551\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 248s 621ms/step - loss: 2.4359 - val_loss: 2.7241\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.6339\n",
      "Recall: 0.4832\n",
      "F1 score: 0.5484\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 258s 646ms/step - loss: 2.4373 - val_loss: 2.7204\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.70673\n",
      "Number of images: 45\n",
      "Presicion: 0.6279\n",
      "Recall: 0.49\n",
      "F1 score: 0.5505\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 251s 627ms/step - loss: 2.4287 - val_loss: 2.7262\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.70673\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6159\n",
      "Recall: 0.4436\n",
      "F1 score: 0.5157\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 263s 658ms/step - loss: 2.4038 - val_loss: 2.7048\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.70673 to 2.70481, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6371\n",
      "Recall: 0.4771\n",
      "F1 score: 0.5456\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 266s 664ms/step - loss: 2.4013 - val_loss: 2.7184\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6277\n",
      "Recall: 0.4878\n",
      "F1 score: 0.549\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 262s 656ms/step - loss: 2.4061 - val_loss: 2.7201\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6285\n",
      "Recall: 0.4788\n",
      "F1 score: 0.5436\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 252s 629ms/step - loss: 2.3776 - val_loss: 2.7178\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6305\n",
      "Recall: 0.4731\n",
      "F1 score: 0.5405\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 251s 628ms/step - loss: 2.3936 - val_loss: 2.7226\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6236\n",
      "Recall: 0.494\n",
      "F1 score: 0.5513\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 248s 620ms/step - loss: 2.3775 - val_loss: 2.7114\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6454\n",
      "Recall: 0.4859\n",
      "F1 score: 0.5544\n",
      "Improve F1 score from 0.55331875002351 to 0.5544410456075037\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 243s 608ms/step - loss: 2.3949 - val_loss: 2.7189\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.633\n",
      "Recall: 0.4824\n",
      "F1 score: 0.5475\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.3712 - val_loss: 2.7086\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.70481\n",
      "Number of images: 45\n",
      "Presicion: 0.6144\n",
      "Recall: 0.4848\n",
      "F1 score: 0.542\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 2.3854 - val_loss: 2.7107\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.70481\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6372\n",
      "Recall: 0.4937\n",
      "F1 score: 0.5563\n",
      "Improve F1 score from 0.5544410456075037 to 0.5563286622746616\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 234s 584ms/step - loss: 2.3477 - val_loss: 2.6998\n",
      "\n",
      "Epoch 00063: val_loss improved from 2.70481 to 2.69984, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6226\n",
      "Recall: 0.4871\n",
      "F1 score: 0.5466\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 243s 607ms/step - loss: 2.3650 - val_loss: 2.7027\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.69984\n",
      "Number of images: 45\n",
      "Presicion: 0.6287\n",
      "Recall: 0.4961\n",
      "F1 score: 0.5546\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 233s 582ms/step - loss: 2.3680 - val_loss: 2.7091\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.69984\n",
      "Number of images: 45\n",
      "Presicion: 0.6439\n",
      "Recall: 0.4889\n",
      "F1 score: 0.5558\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 240s 600ms/step - loss: 2.3565 - val_loss: 2.6950\n",
      "\n",
      "Epoch 00066: val_loss improved from 2.69984 to 2.69500, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6231\n",
      "Recall: 0.4916\n",
      "F1 score: 0.5496\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 237s 591ms/step - loss: 2.3753 - val_loss: 2.6985\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6398\n",
      "Recall: 0.4783\n",
      "F1 score: 0.5474\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 242s 606ms/step - loss: 2.3597 - val_loss: 2.6981\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6321\n",
      "Recall: 0.473\n",
      "F1 score: 0.5411\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 234s 586ms/step - loss: 2.3684 - val_loss: 2.7179\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6276\n",
      "Recall: 0.4765\n",
      "F1 score: 0.5417\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 235s 588ms/step - loss: 2.3603 - val_loss: 2.7003\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6308\n",
      "Recall: 0.4779\n",
      "F1 score: 0.5438\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 234s 584ms/step - loss: 2.3488 - val_loss: 2.6977\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6343\n",
      "Recall: 0.474\n",
      "F1 score: 0.5426\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 240s 599ms/step - loss: 2.3311 - val_loss: 2.7023\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6288\n",
      "Recall: 0.4758\n",
      "F1 score: 0.5417\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 240s 601ms/step - loss: 2.3493 - val_loss: 2.7035\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6298\n",
      "Recall: 0.483\n",
      "F1 score: 0.5468\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 233s 583ms/step - loss: 2.3511 - val_loss: 2.6989\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.69500\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6261\n",
      "Recall: 0.4824\n",
      "F1 score: 0.545\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 235s 588ms/step - loss: 2.3656 - val_loss: 2.6992\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6287\n",
      "Recall: 0.4833\n",
      "F1 score: 0.5465\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 236s 589ms/step - loss: 2.3381 - val_loss: 2.7052\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.69500\n",
      "Number of images: 45\n",
      "Presicion: 0.6304\n",
      "Recall: 0.478\n",
      "F1 score: 0.5437\n",
      "Epoch 00076: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 400\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset learning rate to 0.001\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:07<00:00, 26.41it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 26.71it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "# images_dir = data_path + 'pascal_dataset'\n",
    "images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "#train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "#val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv11_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv14_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv15_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv16_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "# model_checkpoint.best = 2.567152314715915\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=8,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.00001)\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_320, \n",
    "                      label_val, \n",
    "                      (1, 2424, 14),\n",
    "                      data_path + 'history/ssdlite320_mobilenetv1.csv')\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "#              learning_rate_scheduler]\n",
    "             reduce_learning_rate,\n",
    "             f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 3.4112 - val_loss: 2.9022\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.90222, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6052\n",
      "Recall: 0.5351\n",
      "F1 score: 0.568\n",
      "Improve F1 score from -inf to 0.5680241569195243\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.9671 - val_loss: 2.7183\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.90222 to 2.71828, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.632\n",
      "Recall: 0.5813\n",
      "F1 score: 0.6056\n",
      "Improve F1 score from 0.5680241569195243 to 0.6056160601503697\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.8655 - val_loss: 2.7348\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.71828\n",
      "Number of images: 45\n",
      "Presicion: 0.64\n",
      "Recall: 0.57\n",
      "F1 score: 0.603\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6357 - val_loss: 2.6000\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.71828 to 2.59997, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6493\n",
      "Recall: 0.5974\n",
      "F1 score: 0.6223\n",
      "Improve F1 score from 0.6056160601503697 to 0.6222556041919894\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6669 - val_loss: 2.5919\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.59997 to 2.59192, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6569\n",
      "Recall: 0.5551\n",
      "F1 score: 0.6017\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.5925 - val_loss: 2.5101\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.59192 to 2.51012, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6622\n",
      "Recall: 0.6014\n",
      "F1 score: 0.6303\n",
      "Improve F1 score from 0.6222556041919894 to 0.6303122616460775\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.4941 - val_loss: 2.6535\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.51012\n",
      "Number of images: 45\n",
      "Presicion: 0.6408\n",
      "Recall: 0.5161\n",
      "F1 score: 0.5717\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.5533 - val_loss: 2.6696\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.51012\n",
      "Number of images: 45\n",
      "Presicion: 0.6907\n",
      "Recall: 0.5037\n",
      "F1 score: 0.5826\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.4880 - val_loss: 2.6044\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.51012\n",
      "Number of images: 45\n",
      "Presicion: 0.6258\n",
      "Recall: 0.5739\n",
      "F1 score: 0.5987\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.6212 - val_loss: 2.6187\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.51012\n",
      "Number of images: 45\n",
      "Presicion: 0.6543\n",
      "Recall: 0.5142\n",
      "F1 score: 0.5758\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.4610 - val_loss: 2.5968\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.51012\n",
      "Number of images: 45\n",
      "Presicion: 0.6869\n",
      "Recall: 0.5584\n",
      "F1 score: 0.616\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.4000 - val_loss: 2.4104\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.51012 to 2.41037, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6804\n",
      "Recall: 0.5843\n",
      "F1 score: 0.6287\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.3523 - val_loss: 2.4240\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.41037\n",
      "Number of images: 45\n",
      "Presicion: 0.6693\n",
      "Recall: 0.5713\n",
      "F1 score: 0.6165\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.3156 - val_loss: 2.4428\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.41037\n",
      "Number of images: 45\n",
      "Presicion: 0.6866\n",
      "Recall: 0.6095\n",
      "F1 score: 0.6457\n",
      "Improve F1 score from 0.6303122616460775 to 0.6457365542359228\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.2870 - val_loss: 2.3492\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.41037 to 2.34916, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7037\n",
      "Recall: 0.5914\n",
      "F1 score: 0.6427\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.3402 - val_loss: 2.4304\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.7199\n",
      "Recall: 0.5789\n",
      "F1 score: 0.6418\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.2553 - val_loss: 2.4620\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.7198\n",
      "Recall: 0.5873\n",
      "F1 score: 0.6468\n",
      "Improve F1 score from 0.6457365542359228 to 0.6468393802469092\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3296 - val_loss: 2.3662\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.6735\n",
      "Recall: 0.5956\n",
      "F1 score: 0.6322\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.2179 - val_loss: 2.4438\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.6873\n",
      "Recall: 0.5685\n",
      "F1 score: 0.6223\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.1615 - val_loss: 2.4845\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.6756\n",
      "Recall: 0.5968\n",
      "F1 score: 0.6338\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1998 - val_loss: 2.3941\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.6704\n",
      "Recall: 0.6169\n",
      "F1 score: 0.6425\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.1232 - val_loss: 2.5113\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.34916\n",
      "Number of images: 45\n",
      "Presicion: 0.6789\n",
      "Recall: 0.5824\n",
      "F1 score: 0.627\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.1443 - val_loss: 2.3201\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.34916 to 2.32015, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6794\n",
      "Recall: 0.6287\n",
      "F1 score: 0.653\n",
      "Improve F1 score from 0.6468393802469092 to 0.6530461562805236\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1243 - val_loss: 2.3186\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.32015 to 2.31861, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7054\n",
      "Recall: 0.6025\n",
      "F1 score: 0.6499\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1849 - val_loss: 2.2589\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.31861 to 2.25886, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7096\n",
      "Recall: 0.633\n",
      "F1 score: 0.6691\n",
      "Improve F1 score from 0.6530461562805236 to 0.6691342676255179\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1309 - val_loss: 2.2616\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.25886\n",
      "Number of images: 45\n",
      "Presicion: 0.7085\n",
      "Recall: 0.6233\n",
      "F1 score: 0.6631\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.0214 - val_loss: 2.2622\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.25886\n",
      "Number of images: 45\n",
      "Presicion: 0.7295\n",
      "Recall: 0.6226\n",
      "F1 score: 0.6718\n",
      "Improve F1 score from 0.6691342676255179 to 0.6718334733879997\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1106 - val_loss: 2.1960\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.25886 to 2.19603, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.719\n",
      "Recall: 0.6413\n",
      "F1 score: 0.678\n",
      "Improve F1 score from 0.6718334733879997 to 0.6779599058831065\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 65s 4s/step - loss: 1.9533 - val_loss: 2.2397\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.19603\n",
      "Number of images: 45\n",
      "Presicion: 0.7121\n",
      "Recall: 0.5732\n",
      "F1 score: 0.6351\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.0775 - val_loss: 2.1940\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.19603 to 2.19404, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7103\n",
      "Recall: 0.6177\n",
      "F1 score: 0.6608\n",
      "Epoch 31/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.1559 - val_loss: 2.3997\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.19404\n",
      "Number of images: 45\n",
      "Presicion: 0.7032\n",
      "Recall: 0.6093\n",
      "F1 score: 0.6529\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.1408 - val_loss: 2.3910\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.19404\n",
      "Number of images: 45\n",
      "Presicion: 0.6598\n",
      "Recall: 0.5958\n",
      "F1 score: 0.6262\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.0897 - val_loss: 2.1480\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.19404 to 2.14801, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6815\n",
      "Recall: 0.6276\n",
      "F1 score: 0.6534\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0985 - val_loss: 2.1153\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.14801 to 2.11534, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6932\n",
      "Recall: 0.6178\n",
      "F1 score: 0.6533\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.0090 - val_loss: 2.2025\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6782\n",
      "Recall: 0.5917\n",
      "F1 score: 0.632\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 69s 5s/step - loss: 1.9544 - val_loss: 2.2223\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6555\n",
      "Recall: 0.626\n",
      "F1 score: 0.6404\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.8804 - val_loss: 2.2334\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6745\n",
      "Recall: 0.6374\n",
      "F1 score: 0.6554\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9003 - val_loss: 2.1699\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6795\n",
      "Recall: 0.6518\n",
      "F1 score: 0.6654\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.0214 - val_loss: 2.1722\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6699\n",
      "Recall: 0.6412\n",
      "F1 score: 0.6553\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 1.9939 - val_loss: 2.1751\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.11534\n",
      "Number of images: 45\n",
      "Presicion: 0.6044\n",
      "Recall: 0.6631\n",
      "F1 score: 0.6324\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9435 - val_loss: 2.0831\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.11534 to 2.08308, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7303\n",
      "Recall: 0.5841\n",
      "F1 score: 0.6491\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.9037 - val_loss: 2.2283\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.6945\n",
      "Recall: 0.6271\n",
      "F1 score: 0.6591\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.9937 - val_loss: 2.2700\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.6798\n",
      "Recall: 0.6297\n",
      "F1 score: 0.6538\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.0781 - val_loss: 2.4466\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.6858\n",
      "Recall: 0.5763\n",
      "F1 score: 0.6263\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9247 - val_loss: 2.1772\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.7039\n",
      "Recall: 0.6187\n",
      "F1 score: 0.6585\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9126 - val_loss: 2.2137\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.6924\n",
      "Recall: 0.6321\n",
      "F1 score: 0.6609\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9389 - val_loss: 2.4307\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.7054\n",
      "Recall: 0.6182\n",
      "F1 score: 0.6589\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 1.9427 - val_loss: 2.2454\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.6759\n",
      "Recall: 0.6476\n",
      "F1 score: 0.6614\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.7030 - val_loss: 2.2109\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.08308\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Number of images: 45\n",
      "Presicion: 0.7115\n",
      "Recall: 0.6593\n",
      "F1 score: 0.6844\n",
      "Improve F1 score from 0.6779599058831065 to 0.6844115729569334\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9705 - val_loss: 2.0971\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.7291\n",
      "Recall: 0.6274\n",
      "F1 score: 0.6744\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 1.7067 - val_loss: 2.0920\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.08308\n",
      "Number of images: 45\n",
      "Presicion: 0.7248\n",
      "Recall: 0.6249\n",
      "F1 score: 0.6711\n",
      "Epoch 00051: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 15\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
