{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD300 Inference Tutorial\n",
    "\n",
    "This is a brief tutorial that shows how to use a trained SSD300 for inference on the Pascal VOC datasets. If you'd like more detailed explanations, please refer to [`ssd300_training.ipynb`](https://github.com/pierluigiferrari/ssd_keras/blob/master/ssd300_training.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/aldopedraza/Documentos/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files import helper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a trained SSD\n",
    "\n",
    "Either load a trained model or build a model and load trained weights into it. Since the HDF5 files I'm providing contain only the weights for the various SSD versions, not the complete models, you'll have to go with the latter option when using this implementation for the first time. You can then of course save the model and next time load the full model directly, without having to build it.\n",
    "\n",
    "You can find the download links to all the trained model weights in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Build the model and load trained weights into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, height, width):\n",
    "    # 1: Build the Keras model\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    if height == 300:\n",
    "        model = ssd_300(image_size=(height, width, 3),\n",
    "                        n_classes=20,\n",
    "                        mode='inference',\n",
    "                        l2_regularization=0.0005,\n",
    "                        scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], # The scales for MS COCO are [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "                        aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5]],\n",
    "                        two_boxes_for_ar1=True,\n",
    "                        steps=[8, 16, 32, 64, 100, 300],\n",
    "                        offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                        clip_boxes=False,\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        normalize_coords=True,\n",
    "                        subtract_mean=[123, 117, 104],\n",
    "                        swap_channels=[2, 1, 0],\n",
    "                        confidence_thresh=0.5,\n",
    "                        iou_threshold=0.45,\n",
    "                        top_k=200,\n",
    "                        nms_max_output_size=400)\n",
    "    elif height == 512:\n",
    "        model = ssd_512(image_size=(height, width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=[2, 1, 0],\n",
    "               confidence_thresh=0.5,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "    # 2: Load the trained weights into the model.\n",
    "    # TODO: Set the path of the trained weights.\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## 2. Load Images\n",
    "\n",
    "Load some images for which you'd like the model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '/home/aldopedraza/Documentos/data-cic/preprocess_data'\n",
    "path_save = path_root + '/predictions/'\n",
    "test_images_300 = np.load(path_root + '/images_test_300x300.npy')\n",
    "test_images_512 = np.load(path_root + '/images_test_512x512.npy')\n",
    "images_all_300 = np.load(path_root + '/images_all_300x300.npy')\n",
    "images_all_512 = np.load(path_root + '/images_all_512x512.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath1 = '../weights/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.h5'\n",
    "modelpath2 = '../weights/VGG_VOC0712Plus_SSD_512x512_ft_iter_160000.h5'\n",
    "\n",
    "# Pascal voc path models\n",
    "model_pascal_voc_07_12_300x300 = '../weights/pascal_voc/pascal_voc_07_12_300x300.h5'\n",
    "model_pascal_voc_07_12_512x512 = '../weights/pascal_voc/pascal_voc_07_12_512x512.h5'\n",
    "model_pascal_voc_07_plus_12_300x300 = '../weights/pascal_voc/pascal_voc_07_plus_12_300x300.h5'\n",
    "model_pascal_voc_07_plus_12_512x512 = '../weights/pascal_voc/pascal_voc_07_plus_12_512x512.h5'\n",
    "model_pascal_voc_07_12_coco_300x300 = '../weights/pascal_voc/pascal_voc_07_12_coco_300x300.h5'\n",
    "model_pascal_voc_07_12_coco_512x512 = '../weights/pascal_voc/pascal_voc_07_12_coco_512x512.h5'\n",
    "model_pascal_voc_07_plus_12_coco_300x300 = '../weights/pascal_voc/pascal_voc_07_plus_12_coco_300x300.h5'\n",
    "model_pascal_voc_07_plus_12_coco_512x512 = '../weights/pascal_voc/pascal_voc_07_plus_12_coco_512x512.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(path_model, batch_size, images_list, size_model):\n",
    "    '''\n",
    "    Make predictions from a model\n",
    "    path_model: the path to the weights' model\n",
    "    batch_size: size of the batch\n",
    "    images_list: list of images to make predictions\n",
    "    size_model: input size to the model\n",
    "    '''\n",
    "    # Create variable to store predictions\n",
    "    predictions = np.zeros(shape=(1, 200, 6))\n",
    "    \n",
    "    model = load_model(path_model, size_model, size_model)\n",
    "\n",
    "    for batch in helper.get_batch(batch_size, images_list):\n",
    "        predictions = np.append(predictions, model.predict(batch), axis=0)\n",
    "    predictions = predictions[1:] # delete empty item\n",
    "\n",
    "    clean_pre = helper.clean_predictions(predictions)\n",
    "    adjust_pre = helper.adjust_predictions(clean_pre)\n",
    "    return adjust_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions of the models\n",
    "\n",
    "# PASCAL predictions\n",
    "# 07+12\n",
    "pred_voc_07_12_300x300_test = get_predictions(model_pascal_voc_07_12_300x300, 8, test_images_300, 300)\n",
    "pred_voc_07_12_300x300_all = get_predictions(model_pascal_voc_07_12_300x300, 8, images_all_300, 300)\n",
    "pred_voc_07_12_512x512_test = get_predictions(model_pascal_voc_07_12_512x512, 4, test_images_512, 512)\n",
    "pred_voc_07_12_512x512_all = get_predictions(model_pascal_voc_07_12_512x512, 4, images_all_512, 512)\n",
    "# 07++12\n",
    "pred_voc_07_plus_12_300x300_test = get_predictions(model_pascal_voc_07_plus_12_300x300, 8, test_images_300, 300)\n",
    "pred_voc_07_plus_12_300x300_all = get_predictions(model_pascal_voc_07_plus_12_300x300, 8, images_all_300, 300)\n",
    "pred_voc_07_plus_12_512x512_test = get_predictions(model_pascal_voc_07_plus_12_512x512, 4, test_images_512, 512)\n",
    "pred_voc_07_plus_12_512x512_all = get_predictions(model_pascal_voc_07_plus_12_512x512, 4, images_all_512, 512)\n",
    "# 07+12+COCO\n",
    "pred_voc_07_12_coco_300x300_test = get_predictions(model_pascal_voc_07_12_coco_300x300, 8, test_images_300, 300)\n",
    "pred_voc_07_12_coco_300x300_all = get_predictions(model_pascal_voc_07_12_coco_300x300, 8, images_all_300, 300)\n",
    "pred_voc_07_12_coco_512x512_test = get_predictions(model_pascal_voc_07_12_coco_512x512, 4, test_images_512, 512)\n",
    "pred_voc_07_12_coco_512x512_all = get_predictions(model_pascal_voc_07_12_coco_512x512, 4, images_all_512, 512)\n",
    "# 07++12+COCO\n",
    "pred_voc_07_plus_12_coco_300x300_test = get_predictions(model_pascal_voc_07_plus_12_coco_300x300, 8, test_images_300, 300)\n",
    "pred_voc_07_plus_12_coco_300x300_all = get_predictions(model_pascal_voc_07_plus_12_coco_300x300, 8, images_all_300, 300)\n",
    "pred_voc_07_plus_12_coco_512x512_test = get_predictions(model_pascal_voc_07_plus_12_coco_512x512, 4, test_images_512, 512)\n",
    "pred_voc_07_plus_12_coco_512x512_all = get_predictions(model_pascal_voc_07_plus_12_coco_512x512, 4, images_all_512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper.show_image_bb(test_images_300[25], pred_voc_07_plus_12_coco_300x300_test[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_save + 'pred_voc_07_12_300x300_test', pred_voc_07_12_300x300_test)\n",
    "np.save(path_save + 'pred_voc_07_12_300x300_all', pred_voc_07_12_300x300_all)\n",
    "np.save(path_save + 'pred_voc_07_12_512x512_test', pred_voc_07_12_512x512_test)\n",
    "np.save(path_save + 'pred_voc_07_12_512x512_all', pred_voc_07_12_512x512_all)\n",
    "\n",
    "np.save(path_save + 'pred_voc_07_plus_12_300x300_test', pred_voc_07_plus_12_300x300_test)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_300x300_all', pred_voc_07_plus_12_300x300_all)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_512x512_test', pred_voc_07_plus_12_512x512_test)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_512x512_all', pred_voc_07_plus_12_512x512_all)\n",
    "\n",
    "np.save(path_save + 'pred_voc_07_12_coco_300x300_test', pred_voc_07_12_coco_300x300_test)\n",
    "np.save(path_save + 'pred_voc_07_12_coco_300x300_all', pred_voc_07_12_coco_300x300_all)\n",
    "np.save(path_save + 'pred_voc_07_12_coco_512x512_test', pred_voc_07_12_coco_512x512_test)\n",
    "np.save(path_save + 'pred_voc_07_12_coco_512x512_all', pred_voc_07_12_coco_512x512_all)\n",
    "\n",
    "np.save(path_save + 'pred_voc_07_plus_12_coco_300x300_test', pred_voc_07_plus_12_coco_300x300_test)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_coco_300x300_all', pred_voc_07_plus_12_coco_300x300_all)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_coco_512x512_test', pred_voc_07_plus_12_coco_512x512_test)\n",
    "np.save(path_save + 'pred_voc_07_plus_12_coco_512x512_all', pred_voc_07_plus_12_coco_512x512_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12052817892160798777\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1098317824\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15251250285342039015\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
