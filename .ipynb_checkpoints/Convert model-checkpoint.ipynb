{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldopedraza/Documentos/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = './extra_files/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, height, width):\n",
    "    # 1: Build the Keras model\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    if height == 300:\n",
    "        model = ssd_300(image_size=(height, width, 3),\n",
    "                        n_classes=20,\n",
    "                        mode='inference',\n",
    "                        l2_regularization=0.0005,\n",
    "                        scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], # The scales for MS COCO are [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "                        aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5]],\n",
    "                        two_boxes_for_ar1=True,\n",
    "                        steps=[8, 16, 32, 64, 100, 300],\n",
    "                        offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                        clip_boxes=False,\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        normalize_coords=True,\n",
    "                        subtract_mean=[123, 117, 104],\n",
    "                        swap_channels=False,\n",
    "                        confidence_thresh=0.5,\n",
    "                        iou_threshold=0.45,\n",
    "                        top_k=200,\n",
    "                        nms_max_output_size=400)\n",
    "    elif height == 512:\n",
    "        model = ssd_512(image_size=(height, width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=False,\n",
    "               confidence_thresh=0.5,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "    # 2: Load the trained weights into the model.\n",
    "    # TODO: Set the path of the trained weights.\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    '''\n",
    "    Load a frozen graph\n",
    "    frozen_grapth_filename: path in the disk\n",
    "    return: tensorflow graph\n",
    "    '''\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and weights\n",
    "model_pascal_voc_07_plus_12_300x300 = '../weights/pascal_voc/pascal_voc_07_plus_12_300x300.h5'\n",
    "model = load_model(model_pascal_voc_07_plus_12_300x300, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./extra_files/models/ssd_model.pb'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models as .pbtxt or pb\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pbtxt\", as_text=True)\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = load_graph(path_models + '/ssd_opt_model.pb')\n",
    "\n",
    "# save data from a grapth to display on tensorboard\n",
    "# tensorboard --logdir=/home/aldopedraza/Documentos/ssd/extra_files/logs\n",
    "# the path has to be absolute\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.summary.FileWriter('../logs_ssd', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for op in graph.get_operations():\n",
    "#     print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorboard import reshape as reshape\n",
    "# count = 0\n",
    "# for i in model.layers:\n",
    "#     print(count, i)\n",
    "#     count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "sess = keras.backend.get_session()\n",
    "save_path = saver.save(sess, path_models + \"/ssd_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./extra_files/models/ssd_model.ckpt\n",
      "INFO:tensorflow:Froze 71 variables.\n",
      "INFO:tensorflow:Converted 71 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "input_graph_path = path_models + '/ssd_model.pb'\n",
    "checkpoint_path = path_models + '/ssd_model.ckpt'\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = True\n",
    "output_node_names = \"predictions/concat\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_frozen_graph_name = path_models + '/ssd_frozen_model.pb'\n",
    "clear_devices = True\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          output_frozen_graph_name, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for inference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# compile graph_transforms once\n",
    "# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/\n",
    "bazel build tensorflow/tools/graph_transforms:transform_graph\n",
    "!touch WORKSPACE # bazel needs it to work\n",
    "    \n",
    "bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n",
    "--in_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_frozen_model.pb \\\n",
    "--out_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_trans_model.pb \\\n",
    "--inputs='input_1' \\\n",
    "--outputs='predictions/concat' \\\n",
    "--transforms='\n",
    "  strip_unused_nodes(type=float, shape=\"1,512,512,3\")\n",
    "  remove_nodes(op=Identity, op=CheckNumerics)\n",
    "  fold_constants(ignore_errors=true)\n",
    "  fold_batch_norms\n",
    "  fold_old_batch_norms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "--input=./extra_files/models/ssd_frozen_model.pb \\\n",
    "--output=./extra_files/models/ssd_opt_model.pb \\\n",
    "--frozen_graph=True --input_names=input_1 \\\n",
    "--output_names=predictions/concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-cd9c694a31f2>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-cd9c694a31f2>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    bazel build tensorflow/tools/graph_transforms:summarize_graph && bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=../ssd/extra_files/models/ssd_opt_model.pb\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# summary model\n",
    "# bazel build tensorflow/tools/graph_transforms:summarize_graph && \\\n",
    "bazel-bin/tensorflow/tools/graph_transforms/summarize_graph \\\n",
    "--in_graph=../ssd/extra_files/models/ssd_opt_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105440208"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_def_file = \"/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb\"\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = [\"predictions/concat\"]\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays, input_shapes={\"input_1\" : [1, 300, 300, 3]})\n",
    "tflite_model = converter.convert()\n",
    "open(\"/home/aldopedraza/Documentos/ssd/extra_files/models/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### THIS WORKS\n",
    "tflite_convert --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,512,512,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-12 17:46:52.854756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-10-12 17:46:52.855189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.531\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 1.94GiB freeMemory: 1.14GiB\n",
      "2018-10-12 17:46:52.855210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2018-10-12 17:46:53.095451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-10-12 17:46:53.095486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2018-10-12 17:46:53.095502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2018-10-12 17:46:53.095636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 872 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/bin/toco\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 401, in main\n",
      "    app.run(main=run_main, argv=sys.argv[:1])\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n",
      "    _sys.exit(main(argv))\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 397, in run_main\n",
      "    _convert_model(tflite_flags)\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 159, in _convert_model\n",
      "    output_data = converter.convert()\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\", line 439, in convert\n",
      "    **converter_kwargs)\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 309, in toco_convert_impl\n",
      "    input_data.SerializeToString())\n",
      "  File \"/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert.py\", line 109, in toco_convert_protos\n",
      "    (stdout, stderr))\n",
      "RuntimeError: TOCO failed see console for info.\n",
      "b'2018-10-12 17:47:11.553647: F tensorflow/contrib/lite/toco/toco_tooling.cc:227] Check failed: toco_flags.inference_input_type() != FLOAT (1 vs. 1)Quantized inference is not allowed with float inputs.\\nAborted (core dumped)\\n'\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !toco \\\n",
    "#   --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb \\\n",
    "#   --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite \\\n",
    "#   --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n",
    "#   --inference_type=QUANTIZED_UINT8 \\\n",
    "#   --input_shape=\"1,512,512,3\" \\\n",
    "#   --input_array=input_1 \\\n",
    "#   --output_array=predictions/concat \\\n",
    "#   --std_dev_values=127.5 --mean_value=127.5\n",
    "\n",
    "!toco \\\n",
    "--output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite \\\n",
    "--graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb \\\n",
    "--output_format=TFLITE \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--inference_input_type=FLOAT \\\n",
    "--input_arrays=input_1 \\\n",
    "--output_arrays=predictions/concat \\\n",
    "--input_shapes=1,512,512,3 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MetaGraphDef associated with tags serve could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7fd1795fdd5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"predictions/concat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTocoConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'serve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_quantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtflite_quantized_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     result = _freeze_saved_model(saved_model_dir, input_arrays, input_shapes,\n\u001b[0;32m--> 328\u001b[0;31m                                  output_arrays, tag_set, signature_key)\n\u001b[0m\u001b[1;32m    329\u001b[0m     return cls(\n\u001b[1;32m    330\u001b[0m         graph_def=result[0], input_tensors=result[1], output_tensors=result[2])\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mfreeze_saved_model\u001b[0;34m(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    237\u001b[0m   \"\"\"\n\u001b[1;32m    238\u001b[0m   \u001b[0;31m# Read SignatureDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m   \u001b[0mmeta_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_meta_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m   \u001b[0msignature_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/contrib/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36m_get_meta_graph_def\u001b[0;34m(saved_model_dir, tag_set)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \"\"\"\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m   \"\"\"\n\u001b[1;32m    192\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, sess, tags, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m       saver, _ = self.load_graph(sess.graph, tags, import_scope,\n\u001b[0;32m--> 346\u001b[0;31m                                  **saver_kwargs)\n\u001b[0m\u001b[1;32m    347\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_init_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m(self, graph, tags, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m           \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def_from_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m       return tf_saver._import_meta_graph_with_return_elements(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    245\u001b[0m       raise RuntimeError(\n\u001b[1;32m    246\u001b[0m           \u001b[0;34m\"MetaGraphDef associated with tags \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m           \u001b[0;34m\" could not be found in SavedModel. To inspect available tag-sets in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m           \u001b[0;34m\" the SavedModel, please use the SavedModel CLI: `saved_model_cli`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MetaGraphDef associated with tags serve could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "graph_def_file = '/home/aldopedraza/Documentos/ssd/extra_files/models'\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = [\"predictions/concat\"]\n",
    "\n",
    "converter=tf.contrib.lite.TocoConverter.from_saved_model(graph_def_file, tag_set='serve')\n",
    "converter.post_training_quantize=True\n",
    "tflite_quantized_model=converter.convert()\n",
    "open(\"/home/aldopedraza/Documentos/ssd/extra_files/models/quat_model.tflite\", \"wb\").write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model to see if it's compatible with tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/aldopedraza/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/ipykernel/__main__.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9316496e-01 2.0371385e-04 2.3979013e-04 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]\n",
      " [9.9452364e-01 1.7735115e-04 2.3558663e-04 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]\n",
      " [9.9433315e-01 1.8901868e-04 1.7332514e-04 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]\n",
      " ...\n",
      " [4.4124798e-05 2.7008391e-05 9.0820151e-10 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]\n",
      " [2.3393070e-04 4.1228341e-05 2.5147060e-09 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]\n",
      " [5.1122677e-01 3.2095129e-05 1.0950321e-09 ... 1.0000000e-01\n",
      "  2.0000000e-01 2.0000000e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "# Read image\n",
    "image_test = misc.imread('./image_test.jpg')\n",
    "image_test = misc.imresize(image_test, size=(300, 300))\n",
    "image_test = image_test.reshape(1, 300, 300, 3)\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path=\"/home/aldopedraza/Documentos/ssd/extra_files/models/converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(image_test, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(output_data[0][1][32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'predictions/concat',\n",
       "  'index': 152,\n",
       "  'shape': array([   1, 8732,   33], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
