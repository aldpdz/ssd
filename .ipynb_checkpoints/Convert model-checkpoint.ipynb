{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300_vgg_13_bn import ssd_300\n",
    "from models.keras_ssd512 import ssd_512\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, height, width):\n",
    "    # 1: Build the Keras model\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    if height == 300:\n",
    "        model = ssd_300(image_size=(height, width, 3),\n",
    "                        n_classes=1,\n",
    "                        mode='inference',\n",
    "                        l2_regularization=0.0005,\n",
    "                        scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],\n",
    "                        aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                                 [1.0, 2.0, 0.5],\n",
    "                                                 [1.0, 2.0, 0.5]],\n",
    "                        two_boxes_for_ar1=True,\n",
    "                        steps=[8, 16, 32, 64, 100, 300],\n",
    "                        offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                        clip_boxes=False,\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        normalize_coords=True,\n",
    "                        subtract_mean=[123, 117, 104],\n",
    "                        swap_channels=False,\n",
    "                        confidence_thresh=0.20,\n",
    "                        iou_threshold=0.45,\n",
    "                        top_k=200,\n",
    "                        nms_max_output_size=400)\n",
    "    elif height == 512:\n",
    "        model = ssd_512(image_size=(height, width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "               steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "               offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               clip_boxes=False,\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               normalize_coords=True,\n",
    "               subtract_mean=[123, 117, 104],\n",
    "               swap_channels=False,\n",
    "               confidence_thresh=0.15,\n",
    "               iou_threshold=0.45,\n",
    "               top_k=200,\n",
    "               nms_max_output_size=400)\n",
    "\n",
    "    # 2: Load the trained weights into the model.\n",
    "    # TODO: Set the path of the trained weights.\n",
    "    model.load_weights(model_path, by_name=True)\n",
    "\n",
    "    # 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    '''\n",
    "    Load a frozen graph\n",
    "    frozen_grapth_filename: path in the disk\n",
    "    return: tensorflow graph\n",
    "    '''\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph\n",
    "\n",
    "def save_graph(name):\n",
    "    '''\n",
    "    Save grapth to load with tensorboard\n",
    "    '''\n",
    "    graph = load_graph(name)\n",
    "\n",
    "    # save data from a grapth to display on tensorboard\n",
    "    # tensorboard --logdir=wholepath\n",
    "    # the path has to be absolute\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        tf.summary.FileWriter('../logs_ssd', sess.graph)\n",
    "\n",
    "def show_operations_graph(graph):\n",
    "    '''\n",
    "    Print operations contained in a graph\n",
    "    '''\n",
    "    for op in graph.get_operations():\n",
    "        print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and weights\n",
    "# model_pascal_voc_07_plus_12_300x300 = '../weights/pascal_voc/pascal_voc_07_12_coco_300x300.h5'\n",
    "# model = load_model(model_pascal_voc_07_plus_12_300x300, 300, 300)\n",
    "model_pascal_voc_07_12_coco_300x300 = '../weights/models/ssd300_adam_vgg13_bn/ssd300_vgg_13_bn_pascal_cic_epoch-66_loss-2.3027_val_loss-2.5576.h5'\n",
    "model = load_model(model_pascal_voc_07_12_coco_300x300, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_model.pb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models as .pbtxt or pb\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pbtxt\", as_text=True)\n",
    "tf.train.write_graph(K.get_session().graph, path_models, \"ssd_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph(path_models + '/ssd_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "sess = keras.backend.get_session()\n",
    "save_path = saver.save(sess, path_models + \"/ssd_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the Graph\n",
    "In order to convert the graph to tflite we need to freeze it, in this case we'll use the tools provided by tensorflow to do so.\n",
    "\n",
    "We need to specify the graph, the checkpoints, the output name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_model.ckpt\n",
      "INFO:tensorflow:Froze 105 variables.\n",
      "INFO:tensorflow:Converted 105 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "input_graph_path = path_models + '/ssd_model.pb'\n",
    "checkpoint_path = path_models + '/ssd_model.ckpt'\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = True\n",
    "output_node_names = \"decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_frozen_graph_name = path_models + '/ssd_frozen_model.pb'\n",
    "clear_devices = True\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          output_frozen_graph_name, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_model.ckpt\n",
      "INFO:tensorflow:Froze 105 variables.\n",
      "INFO:tensorflow:Converted 105 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "input_graph_path = path_models + '/ssd_model.pb'\n",
    "checkpoint_path = path_models + '/ssd_model.ckpt'\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = True\n",
    "output_node_names = \"decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3\"\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_frozen_graph_name = path_models + '/ssd_frozen_model.pb'\n",
    "clear_devices = True\n",
    "\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          output_frozen_graph_name, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for inference\n",
    "\n",
    "Optimize for inference will help us to remove those parts of the graph that were used during training.\n",
    "\n",
    "We need the input and output names and the frozen model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# compile graph_transforms once\n",
    "# https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/\n",
    "bazel build tensorflow/tools/graph_transforms:transform_graph\n",
    "!touch WORKSPACE # bazel needs it to work\n",
    "    \n",
    "bazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\n",
    "--in_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_frozen_model.pb \\\n",
    "--out_graph=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_trans_model.pb \\\n",
    "--inputs='input_1' \\\n",
    "--outputs='predictions/concat' \\\n",
    "--transforms='\n",
    "  strip_unused_nodes(type=float, shape=\"1,512,512,3\")\n",
    "  remove_nodes(op=Identity, op=CheckNumerics)\n",
    "  fold_constants(ignore_errors=true)\n",
    "  fold_batch_norms\n",
    "  fold_old_batch_norms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "--input=./extra_files/models/ssd_frozen_model.pb \\\n",
    "--output=./extra_files/models/ssd_opt_model.pb \\\n",
    "--frozen_graph=True --input_names=input_1 \\\n",
    "--output_names=predictions/concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_1/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_1/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_2/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_2/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_3/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_3/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_4/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_4/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_5/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_5/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_6/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_6/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_7/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_7/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_8/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_8/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_9/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_9/cond/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_10/FusedBatchNorm'\r\n",
      "WARNING:tensorflow:Didn't find expected Conv2D input to 'batch_normalization_10/cond/FusedBatchNorm'\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tensorflow.python.tools.optimize_for_inference \\\n",
    "--input=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_frozen_model.pb \\\n",
    "--output=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_opt_model.pb \\\n",
    "--frozen_graph=True --input_names=input_1 \\\n",
    "--output_names=predictions/concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary model\n",
    "# bazel build tensorflow/tools/graph_transforms:summarize_graph && \\\n",
    "# bazel-bin/tensorflow/tools/graph_transforms/summarize_graph \\\n",
    "# --in_graph=../ssd/extra_files/models/ssd_opt_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to tflite model\n",
    "Finally we conver the model to tflite format, we need a frozen model in the same way the input and output name are required, and all the operations in the model need to be conpatible with tflite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_def_file = \"/home/aldopedraza/Documentos/models/ssd_frozen_model.pb\"\n",
    "input_arrays = [\"input_1\"]\n",
    "output_arrays = [\"decoded_predictions/loop_over_batch/TensorArrayStack/TensorArrayGatherV3\"]\n",
    "\n",
    "converter = tf.contrib.lite.TocoConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays, input_shapes={\"input_1\" : [1, 300, 300, 3]})\n",
    "tflite_model = converter.convert()\n",
    "open(\"/home/aldopedraza/Documentos/models/converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### THIS WORKS\n",
    "tflite_convert --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,512,512,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !toco \\\n",
    "#   --graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb \\\n",
    "#   --output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite \\\n",
    "#   --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n",
    "#   --inference_type=QUANTIZED_UINT8 \\\n",
    "#   --input_shape=\"1,512,512,3\" \\\n",
    "#   --input_array=input_1 \\\n",
    "#   --output_array=predictions/concat \\\n",
    "#   --std_dev_values=127.5 --mean_value=127.5\n",
    "\n",
    "!toco \\\n",
    "--output_file=/home/aldopedraza/Documentos/ssd/extra_files/models/tflite_model.tflite \\\n",
    "--graph_def_file=/home/aldopedraza/Documentos/ssd/extra_files/models/ssd_opt_model.pb \\\n",
    "--output_format=TFLITE \\\n",
    "--inference_type=QUANTIZED_UINT8 \\\n",
    "--inference_input_type=FLOAT \\\n",
    "--input_arrays=input_1 \\\n",
    "--output_arrays=predictions/concat \\\n",
    "--input_shapes=1,512,512,3 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-12 16:47:46.879605: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-02-12 16:47:46.979460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-02-12 16:47:46.979884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 7.92GiB freeMemory: 6.83GiB\n",
      "2019-02-12 16:47:46.979899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
      "2019-02-12 16:47:47.159562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-02-12 16:47:47.159594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
      "2019-02-12 16:47:47.159602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
      "2019-02-12 16:47:47.159733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6577 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "### THIS WORKS\n",
    "!tflite_convert --output_file=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/tflite_vgg13_bn.tflite --graph_def_file=/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/ssd_opt_model.pb --input_arrays=input_1 --output_arrays=predictions/concat --input_shapes=1,300,300,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model to see if it's compatible with tflite\n",
    "\n",
    "In order to be sure that the model works correctly what we can do it's to use the interpreter to load the model and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n",
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  import sys\n",
      "/home/aldo/anaconda3/envs/test2/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97709185  0.02290815 -0.33178067 ...  0.1         0.2\n",
      "   0.2       ]\n",
      " [ 0.9887371   0.01126288 -0.4059725  ...  0.1         0.2\n",
      "   0.2       ]\n",
      " [ 0.94732344  0.05267651  0.0720466  ...  0.1         0.2\n",
      "   0.2       ]\n",
      " ...\n",
      " [ 0.97145116  0.02854885  0.08363865 ...  0.1         0.2\n",
      "   0.2       ]\n",
      " [ 0.96050304  0.03949701  0.12800285 ...  0.1         0.2\n",
      "   0.2       ]\n",
      " [ 0.97190845  0.02809148  0.05742138 ...  0.1         0.2\n",
      "   0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "\n",
    "# Read image\n",
    "image_test = misc.imread('./image_test.jpg')\n",
    "image_test = misc.imresize(image_test, size=(300, 300))\n",
    "misc.imsave('./resize_image.jpg', image_test)\n",
    "image_test = image_test.reshape(1, 300, 300, 3)\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path=\"/home/aldopedraza/Documentos/ssd/extra_files/models/converted_model.tflite\")\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path=\"../models/converted_model.tflite\")\n",
    "# interpreter = tf.contrib.lite.Interpreter(model_path=\"/home/aldo/Downloads/prueba/tflite_model.tflite\")\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path='/home/aldo/Documents/data-cic/tflite_models/vgg_13_bn/tflite_vgg13_bn.tflite')\n",
    "\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(image_test, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
