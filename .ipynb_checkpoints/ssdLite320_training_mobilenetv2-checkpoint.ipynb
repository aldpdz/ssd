{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSDLite300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssdlite320_mobilenetv2 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 320 # Height of the model input images\n",
    "img_width = 320 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [-1., -1., -1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = new_scales\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 32, 64, 107, 160, 320] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "\n",
    "# TODO: Set the path to the weights you want to load.\n",
    "# weights_path = '../weights/models/ssdlite320_mobilenetv1/ssdlite320_mobilenetv1_pascal.h5'\n",
    "# model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 320, 320, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 320, 320, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 320, 320, 3)  0           input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             558656      input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_expand (Conv2D)     (None, 20, 20, 576)  55296       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_expand (BatchNorma (None, 20, 20, 576)  2304        mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 20, 20, 576)  0           bn13_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_depthwise (Depthwis (None, 20, 20, 576)  5184        conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_depthwise (BatchNorma (None, 20, 20, 576)  2304        mobl13_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 20, 20, 576)  0           bn13_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_project (Conv2D)    (None, 20, 20, 160)  92160       conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_project (BatchNorm (None, 20, 20, 160)  640         mobl13_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_expand (Conv2D)     (None, 20, 20, 960)  153600      bn13_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_expand (BatchNorma (None, 20, 20, 960)  3840        mobl14_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu (Activation)       (None, 20, 20, 960)  0           bn14_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_depthwise (Depthwis (None, 20, 20, 960)  8640        conv_14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_depthwise (BatchNorma (None, 20, 20, 960)  3840        mobl14_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_relu (Activation)    (None, 20, 20, 960)  0           bn14_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_project (Conv2D)    (None, 20, 20, 160)  153600      conv_dw_14_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_project (BatchNorm (None, 20, 20, 160)  640         mobl14_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_14 (Add)            (None, 20, 20, 160)  0           bn13_conv_bn_project[0][0]       \n",
      "                                                                 bn14_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_expand (Conv2D)     (None, 20, 20, 960)  153600      res_connect_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_expand (BatchNorma (None, 20, 20, 960)  3840        mobl15_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu (Activation)       (None, 20, 20, 960)  0           bn15_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_depthwise (Depthwis (None, 20, 20, 960)  8640        conv_15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_depthwise (BatchNorma (None, 20, 20, 960)  3840        mobl15_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_relu (Activation)    (None, 20, 20, 960)  0           bn15_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_project (Conv2D)    (None, 20, 20, 160)  153600      conv_dw_15_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_project (BatchNorm (None, 20, 20, 160)  640         mobl15_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_15 (Add)            (None, 20, 20, 160)  0           res_connect_14[0][0]             \n",
      "                                                                 bn15_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_expand (Conv2D)     (None, 20, 20, 960)  153600      res_connect_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_expand (BatchNorma (None, 20, 20, 960)  3840        mobl16_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu (Activation)       (None, 20, 20, 960)  0           bn16_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_depthwise (Depthwis (None, 20, 20, 960)  8640        conv_16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_depthwise (BatchNorma (None, 20, 20, 960)  3840        mobl16_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16_relu (Activation)    (None, 20, 20, 960)  0           bn16_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_project (Conv2D)    (None, 20, 20, 320)  307200      conv_dw_16_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_project (BatchNorm (None, 20, 20, 320)  1280        mobl16_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 10, 10, 1280) 409600      bn16_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 10, 10, 1280) 5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_relu (Activation)        (None, 10, 10, 1280) 0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv1 (Conv2D)             (None, 10, 10, 256)  327680      Conv_1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv1_bn (BatchNormalizati (None, 10, 10, 256)  1024        18_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv1_act (Activation)     (None, 10, 10, 256)  0           18_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "18_dwconv2 (DepthwiseConv2D)    (None, 5, 5, 256)    2304        18_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "18_sepconv2_bn (BatchNormalizat (None, 5, 5, 256)    1024        18_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "18_sepconv2_act (Activation)    (None, 5, 5, 256)    0           18_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv3 (Conv2D)             (None, 5, 5, 512)    131072      18_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv3_bn (BatchNormalizati (None, 5, 5, 512)    2048        18_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "18_pwconv3_act (Activation)     (None, 5, 5, 512)    0           18_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv1 (Conv2D)             (None, 5, 5, 128)    65536       18_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv1_bn (BatchNormalizati (None, 5, 5, 128)    512         19_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv1_act (Activation)     (None, 5, 5, 128)    0           19_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "19_dwconv2 (DepthwiseConv2D)    (None, 3, 3, 128)    1152        19_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "19_sepconv2_bn (BatchNormalizat (None, 3, 3, 128)    512         19_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "19_sepconv2_act (Activation)    (None, 3, 3, 128)    0           19_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv3 (Conv2D)             (None, 3, 3, 256)    32768       19_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv3_bn (BatchNormalizati (None, 3, 3, 256)    1024        19_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "19_pwconv3_act (Activation)     (None, 3, 3, 256)    0           19_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv1 (Conv2D)             (None, 3, 3, 128)    32768       19_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv1_bn (BatchNormalizati (None, 3, 3, 128)    512         20_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv1_act (Activation)     (None, 3, 3, 128)    0           20_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "20_dwconv2 (DepthwiseConv2D)    (None, 2, 2, 128)    1152        20_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "20_sepconv2_bn (BatchNormalizat (None, 2, 2, 128)    512         20_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "20_sepconv2_act (Activation)    (None, 2, 2, 128)    0           20_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv3 (Conv2D)             (None, 2, 2, 256)    32768       20_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv3_bn (BatchNormalizati (None, 2, 2, 256)    1024        20_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "20_pwconv3_act (Activation)     (None, 2, 2, 256)    0           20_pwconv3_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "21_pwconv1 (Conv2D)             (None, 2, 2, 64)     16384       20_pwconv3_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "21_pwconv1_bn (BatchNormalizati (None, 2, 2, 64)     256         21_pwconv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "21_pwconv1_act (Activation)     (None, 2, 2, 64)     0           21_pwconv1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "21_dwconv2 (DepthwiseConv2D)    (None, 1, 1, 64)     576         21_pwconv1_act[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "21_sepconv2_bn (BatchNormalizat (None, 1, 1, 64)     256         21_dwconv2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "21_sepconv2_act (Activation)    (None, 1, 1, 64)     0           21_sepconv2_bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "21_pwconv3 (Conv2D)             (None, 1, 1, 128)    8192        21_sepconv2_act[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 20, 20, 8)    41480       mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf (Conv2D)       (None, 10, 10, 12)   138252      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_conf (Conv2D)     (None, 5, 5, 12)     55308       18_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_conf (Conv2D)     (None, 3, 3, 12)     27660       19_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_conf (Conv2D)     (None, 2, 2, 8)      18440       20_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_conf (Conv2D)     (None, 1, 1, 8)      9224        21_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 20, 20, 16)   82960       mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc (Conv2D)        (None, 10, 10, 24)   276504      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_loc (Conv2D)      (None, 5, 5, 24)     110616      18_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_loc (Conv2D)      (None, 3, 3, 24)     55320       19_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_loc (Conv2D)      (None, 2, 2, 16)     36880       20_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_loc (Conv2D)      (None, 1, 1, 16)     18448       21_pwconv3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1600, 2)      0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 600, 2)       0           conv17_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 150, 2)       0           conv18_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 54, 2)        0           conv19_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 16, 2)        0           conv20_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 4, 2)         0           conv21_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 20, 20, 4, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox (AnchorBox (None, 10, 10, 6, 8) 0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox (AnchorB (None, 5, 5, 6, 8)   0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox (AnchorB (None, 3, 3, 6, 8)   0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox (AnchorB (None, 2, 2, 4, 8)   0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox (AnchorB (None, 1, 1, 4, 8)   0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 2424, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1600, 4)      0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 600, 4)       0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 150, 4)       0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 54, 4)        0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 16, 4)        0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 4, 4)         0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 1600, 8)      0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox_reshape (R (None, 600, 8)       0           conv17_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox_reshape  (None, 150, 8)       0           conv18_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox_reshape  (None, 54, 8)        0           conv19_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox_reshape  (None, 16, 8)        0           conv20_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox_reshape  (None, 4, 8)         0           conv21_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 2424, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 2424, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 2424, 8)      0           conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv17_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv18_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv19_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv20_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv21_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2424, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,790,132\n",
      "Trainable params: 3,751,668\n",
      "Non-trainable params: 38,464\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:25<00:00, 253.46it/s]\n",
      "Loading images into memory: 100%|██████████| 2097/2097 [00:08<00:00, 260.88it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "images_dir = data_path + 'pascal_dataset'\n",
    "# images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val_320.npy')\n",
    "val_images_320 = np.load('../data-cic/preprocess_data/images_val_320x320.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=12,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_320, \n",
    "                      label_val, (1, 2424, 14),\n",
    "                      data_path + 'history/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_f1.csv')\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "#              learning_rate_scheduler]\n",
    "             reduce_learning_rate,\n",
    "             f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "400/400 [==============================] - 229s 573ms/step - loss: 5.6792 - val_loss: 4.5497\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.54973, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.2355\n",
      "Recall: 0.3721\n",
      "F1 score: 0.2885\n",
      "Improve F1 score from -inf to 0.2884544922710439\n",
      "Epoch 2/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 4.3143 - val_loss: 5.6021\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.54973\n",
      "Number of images: 45\n",
      "Presicion: 0.1656\n",
      "Recall: 0.4336\n",
      "F1 score: 0.2396\n",
      "Epoch 3/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 3.8307 - val_loss: 4.6025\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.54973\n",
      "Number of images: 45\n",
      "Presicion: 0.3395\n",
      "Recall: 0.384\n",
      "F1 score: 0.3604\n",
      "Improve F1 score from 0.2884544922710439 to 0.3603616046773314\n",
      "Epoch 4/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.6705 - val_loss: 4.3167\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.54973 to 4.31665, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.3908\n",
      "Recall: 0.3367\n",
      "F1 score: 0.3617\n",
      "Improve F1 score from 0.3603616046773314 to 0.3617318276378365\n",
      "Epoch 5/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.5623 - val_loss: 3.6007\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.31665 to 3.60068, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.4164\n",
      "Recall: 0.2802\n",
      "F1 score: 0.335\n",
      "Epoch 6/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 3.7668 - val_loss: 5.7086\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.60068\n",
      "Number of images: 45\n",
      "Presicion: 0.0524\n",
      "Recall: 0.4611\n",
      "F1 score: 0.0941\n",
      "Epoch 7/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.5491 - val_loss: 3.7828\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.60068\n",
      "Number of images: 45\n",
      "Presicion: 0.2626\n",
      "Recall: 0.3016\n",
      "F1 score: 0.2807\n",
      "Epoch 8/1000\n",
      "400/400 [==============================] - 222s 555ms/step - loss: 3.4575 - val_loss: 3.6281\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.60068\n",
      "Number of images: 45\n",
      "Presicion: 0.4448\n",
      "Recall: 0.309\n",
      "F1 score: 0.3647\n",
      "Improve F1 score from 0.3617318276378365 to 0.3646927851726941\n",
      "Epoch 9/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 3.3967 - val_loss: 3.7161\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.60068\n",
      "Number of images: 45\n",
      "Presicion: 0.326\n",
      "Recall: 0.2713\n",
      "F1 score: 0.2961\n",
      "Epoch 10/1000\n",
      "400/400 [==============================] - 219s 549ms/step - loss: 3.3595 - val_loss: 3.5887\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.60068 to 3.58865, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5492\n",
      "Recall: 0.2945\n",
      "F1 score: 0.3834\n",
      "Improve F1 score from 0.3646927851726941 to 0.38337282235760883\n",
      "Epoch 11/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 3.3345 - val_loss: 3.4840\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.58865 to 3.48404, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5435\n",
      "Recall: 0.2161\n",
      "F1 score: 0.3092\n",
      "Epoch 12/1000\n",
      "400/400 [==============================] - 223s 557ms/step - loss: 3.2719 - val_loss: 3.7101\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.48404\n",
      "Number of images: 45\n",
      "Presicion: 0.5307\n",
      "Recall: 0.2346\n",
      "F1 score: 0.3253\n",
      "Epoch 13/1000\n",
      "400/400 [==============================] - 222s 554ms/step - loss: 3.2689 - val_loss: 3.4546\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.48404 to 3.45460, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5115\n",
      "Recall: 0.303\n",
      "F1 score: 0.3806\n",
      "Epoch 14/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.2494 - val_loss: 3.5304\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.45460\n",
      "Number of images: 45\n",
      "Presicion: 0.5207\n",
      "Recall: 0.2242\n",
      "F1 score: 0.3134\n",
      "Epoch 15/1000\n",
      "400/400 [==============================] - 221s 554ms/step - loss: 3.2095 - val_loss: 3.2703\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.45460 to 3.27035, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.464\n",
      "Recall: 0.4174\n",
      "F1 score: 0.4395\n",
      "Improve F1 score from 0.38337282235760883 to 0.4394698832456341\n",
      "Epoch 16/1000\n",
      "400/400 [==============================] - 220s 551ms/step - loss: 3.1974 - val_loss: 3.2948\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.27035\n",
      "Number of images: 45\n",
      "Presicion: 0.4725\n",
      "Recall: 0.3688\n",
      "F1 score: 0.4143\n",
      "Epoch 17/1000\n",
      "400/400 [==============================] - 222s 554ms/step - loss: 3.1586 - val_loss: 3.2759\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.27035\n",
      "Number of images: 45\n",
      "Presicion: 0.4543\n",
      "Recall: 0.4205\n",
      "F1 score: 0.4367\n",
      "Epoch 18/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 3.1735 - val_loss: 3.5140\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.27035\n",
      "Number of images: 45\n",
      "Presicion: 0.4622\n",
      "Recall: 0.3752\n",
      "F1 score: 0.4142\n",
      "Epoch 19/1000\n",
      "400/400 [==============================] - 219s 549ms/step - loss: 3.1530 - val_loss: 3.3077\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.27035\n",
      "Number of images: 45\n",
      "Presicion: 0.4434\n",
      "Recall: 0.3818\n",
      "F1 score: 0.4103\n",
      "Epoch 20/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.1466 - val_loss: 3.2547\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.27035 to 3.25474, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.4419\n",
      "Recall: 0.4116\n",
      "F1 score: 0.4262\n",
      "Epoch 21/1000\n",
      "400/400 [==============================] - 222s 555ms/step - loss: 3.1185 - val_loss: 3.1938\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.25474 to 3.19382, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5632\n",
      "Recall: 0.3285\n",
      "F1 score: 0.415\n",
      "Epoch 22/1000\n",
      "400/400 [==============================] - 222s 554ms/step - loss: 3.0792 - val_loss: 3.3585\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.3718\n",
      "Recall: 0.2992\n",
      "F1 score: 0.3316\n",
      "Epoch 23/1000\n",
      "400/400 [==============================] - 223s 557ms/step - loss: 3.0917 - val_loss: 3.2992\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.531\n",
      "Recall: 0.28\n",
      "F1 score: 0.3666\n",
      "Epoch 24/1000\n",
      "400/400 [==============================] - 223s 557ms/step - loss: 3.0830 - val_loss: 3.4306\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.4658\n",
      "Recall: 0.3194\n",
      "F1 score: 0.379\n",
      "Epoch 25/1000\n",
      "400/400 [==============================] - 220s 550ms/step - loss: 3.0364 - val_loss: 3.2264\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.5382\n",
      "Recall: 0.3542\n",
      "F1 score: 0.4272\n",
      "Epoch 26/1000\n",
      "400/400 [==============================] - 221s 551ms/step - loss: 3.0243 - val_loss: 3.3030\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.5871\n",
      "Recall: 0.279\n",
      "F1 score: 0.3782\n",
      "Epoch 27/1000\n",
      "400/400 [==============================] - 221s 553ms/step - loss: 3.0187 - val_loss: 3.2537\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.19382\n",
      "Number of images: 45\n",
      "Presicion: 0.5944\n",
      "Recall: 0.2528\n",
      "F1 score: 0.3547\n",
      "Epoch 28/1000\n",
      "400/400 [==============================] - 224s 559ms/step - loss: 3.0374 - val_loss: 3.0175\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.19382 to 3.01753, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5811\n",
      "Recall: 0.3461\n",
      "F1 score: 0.4338\n",
      "Epoch 29/1000\n",
      "400/400 [==============================] - 222s 556ms/step - loss: 2.9927 - val_loss: 3.0391\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.53\n",
      "Recall: 0.3857\n",
      "F1 score: 0.4465\n",
      "Improve F1 score from 0.4394698832456341 to 0.44646350453412564\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 219s 548ms/step - loss: 2.9924 - val_loss: 3.0219\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.5192\n",
      "Recall: 0.3454\n",
      "F1 score: 0.4148\n",
      "Epoch 31/1000\n",
      "400/400 [==============================] - 220s 550ms/step - loss: 2.9774 - val_loss: 3.1560\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.4692\n",
      "Recall: 0.4026\n",
      "F1 score: 0.4334\n",
      "Epoch 32/1000\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 2.9821 - val_loss: 3.4688\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.4384\n",
      "Recall: 0.2738\n",
      "F1 score: 0.3371\n",
      "Epoch 33/1000\n",
      "400/400 [==============================] - 224s 561ms/step - loss: 2.9522 - val_loss: 3.2251\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.5274\n",
      "Recall: 0.3918\n",
      "F1 score: 0.4496\n",
      "Improve F1 score from 0.44646350453412564 to 0.44959720659224206\n",
      "Epoch 34/1000\n",
      "400/400 [==============================] - 222s 554ms/step - loss: 2.9481 - val_loss: 3.3351\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.3729\n",
      "Recall: 0.3954\n",
      "F1 score: 0.3838\n",
      "Epoch 35/1000\n",
      "400/400 [==============================] - 222s 555ms/step - loss: 2.9321 - val_loss: 3.1595\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.4784\n",
      "Recall: 0.4002\n",
      "F1 score: 0.4358\n",
      "Epoch 36/1000\n",
      "400/400 [==============================] - 223s 558ms/step - loss: 3.0666 - val_loss: 3.5370\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.5501\n",
      "Recall: 0.2897\n",
      "F1 score: 0.3796\n",
      "Epoch 37/1000\n",
      "400/400 [==============================] - 224s 560ms/step - loss: 2.9490 - val_loss: 3.2190\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.01753\n",
      "Number of images: 45\n",
      "Presicion: 0.4597\n",
      "Recall: 0.3606\n",
      "F1 score: 0.4042\n",
      "Epoch 38/1000\n",
      "400/400 [==============================] - 222s 556ms/step - loss: 2.9227 - val_loss: 3.0750\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.01753\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Number of images: 45\n",
      "Presicion: 0.4958\n",
      "Recall: 0.3715\n",
      "F1 score: 0.4247\n",
      "Epoch 39/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.7917 - val_loss: 2.8739\n",
      "\n",
      "Epoch 00039: val_loss improved from 3.01753 to 2.87394, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5104\n",
      "Recall: 0.3862\n",
      "F1 score: 0.4397\n",
      "Epoch 40/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7658 - val_loss: 2.8324\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.87394 to 2.83235, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5633\n",
      "Recall: 0.3944\n",
      "F1 score: 0.4639\n",
      "Improve F1 score from 0.44959720659224206 to 0.4639345700701157\n",
      "Epoch 41/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.7523 - val_loss: 2.7409\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.83235 to 2.74092, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5778\n",
      "Recall: 0.4035\n",
      "F1 score: 0.4752\n",
      "Improve F1 score from 0.4639345700701157 to 0.47518729704223633\n",
      "Epoch 42/1000\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.7309 - val_loss: 2.7308\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.74092 to 2.73084, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5967\n",
      "Recall: 0.4702\n",
      "F1 score: 0.5259\n",
      "Improve F1 score from 0.47518729704223633 to 0.5259422385634808\n",
      "Epoch 43/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.7066 - val_loss: 2.7814\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5048\n",
      "Recall: 0.4685\n",
      "F1 score: 0.486\n",
      "Epoch 44/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7305 - val_loss: 2.8217\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.4912\n",
      "Recall: 0.4433\n",
      "F1 score: 0.466\n",
      "Epoch 45/1000\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.7009 - val_loss: 2.7996\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5523\n",
      "Recall: 0.4496\n",
      "F1 score: 0.4957\n",
      "Epoch 46/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6836 - val_loss: 2.7601\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5502\n",
      "Recall: 0.4656\n",
      "F1 score: 0.5044\n",
      "Epoch 47/1000\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 2.6757 - val_loss: 2.7622\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.6055\n",
      "Recall: 0.426\n",
      "F1 score: 0.5001\n",
      "Epoch 48/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7028 - val_loss: 2.7643\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5973\n",
      "Recall: 0.4777\n",
      "F1 score: 0.5308\n",
      "Improve F1 score from 0.5259422385634808 to 0.5308118833880706\n",
      "Epoch 49/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6733 - val_loss: 2.7808\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5942\n",
      "Recall: 0.3959\n",
      "F1 score: 0.4752\n",
      "Epoch 50/1000\n",
      "400/400 [==============================] - 219s 546ms/step - loss: 2.7048 - val_loss: 2.7938\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.5694\n",
      "Recall: 0.415\n",
      "F1 score: 0.4801\n",
      "Epoch 51/1000\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 2.6608 - val_loss: 2.8579\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.73084\n",
      "Number of images: 45\n",
      "Presicion: 0.6076\n",
      "Recall: 0.4077\n",
      "F1 score: 0.488\n",
      "Epoch 52/1000\n",
      "400/400 [==============================] - 217s 544ms/step - loss: 2.6862 - val_loss: 2.8530\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.73084\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Number of images: 45\n",
      "Presicion: 0.5985\n",
      "Recall: 0.3917\n",
      "F1 score: 0.4735\n",
      "Epoch 53/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6033 - val_loss: 2.6903\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.73084 to 2.69028, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6082\n",
      "Recall: 0.4384\n",
      "F1 score: 0.5095\n",
      "Epoch 54/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.5711 - val_loss: 2.6865\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.69028 to 2.68646, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5803\n",
      "Recall: 0.4775\n",
      "F1 score: 0.5239\n",
      "Epoch 55/1000\n",
      "400/400 [==============================] - 215s 539ms/step - loss: 2.5784 - val_loss: 2.6551\n",
      "\n",
      "Epoch 00055: val_loss improved from 2.68646 to 2.65507, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6047\n",
      "Recall: 0.4482\n",
      "F1 score: 0.5149\n",
      "Epoch 56/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.5512 - val_loss: 2.6461\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.65507 to 2.64611, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.611\n",
      "Recall: 0.4308\n",
      "F1 score: 0.5053\n",
      "Epoch 57/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.5699 - val_loss: 2.6412\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.64611 to 2.64125, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6069\n",
      "Recall: 0.442\n",
      "F1 score: 0.5115\n",
      "Epoch 58/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.5432 - val_loss: 2.6509\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.64125\n",
      "Number of images: 45\n",
      "Presicion: 0.6169\n",
      "Recall: 0.4297\n",
      "F1 score: 0.5065\n",
      "Epoch 59/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.5557 - val_loss: 2.6381\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.64125 to 2.63811, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6095\n",
      "Recall: 0.4522\n",
      "F1 score: 0.5192\n",
      "Epoch 60/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.5520 - val_loss: 2.6641\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.5888\n",
      "Recall: 0.4708\n",
      "F1 score: 0.5232\n",
      "Epoch 61/1000\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.5468 - val_loss: 2.6854\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.6021\n",
      "Recall: 0.4456\n",
      "F1 score: 0.5122\n",
      "Epoch 62/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.5219 - val_loss: 2.6635\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.6242\n",
      "Recall: 0.4398\n",
      "F1 score: 0.516\n",
      "Epoch 63/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.5418 - val_loss: 2.6585\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.6245\n",
      "Recall: 0.4149\n",
      "F1 score: 0.4986\n",
      "Epoch 64/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.5354 - val_loss: 2.6625\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.5975\n",
      "Recall: 0.4422\n",
      "F1 score: 0.5083\n",
      "Epoch 65/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.5215 - val_loss: 2.6612\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.63811\n",
      "Number of images: 45\n",
      "Presicion: 0.6251\n",
      "Recall: 0.4322\n",
      "F1 score: 0.5111\n",
      "Epoch 66/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.5407 - val_loss: 2.6339\n",
      "\n",
      "Epoch 00066: val_loss improved from 2.63811 to 2.63387, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6144\n",
      "Recall: 0.4417\n",
      "F1 score: 0.5139\n",
      "Epoch 67/1000\n",
      "400/400 [==============================] - 217s 541ms/step - loss: 2.5050 - val_loss: 2.6676\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.5901\n",
      "Recall: 0.4521\n",
      "F1 score: 0.512\n",
      "Epoch 68/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.5128 - val_loss: 2.6552\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.5827\n",
      "Recall: 0.4449\n",
      "F1 score: 0.5045\n",
      "Epoch 69/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.5100 - val_loss: 2.6392\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.5979\n",
      "Recall: 0.4548\n",
      "F1 score: 0.5166\n",
      "Epoch 70/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.5224 - val_loss: 2.6952\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.5883\n",
      "Recall: 0.4592\n",
      "F1 score: 0.5158\n",
      "Epoch 71/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.5344 - val_loss: 2.6517\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.6057\n",
      "Recall: 0.4419\n",
      "F1 score: 0.511\n",
      "Epoch 72/1000\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.4845 - val_loss: 2.6683\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.6068\n",
      "Recall: 0.4386\n",
      "F1 score: 0.5092\n",
      "Epoch 73/1000\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 2.5006 - val_loss: 2.6448\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.63387\n",
      "Number of images: 45\n",
      "Presicion: 0.608\n",
      "Recall: 0.4504\n",
      "F1 score: 0.5175\n",
      "Epoch 74/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.4805 - val_loss: 2.6285\n",
      "\n",
      "Epoch 00074: val_loss improved from 2.63387 to 2.62848, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5988\n",
      "Recall: 0.449\n",
      "F1 score: 0.5132\n",
      "Epoch 75/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.4981 - val_loss: 2.6241\n",
      "\n",
      "Epoch 00075: val_loss improved from 2.62848 to 2.62407, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.605\n",
      "Recall: 0.43\n",
      "F1 score: 0.5027\n",
      "Epoch 76/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.4956 - val_loss: 2.6662\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5979\n",
      "Recall: 0.4493\n",
      "F1 score: 0.513\n",
      "Epoch 77/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.4911 - val_loss: 2.7066\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5818\n",
      "Recall: 0.438\n",
      "F1 score: 0.4998\n",
      "Epoch 78/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.5060 - val_loss: 2.6496\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5926\n",
      "Recall: 0.459\n",
      "F1 score: 0.5173\n",
      "Epoch 79/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.4762 - val_loss: 2.6782\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5642\n",
      "Recall: 0.4776\n",
      "F1 score: 0.5173\n",
      "Epoch 80/1000\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 2.4720 - val_loss: 2.6337\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5887\n",
      "Recall: 0.4638\n",
      "F1 score: 0.5188\n",
      "Epoch 81/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.4843 - val_loss: 2.6450\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5796\n",
      "Recall: 0.4688\n",
      "F1 score: 0.5183\n",
      "Epoch 82/1000\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 2.4849 - val_loss: 2.6552\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5733\n",
      "Recall: 0.4732\n",
      "F1 score: 0.5185\n",
      "Epoch 83/1000\n",
      "400/400 [==============================] - 215s 539ms/step - loss: 2.4707 - val_loss: 2.6387\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5751\n",
      "Recall: 0.4756\n",
      "F1 score: 0.5206\n",
      "Epoch 84/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.4661 - val_loss: 2.6461\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.62407\n",
      "Number of images: 45\n",
      "Presicion: 0.5765\n",
      "Recall: 0.4476\n",
      "F1 score: 0.504\n",
      "Epoch 85/1000\n",
      "400/400 [==============================] - 215s 539ms/step - loss: 2.4856 - val_loss: 2.6545\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.62407\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.5853\n",
      "Recall: 0.4545\n",
      "F1 score: 0.5117\n",
      "Epoch 86/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.4451 - val_loss: 2.6146\n",
      "\n",
      "Epoch 00086: val_loss improved from 2.62407 to 2.61456, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.5969\n",
      "Recall: 0.4475\n",
      "F1 score: 0.5115\n",
      "Epoch 87/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.4105 - val_loss: 2.6085\n",
      "\n",
      "Epoch 00087: val_loss improved from 2.61456 to 2.60846, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.615\n",
      "Recall: 0.4429\n",
      "F1 score: 0.5149\n",
      "Epoch 88/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.4269 - val_loss: 2.6226\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5967\n",
      "Recall: 0.4619\n",
      "F1 score: 0.5207\n",
      "Epoch 89/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.4074 - val_loss: 2.6209\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5908\n",
      "Recall: 0.4716\n",
      "F1 score: 0.5245\n",
      "Epoch 90/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.4199 - val_loss: 2.6171\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5919\n",
      "Recall: 0.467\n",
      "F1 score: 0.5221\n",
      "Epoch 91/1000\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.4313 - val_loss: 2.6126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00091: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5797\n",
      "Recall: 0.4709\n",
      "F1 score: 0.5197\n",
      "Epoch 92/1000\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 2.4041 - val_loss: 2.6115\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5634\n",
      "Recall: 0.4667\n",
      "F1 score: 0.5105\n",
      "Epoch 93/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.3999 - val_loss: 2.6167\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.6025\n",
      "Recall: 0.4812\n",
      "F1 score: 0.5351\n",
      "Improve F1 score from 0.5308118833880706 to 0.5350965757554014\n",
      "Epoch 94/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.4187 - val_loss: 2.6230\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.60846\n",
      "Number of images: 45\n",
      "Presicion: 0.5945\n",
      "Recall: 0.4841\n",
      "F1 score: 0.5337\n",
      "Epoch 95/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.4023 - val_loss: 2.5995\n",
      "\n",
      "Epoch 00095: val_loss improved from 2.60846 to 2.59953, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6098\n",
      "Recall: 0.4588\n",
      "F1 score: 0.5236\n",
      "Epoch 96/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.3880 - val_loss: 2.6171\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.6059\n",
      "Recall: 0.4679\n",
      "F1 score: 0.528\n",
      "Epoch 97/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.3961 - val_loss: 2.6219\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.5784\n",
      "Recall: 0.4528\n",
      "F1 score: 0.508\n",
      "Epoch 98/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.3984 - val_loss: 2.6124\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.5987\n",
      "Recall: 0.4468\n",
      "F1 score: 0.5117\n",
      "Epoch 99/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.3962 - val_loss: 2.6180\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.5865\n",
      "Recall: 0.4766\n",
      "F1 score: 0.5259\n",
      "Epoch 100/1000\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 2.3948 - val_loss: 2.6107\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.5995\n",
      "Recall: 0.4657\n",
      "F1 score: 0.5242\n",
      "Epoch 101/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.4035 - val_loss: 2.6141\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.612\n",
      "Recall: 0.4549\n",
      "F1 score: 0.5219\n",
      "Epoch 102/1000\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.3740 - val_loss: 2.6005\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.5896\n",
      "Recall: 0.4725\n",
      "F1 score: 0.5246\n",
      "Epoch 103/1000\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.3851 - val_loss: 2.6103\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.59953\n",
      "Number of images: 45\n",
      "Presicion: 0.6152\n",
      "Recall: 0.4738\n",
      "F1 score: 0.5353\n",
      "Improve F1 score from 0.5350965757554014 to 0.5353124531568757\n",
      "Epoch 104/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.3795 - val_loss: 2.5988\n",
      "\n",
      "Epoch 00104: val_loss improved from 2.59953 to 2.59876, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6276\n",
      "Recall: 0.4674\n",
      "F1 score: 0.5358\n",
      "Improve F1 score from 0.5353124531568757 to 0.5358297226971077\n",
      "Epoch 105/1000\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.3656 - val_loss: 2.6189\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.59876\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.6316\n",
      "Recall: 0.4607\n",
      "F1 score: 0.5328\n",
      "Epoch 106/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.3489 - val_loss: 2.5933\n",
      "\n",
      "Epoch 00106: val_loss improved from 2.59876 to 2.59335, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.597\n",
      "Recall: 0.4762\n",
      "F1 score: 0.5298\n",
      "Epoch 107/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.3526 - val_loss: 2.6014\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.59335\n",
      "Number of images: 45\n",
      "Presicion: 0.6083\n",
      "Recall: 0.4635\n",
      "F1 score: 0.5261\n",
      "Epoch 108/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.3708 - val_loss: 2.5958\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.59335\n",
      "Number of images: 45\n",
      "Presicion: 0.6\n",
      "Recall: 0.4626\n",
      "F1 score: 0.5224\n",
      "Epoch 109/1000\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.3624 - val_loss: 2.5889\n",
      "\n",
      "Epoch 00109: val_loss improved from 2.59335 to 2.58893, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6118\n",
      "Recall: 0.4778\n",
      "F1 score: 0.5366\n",
      "Improve F1 score from 0.5358297226971077 to 0.5365843110357557\n",
      "Epoch 110/1000\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.3477 - val_loss: 2.5927\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2.58893\n",
      "Number of images: 45\n",
      "Presicion: 0.6047\n",
      "Recall: 0.4611\n",
      "F1 score: 0.5232\n",
      "Epoch 111/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.3714 - val_loss: 2.5884\n",
      "\n",
      "Epoch 00111: val_loss improved from 2.58893 to 2.58838, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.611\n",
      "Recall: 0.4579\n",
      "F1 score: 0.5235\n",
      "Epoch 112/1000\n",
      "400/400 [==============================] - 217s 544ms/step - loss: 2.3433 - val_loss: 2.5949\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6162\n",
      "Recall: 0.4751\n",
      "F1 score: 0.5365\n",
      "Epoch 113/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.3531 - val_loss: 2.5979\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6134\n",
      "Recall: 0.4653\n",
      "F1 score: 0.5292\n",
      "Epoch 114/1000\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.3411 - val_loss: 2.5972\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6083\n",
      "Recall: 0.4852\n",
      "F1 score: 0.5398\n",
      "Improve F1 score from 0.5365843110357557 to 0.5397928972491306\n",
      "Epoch 115/1000\n",
      "400/400 [==============================] - 215s 536ms/step - loss: 2.3275 - val_loss: 2.6097\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6046\n",
      "Recall: 0.485\n",
      "F1 score: 0.5382\n",
      "Epoch 116/1000\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.3575 - val_loss: 2.6054\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6023\n",
      "Recall: 0.4735\n",
      "F1 score: 0.5302\n",
      "Epoch 117/1000\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 2.3264 - val_loss: 2.6029\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6041\n",
      "Recall: 0.4758\n",
      "F1 score: 0.5323\n",
      "Epoch 118/1000\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.3393 - val_loss: 2.5930\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.5928\n",
      "Recall: 0.4715\n",
      "F1 score: 0.5252\n",
      "Epoch 119/1000\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 2.3515 - val_loss: 2.6038\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2.58838\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Number of images: 45\n",
      "Presicion: 0.5832\n",
      "Recall: 0.4921\n",
      "F1 score: 0.5338\n",
      "Epoch 120/1000\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.3589 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.603\n",
      "Recall: 0.4807\n",
      "F1 score: 0.535\n",
      "Epoch 121/1000\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 2.3368 - val_loss: 2.5960\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6022\n",
      "Recall: 0.4778\n",
      "F1 score: 0.5328\n",
      "Epoch 122/1000\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.3228 - val_loss: 2.5984\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2.58838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 45\n",
      "Presicion: 0.6068\n",
      "Recall: 0.4809\n",
      "F1 score: 0.5366\n",
      "Epoch 123/1000\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 2.3094 - val_loss: 2.5892\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2.58838\n",
      "Number of images: 45\n",
      "Presicion: 0.6101\n",
      "Recall: 0.4756\n",
      "F1 score: 0.5345\n",
      "Epoch 00123: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 400\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset learning rate to 0.001\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:07<00:00, 28.15it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 28.01it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "# images_dir = data_path + 'pascal_dataset'\n",
    "images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "# model_checkpoint.best = 2.567152314715915\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=12,\n",
    "                               verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_320, \n",
    "                      label_val, (1, 2424, 14),\n",
    "                      data_path + 'history/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic_f1.csv')\n",
    "\n",
    "# learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping,\n",
    "#              learning_rate_scheduler]\n",
    "             reduce_learning_rate,\n",
    "             f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 3.3283 - val_loss: 2.9904\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.99039, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6378\n",
      "Recall: 0.5186\n",
      "F1 score: 0.5721\n",
      "Improve F1 score from -inf to 0.5720661748345818\n",
      "Epoch 2/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.8354 - val_loss: 2.8278\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.99039 to 2.82776, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.645\n",
      "Recall: 0.5363\n",
      "F1 score: 0.5856\n",
      "Improve F1 score from 0.5720661748345818 to 0.5856417903961293\n",
      "Epoch 3/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.8889 - val_loss: 2.8025\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.82776 to 2.80247, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6725\n",
      "Recall: 0.5185\n",
      "F1 score: 0.5856\n",
      "Epoch 4/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.6904 - val_loss: 2.7674\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.80247 to 2.76741, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.683\n",
      "Recall: 0.4582\n",
      "F1 score: 0.5484\n",
      "Epoch 5/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7517 - val_loss: 2.8231\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6754\n",
      "Recall: 0.4558\n",
      "F1 score: 0.5443\n",
      "Epoch 6/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.6985 - val_loss: 2.9986\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6535\n",
      "Recall: 0.4075\n",
      "F1 score: 0.502\n",
      "Epoch 7/1000\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.6974 - val_loss: 3.1327\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6453\n",
      "Recall: 0.4553\n",
      "F1 score: 0.5339\n",
      "Epoch 8/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.3968 - val_loss: 2.8691\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6779\n",
      "Recall: 0.4879\n",
      "F1 score: 0.5674\n",
      "Epoch 9/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.4066 - val_loss: 2.9492\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.681\n",
      "Recall: 0.4636\n",
      "F1 score: 0.5516\n",
      "Epoch 10/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.4451 - val_loss: 3.0865\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6595\n",
      "Recall: 0.4595\n",
      "F1 score: 0.5416\n",
      "Epoch 11/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.3900 - val_loss: 3.0024\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6705\n",
      "Recall: 0.4768\n",
      "F1 score: 0.5573\n",
      "Epoch 12/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.3969 - val_loss: 2.8803\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6793\n",
      "Recall: 0.5035\n",
      "F1 score: 0.5784\n",
      "Epoch 13/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3734 - val_loss: 2.9662\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.6749\n",
      "Recall: 0.4579\n",
      "F1 score: 0.5456\n",
      "Epoch 14/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.3833 - val_loss: 2.7978\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.76741\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Number of images: 45\n",
      "Presicion: 0.7121\n",
      "Recall: 0.419\n",
      "F1 score: 0.5276\n",
      "Epoch 15/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.3419 - val_loss: 2.7819\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.76741\n",
      "Number of images: 45\n",
      "Presicion: 0.7266\n",
      "Recall: 0.4338\n",
      "F1 score: 0.5432\n",
      "Epoch 16/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2205 - val_loss: 2.7517\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.76741 to 2.75174, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7082\n",
      "Recall: 0.4653\n",
      "F1 score: 0.5616\n",
      "Epoch 17/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.2975 - val_loss: 2.7170\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.75174 to 2.71698, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7294\n",
      "Recall: 0.4817\n",
      "F1 score: 0.5802\n",
      "Epoch 18/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1470 - val_loss: 2.7155\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.71698 to 2.71551, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7201\n",
      "Recall: 0.4665\n",
      "F1 score: 0.5662\n",
      "Epoch 19/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1782 - val_loss: 2.7176\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.71551\n",
      "Number of images: 45\n",
      "Presicion: 0.7386\n",
      "Recall: 0.4671\n",
      "F1 score: 0.5723\n",
      "Epoch 20/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0904 - val_loss: 2.7926\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.71551\n",
      "Number of images: 45\n",
      "Presicion: 0.7338\n",
      "Recall: 0.4349\n",
      "F1 score: 0.5461\n",
      "Epoch 21/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.1467 - val_loss: 2.7444\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.71551\n",
      "Number of images: 45\n",
      "Presicion: 0.7481\n",
      "Recall: 0.4378\n",
      "F1 score: 0.5524\n",
      "Epoch 22/1000\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.0620 - val_loss: 2.6607\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.71551 to 2.66070, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7363\n",
      "Recall: 0.4554\n",
      "F1 score: 0.5627\n",
      "Epoch 23/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1521 - val_loss: 2.6481\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.66070 to 2.64810, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7335\n",
      "Recall: 0.494\n",
      "F1 score: 0.5904\n",
      "Improve F1 score from 0.5856417903961293 to 0.5903589208349189\n",
      "Epoch 24/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0833 - val_loss: 2.7047\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.64810\n",
      "Number of images: 45\n",
      "Presicion: 0.7411\n",
      "Recall: 0.4539\n",
      "F1 score: 0.563\n",
      "Epoch 25/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1164 - val_loss: 2.6980\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.64810\n",
      "Number of images: 45\n",
      "Presicion: 0.7444\n",
      "Recall: 0.4739\n",
      "F1 score: 0.5792\n",
      "Epoch 26/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.2491 - val_loss: 2.6793\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.64810\n",
      "Number of images: 45\n",
      "Presicion: 0.7287\n",
      "Recall: 0.4524\n",
      "F1 score: 0.5583\n",
      "Epoch 27/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1828 - val_loss: 2.6124\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.64810 to 2.61244, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7292\n",
      "Recall: 0.5001\n",
      "F1 score: 0.5933\n",
      "Improve F1 score from 0.5903589208349189 to 0.5933109759865185\n",
      "Epoch 28/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.0662 - val_loss: 2.8508\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.61244\n",
      "Number of images: 45\n",
      "Presicion: 0.7426\n",
      "Recall: 0.3896\n",
      "F1 score: 0.5111\n",
      "Epoch 29/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1152 - val_loss: 2.7635\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.61244\n",
      "Number of images: 45\n",
      "Presicion: 0.7363\n",
      "Recall: 0.4227\n",
      "F1 score: 0.5371\n",
      "Epoch 30/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0954 - val_loss: 2.6269\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.61244\n",
      "Number of images: 45\n",
      "Presicion: 0.7207\n",
      "Recall: 0.4661\n",
      "F1 score: 0.5661\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 63s 4s/step - loss: 2.1317 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.61244 to 2.57007, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7376\n",
      "Recall: 0.4901\n",
      "F1 score: 0.5889\n",
      "Epoch 32/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9586 - val_loss: 2.5910\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.57007\n",
      "Number of images: 45\n",
      "Presicion: 0.7135\n",
      "Recall: 0.5072\n",
      "F1 score: 0.5929\n",
      "Epoch 33/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0320 - val_loss: 2.5991\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.57007\n",
      "Number of images: 45\n",
      "Presicion: 0.7174\n",
      "Recall: 0.471\n",
      "F1 score: 0.5686\n",
      "Epoch 34/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9874 - val_loss: 2.5062\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.57007 to 2.50616, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7248\n",
      "Recall: 0.5062\n",
      "F1 score: 0.5961\n",
      "Improve F1 score from 0.5933109759865185 to 0.596097457056984\n",
      "Epoch 35/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9235 - val_loss: 2.5238\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.50616\n",
      "Number of images: 45\n",
      "Presicion: 0.7303\n",
      "Recall: 0.5285\n",
      "F1 score: 0.6132\n",
      "Improve F1 score from 0.596097457056984 to 0.613208058009637\n",
      "Epoch 36/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0039 - val_loss: 2.4811\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.50616 to 2.48112, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7175\n",
      "Recall: 0.537\n",
      "F1 score: 0.6143\n",
      "Improve F1 score from 0.613208058009637 to 0.6142649352702104\n",
      "Epoch 37/1000\n",
      "15/15 [==============================] - 59s 4s/step - loss: 1.8665 - val_loss: 2.6050\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.48112\n",
      "Number of images: 45\n",
      "Presicion: 0.7215\n",
      "Recall: 0.515\n",
      "F1 score: 0.601\n",
      "Epoch 38/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9195 - val_loss: 2.6247\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.48112\n",
      "Number of images: 45\n",
      "Presicion: 0.7153\n",
      "Recall: 0.5282\n",
      "F1 score: 0.6077\n",
      "Epoch 39/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0124 - val_loss: 2.7289\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.48112\n",
      "Number of images: 45\n",
      "Presicion: 0.7154\n",
      "Recall: 0.4971\n",
      "F1 score: 0.5866\n",
      "Epoch 40/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.1226 - val_loss: 2.5219\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.48112\n",
      "Number of images: 45\n",
      "Presicion: 0.6948\n",
      "Recall: 0.5565\n",
      "F1 score: 0.618\n",
      "Improve F1 score from 0.6142649352702104 to 0.6179765737094259\n",
      "Epoch 41/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.0580 - val_loss: 2.4665\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.48112 to 2.46645, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7164\n",
      "Recall: 0.5599\n",
      "F1 score: 0.6286\n",
      "Improve F1 score from 0.6179765737094259 to 0.6285598550744379\n",
      "Epoch 42/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9597 - val_loss: 2.5018\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7183\n",
      "Recall: 0.528\n",
      "F1 score: 0.6086\n",
      "Epoch 43/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9244 - val_loss: 2.6305\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.708\n",
      "Recall: 0.4899\n",
      "F1 score: 0.5791\n",
      "Epoch 44/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9560 - val_loss: 2.5163\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7098\n",
      "Recall: 0.5451\n",
      "F1 score: 0.6167\n",
      "Epoch 45/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0003 - val_loss: 2.5269\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7217\n",
      "Recall: 0.5278\n",
      "F1 score: 0.6097\n",
      "Epoch 46/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9497 - val_loss: 2.4934\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7144\n",
      "Recall: 0.5473\n",
      "F1 score: 0.6198\n",
      "Epoch 47/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9254 - val_loss: 2.5502\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7164\n",
      "Recall: 0.5128\n",
      "F1 score: 0.5977\n",
      "Epoch 48/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9328 - val_loss: 2.5495\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7159\n",
      "Recall: 0.5239\n",
      "F1 score: 0.605\n",
      "Epoch 49/1000\n",
      "15/15 [==============================] - 59s 4s/step - loss: 1.8479 - val_loss: 2.6240\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.46645\n",
      "Number of images: 45\n",
      "Presicion: 0.7159\n",
      "Recall: 0.4944\n",
      "F1 score: 0.5849\n",
      "Epoch 50/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0702 - val_loss: 2.4536\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.46645 to 2.45356, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6823\n",
      "Recall: 0.5556\n",
      "F1 score: 0.6125\n",
      "Epoch 51/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.9462 - val_loss: 2.5450\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.45356\n",
      "Number of images: 45\n",
      "Presicion: 0.6979\n",
      "Recall: 0.5396\n",
      "F1 score: 0.6086\n",
      "Epoch 52/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.8978 - val_loss: 2.5940\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.45356\n",
      "Number of images: 45\n",
      "Presicion: 0.7041\n",
      "Recall: 0.5286\n",
      "F1 score: 0.6038\n",
      "Epoch 53/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9392 - val_loss: 2.4459\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.45356 to 2.44595, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7157\n",
      "Recall: 0.5221\n",
      "F1 score: 0.6038\n",
      "Epoch 54/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.8929 - val_loss: 2.5605\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.44595\n",
      "Number of images: 45\n",
      "Presicion: 0.7114\n",
      "Recall: 0.5402\n",
      "F1 score: 0.614\n",
      "Epoch 55/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9618 - val_loss: 2.5832\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.44595\n",
      "Number of images: 45\n",
      "Presicion: 0.7102\n",
      "Recall: 0.5189\n",
      "F1 score: 0.5996\n",
      "Epoch 56/1000\n",
      "15/15 [==============================] - 56s 4s/step - loss: 1.7491 - val_loss: 2.6291\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.44595\n",
      "Number of images: 45\n",
      "Presicion: 0.6974\n",
      "Recall: 0.5021\n",
      "F1 score: 0.5838\n",
      "Epoch 57/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.8431 - val_loss: 2.4863\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.44595\n",
      "Number of images: 45\n",
      "Presicion: 0.7048\n",
      "Recall: 0.5343\n",
      "F1 score: 0.6078\n",
      "Epoch 58/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.9238 - val_loss: 2.5681\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.44595\n",
      "Number of images: 45\n",
      "Presicion: 0.6974\n",
      "Recall: 0.4992\n",
      "F1 score: 0.5819\n",
      "Epoch 59/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.8777 - val_loss: 2.4210\n",
      "\n",
      "Epoch 00059: val_loss improved from 2.44595 to 2.42096, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7213\n",
      "Recall: 0.5336\n",
      "F1 score: 0.6134\n",
      "Epoch 60/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9584 - val_loss: 2.6161\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.42096\n",
      "Number of images: 45\n",
      "Presicion: 0.7044\n",
      "Recall: 0.47\n",
      "F1 score: 0.5638\n",
      "Epoch 61/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.8854 - val_loss: 2.7325\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.42096\n",
      "Number of images: 45\n",
      "Presicion: 0.7004\n",
      "Recall: 0.4826\n",
      "F1 score: 0.5715\n",
      "Epoch 62/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.8343 - val_loss: 2.6418\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.42096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 45\n",
      "Presicion: 0.6959\n",
      "Recall: 0.4894\n",
      "F1 score: 0.5746\n",
      "Epoch 63/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.7863 - val_loss: 2.4042\n",
      "\n",
      "Epoch 00063: val_loss improved from 2.42096 to 2.40416, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.6928\n",
      "Recall: 0.5699\n",
      "F1 score: 0.6254\n",
      "Epoch 64/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9159 - val_loss: 2.5404\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7006\n",
      "Recall: 0.4934\n",
      "F1 score: 0.579\n",
      "Epoch 65/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.8836 - val_loss: 2.5233\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7046\n",
      "Recall: 0.5192\n",
      "F1 score: 0.5979\n",
      "Epoch 66/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.7918 - val_loss: 2.4503\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7259\n",
      "Recall: 0.5275\n",
      "F1 score: 0.611\n",
      "Epoch 67/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.8553 - val_loss: 2.4454\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7135\n",
      "Recall: 0.5353\n",
      "F1 score: 0.6117\n",
      "Epoch 68/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.7962 - val_loss: 2.4357\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7224\n",
      "Recall: 0.5226\n",
      "F1 score: 0.6064\n",
      "Epoch 69/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.8923 - val_loss: 2.4190\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.40416\n",
      "Number of images: 45\n",
      "Presicion: 0.7137\n",
      "Recall: 0.5172\n",
      "F1 score: 0.5998\n",
      "Epoch 70/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9688 - val_loss: 2.3784\n",
      "\n",
      "Epoch 00070: val_loss improved from 2.40416 to 2.37842, saving model to /home/aldo/Documents/weights/models/ssdlite320_mobilenetv2/ssdlite320_mobilenetv2_pascal_cic.h5\n",
      "Number of images: 45\n",
      "Presicion: 0.7184\n",
      "Recall: 0.5312\n",
      "F1 score: 0.6108\n",
      "Epoch 71/1000\n",
      "15/15 [==============================] - 65s 4s/step - loss: 1.9488 - val_loss: 2.4946\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7259\n",
      "Recall: 0.4547\n",
      "F1 score: 0.5591\n",
      "Epoch 72/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0000 - val_loss: 2.6281\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7468\n",
      "Recall: 0.4326\n",
      "F1 score: 0.5478\n",
      "Epoch 73/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.8627 - val_loss: 2.6921\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7333\n",
      "Recall: 0.4375\n",
      "F1 score: 0.548\n",
      "Epoch 74/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.7752 - val_loss: 2.6878\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7245\n",
      "Recall: 0.4658\n",
      "F1 score: 0.567\n",
      "Epoch 75/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.8136 - val_loss: 2.7165\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7254\n",
      "Recall: 0.4709\n",
      "F1 score: 0.5711\n",
      "Epoch 76/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.8778 - val_loss: 2.6151\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7371\n",
      "Recall: 0.4671\n",
      "F1 score: 0.5719\n",
      "Epoch 77/1000\n",
      "15/15 [==============================] - 64s 4s/step - loss: 1.8168 - val_loss: 2.4883\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7517\n",
      "Recall: 0.4957\n",
      "F1 score: 0.5975\n",
      "Epoch 78/1000\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9272 - val_loss: 2.5013\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7445\n",
      "Recall: 0.5206\n",
      "F1 score: 0.6127\n",
      "Epoch 79/1000\n",
      "15/15 [==============================] - 61s 4s/step - loss: 1.8169 - val_loss: 2.5259\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7136\n",
      "Recall: 0.5236\n",
      "F1 score: 0.604\n",
      "Epoch 80/1000\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.7672 - val_loss: 2.4954\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.37842\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Number of images: 45\n",
      "Presicion: 0.7211\n",
      "Recall: 0.5173\n",
      "F1 score: 0.6024\n",
      "Epoch 81/1000\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.8893 - val_loss: 2.4808\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7281\n",
      "Recall: 0.5055\n",
      "F1 score: 0.5967\n",
      "Epoch 82/1000\n",
      "15/15 [==============================] - 66s 4s/step - loss: 1.9015 - val_loss: 2.4076\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.37842\n",
      "Number of images: 45\n",
      "Presicion: 0.7413\n",
      "Recall: 0.5284\n",
      "F1 score: 0.617\n",
      "Epoch 00082: early stopping\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 1000\n",
    "steps_per_epoch = 15\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
