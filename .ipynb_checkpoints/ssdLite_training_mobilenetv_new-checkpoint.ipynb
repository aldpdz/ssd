{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSDLite300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssdlite320PPN_mobilenetv2 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = new_scales\n",
    "aspect_ratios = [[1.0, 0.5, 2.0/3.0],\n",
    "                 [1.0, 0.5, 2.0/3.0, 1.0/3.0, 3.0/4.0],\n",
    "                 [1.0, 0.5, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True\n",
    "size_classifier = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                alpha=0.35,\n",
    "                expansion=1,\n",
    "                mode='training',\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             91600       input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_expand (Conv2D)     (None, 18, 18, 32)   1024        model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_expand (BatchNorma (None, 18, 18, 32)   128         mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 18, 18, 32)   0           bn13_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_depthwise (Depthwis (None, 18, 18, 32)   288         conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_depthwise (BatchNorma (None, 18, 18, 32)   128         mobl13_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 18, 18, 32)   0           bn13_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_project (Conv2D)    (None, 18, 18, 56)   1792        conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_project (BatchNorm (None, 18, 18, 56)   224         mobl13_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_expand (Conv2D)     (None, 18, 18, 56)   3136        bn13_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_expand (BatchNorma (None, 18, 18, 56)   224         mobl14_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu (Activation)       (None, 18, 18, 56)   0           bn14_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_depthwise (Depthwis (None, 18, 18, 56)   504         conv_14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_depthwise (BatchNorma (None, 18, 18, 56)   224         mobl14_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_relu (Activation)    (None, 18, 18, 56)   0           bn14_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_project (Conv2D)    (None, 18, 18, 56)   3136        conv_dw_14_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_project (BatchNorm (None, 18, 18, 56)   224         mobl14_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_14 (Add)            (None, 18, 18, 56)   0           bn13_conv_bn_project[0][0]       \n",
      "                                                                 bn14_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_expand (Conv2D)     (None, 18, 18, 56)   3136        res_connect_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_expand (BatchNorma (None, 18, 18, 56)   224         mobl15_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu (Activation)       (None, 18, 18, 56)   0           bn15_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_depthwise (Depthwis (None, 18, 18, 56)   504         conv_15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_depthwise (BatchNorma (None, 18, 18, 56)   224         mobl15_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_relu (Activation)    (None, 18, 18, 56)   0           bn15_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_project (Conv2D)    (None, 18, 18, 56)   3136        conv_dw_15_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_project (BatchNorm (None, 18, 18, 56)   224         mobl15_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_15 (Add)            (None, 18, 18, 56)   0           res_connect_14[0][0]             \n",
      "                                                                 bn15_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_expand (Conv2D)     (None, 18, 18, 56)   3136        res_connect_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_expand (BatchNorma (None, 18, 18, 56)   224         mobl16_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu (Activation)       (None, 18, 18, 56)   0           bn16_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_depthwise (Depthwis (None, 18, 18, 56)   504         conv_16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_depthwise (BatchNorma (None, 18, 18, 56)   224         mobl16_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16_relu (Activation)    (None, 18, 18, 56)   0           bn16_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_project (Conv2D)    (None, 18, 18, 112)  6272        conv_dw_16_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_project (BatchNorm (None, 18, 18, 112)  448         mobl16_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 9, 9, 1280)   143360      bn16_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 9, 9, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_relu (Activation)        (None, 9, 9, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv_features (Conv2D)          (None, 9, 9, 256)    327680      Conv_1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_features (BatchNormalization (None, 9, 9, 256)    1024        Conv_features[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu_features (Activation)      (None, 9, 9, 256)    0           bn_features[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_17 (MaxPooling2D)       (None, 5, 5, 256)    0           relu_features[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_18_2 (MaxPooling2D)     (None, 3, 3, 256)    0           maxpool_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_19_2 (MaxPooling2D)     (None, 2, 2, 256)    0           maxpool_18_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_20_2 (MaxPooling2D)     (None, 1, 1, 256)    0           maxpool_19_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower (Conv2D)             multiple             131072      maxpool_17[0][0]                 \n",
      "                                                                 maxpool_18_2[0][0]               \n",
      "                                                                 maxpool_19_2[0][0]               \n",
      "                                                                 maxpool_20_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_tower (BatchNormalization)   multiple             2048        conv_tower[0][0]                 \n",
      "                                                                 conv_tower[1][0]                 \n",
      "                                                                 conv_tower[2][0]                 \n",
      "                                                                 conv_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "relu_tower (Activation)         multiple             0           bn_tower[0][0]                   \n",
      "                                                                 bn_tower[1][0]                   \n",
      "                                                                 bn_tower[2][0]                   \n",
      "                                                                 bn_tower[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 18, 18, 8)    2312        mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf (Conv2D)       (None, 9, 9, 12)     138252      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "shared_mbox_conf (Conv2D)       multiple             46090       relu_tower[0][0]                 \n",
      "                                                                 relu_tower[1][0]                 \n",
      "                                                                 relu_tower[2][0]                 \n",
      "                                                                 relu_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 18, 18, 16)   4624        mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc (Conv2D)        (None, 9, 9, 24)     276504      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "shared_mbox_loc (Conv2D)        multiple             92180       relu_tower[0][0]                 \n",
      "                                                                 relu_tower[1][0]                 \n",
      "                                                                 relu_tower[2][0]                 \n",
      "                                                                 relu_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1296, 2)      0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 486, 2)       0           conv17_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 125, 2)       0           shared_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 45, 2)        0           shared_mbox_conf[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 20, 2)        0           shared_mbox_conf[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 5, 2)         0           shared_mbox_conf[3][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 18, 18, 4, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox (AnchorBox (None, 9, 9, 6, 8)   0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox (AnchorB (None, 5, 5, 5, 8)   0           shared_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox (AnchorB (None, 3, 3, 5, 8)   0           shared_mbox_loc[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox (AnchorB (None, 2, 2, 5, 8)   0           shared_mbox_loc[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox (AnchorB (None, 1, 1, 5, 8)   0           shared_mbox_loc[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 1977, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1296, 4)      0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 486, 4)       0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 125, 4)       0           shared_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 45, 4)        0           shared_mbox_loc[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 20, 4)        0           shared_mbox_loc[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 5, 4)         0           shared_mbox_loc[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 1296, 8)      0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox_reshape (R (None, 486, 8)       0           conv17_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox_reshape  (None, 125, 8)       0           conv18_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox_reshape  (None, 45, 8)        0           conv19_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox_reshape  (None, 20, 8)        0           conv20_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox_reshape  (None, 5, 8)         0           conv21_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 1977, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 1977, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 1977, 8)      0           conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv17_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv18_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv19_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv20_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv21_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 1977, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,291,154\n",
      "Trainable params: 1,279,538\n",
      "Non-trainable params: 11,616\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:26<00:00, 244.84it/s]\n",
      "Loading images into memory: 100%|██████████| 2097/2097 [00:08<00:00, 246.86it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "images_dir = data_path + 'pascal_dataset'\n",
    "# images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "# predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "predictor_sizes = [(18, 18), (9, 9), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val.npy')\n",
    "val_images_300 = np.load('../data-cic/preprocess_data/images_val_300x300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir=data_path + 'history/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5', \n",
    "                                   histogram_freq=0, \n",
    "                                   write_graph=False, \n",
    "                                   write_images=False,\n",
    "                                   update_freq='epoch')\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_300, \n",
    "                      label_val, (1, 1977, 14),\n",
    "                      data_path + 'history/new_net/new_share_conv_conf_pascal_f1_a_0.35_e_1_ps_ng_0.5.csv',\n",
    "                      '/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_f1_a_0.35_e_1_ps_ng_0.5.h5')\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             reduce_learning_rate,\n",
    "             f1_callback,\n",
    "             tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "400/400 [==============================] - 225s 561ms/step - loss: 10.1451 - val_loss: 9.2928\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.29276, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.11225141226327574\n",
      "Improve F1 score from -inf to 0.11225141226327574\n",
      "Epoch 2/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 4.6065 - val_loss: 11.3443\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 9.29276\n",
      "F1 score: 0.1002673701688534\n",
      "Epoch 3/120\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 4.3191 - val_loss: 6.9097\n",
      "\n",
      "Epoch 00003: val_loss improved from 9.29276 to 6.90971, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.10305863993195208\n",
      "Epoch 4/120\n",
      "400/400 [==============================] - 216s 539ms/step - loss: 4.2021 - val_loss: 7.0112\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.90971\n",
      "F1 score: 0.11875436987679683\n",
      "Improve F1 score from 0.11225141226327574 to 0.11875436987679683\n",
      "Epoch 5/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 4.0861 - val_loss: 6.7537\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.90971 to 6.75369, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.19203747802564103\n",
      "Improve F1 score from 0.11875436987679683 to 0.19203747802564103\n",
      "Epoch 6/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 4.0155 - val_loss: 6.7186\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.75369 to 6.71857, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.1861419518039421\n",
      "Epoch 7/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.9474 - val_loss: 6.5923\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.71857 to 6.59227, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.24562074575123236\n",
      "Improve F1 score from 0.19203747802564103 to 0.24562074575123236\n",
      "Epoch 8/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.8917 - val_loss: 8.9382\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.59227\n",
      "F1 score: 0.20750598765589984\n",
      "Epoch 9/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.8444 - val_loss: 6.1561\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.59227 to 6.15609, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.19746613810090918\n",
      "Epoch 10/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.7790 - val_loss: 6.2203\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.15609\n",
      "F1 score: 0.21236911084490737\n",
      "Epoch 11/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.7566 - val_loss: 6.5255\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6.15609\n",
      "F1 score: 0.3017217370865673\n",
      "Improve F1 score from 0.24562074575123236 to 0.3017217370865673\n",
      "Epoch 12/120\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 3.7270 - val_loss: 6.4458\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 6.15609\n",
      "F1 score: 0.2544939997568814\n",
      "Epoch 13/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.7000 - val_loss: 6.2291\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 6.15609\n",
      "F1 score: 0.2657915877716876\n",
      "Epoch 14/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.6682 - val_loss: 6.4426\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 6.15609\n",
      "F1 score: 0.07822915393937319\n",
      "Epoch 15/120\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 3.6679 - val_loss: 7.0159\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 6.15609\n",
      "F1 score: 0.22221124988171642\n",
      "Epoch 16/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.6394 - val_loss: 7.2939\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 6.15609\n",
      "F1 score: 0.2534926652412487\n",
      "Epoch 17/120\n",
      "400/400 [==============================] - 213s 531ms/step - loss: 3.6255 - val_loss: 6.8947\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 6.15609\n",
      "F1 score: 0.18314369740515188\n",
      "Epoch 18/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.5991 - val_loss: 5.3472\n",
      "\n",
      "Epoch 00018: val_loss improved from 6.15609 to 5.34718, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.1806306719419735\n",
      "Epoch 19/120\n",
      "400/400 [==============================] - 213s 534ms/step - loss: 3.5777 - val_loss: 6.1668\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3657708415004964\n",
      "Improve F1 score from 0.3017217370865673 to 0.3657708415004964\n",
      "Epoch 20/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.5523 - val_loss: 6.1920\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3375876463756498\n",
      "Epoch 21/120\n",
      "400/400 [==============================] - 209s 523ms/step - loss: 3.5268 - val_loss: 7.0645\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3325659679056627\n",
      "Epoch 22/120\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 3.5345 - val_loss: 6.1145\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.34718\n",
      "F1 score: 0.31359382834264937\n",
      "Epoch 23/120\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 3.5167 - val_loss: 6.5612\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.34718\n",
      "F1 score: 0.23794846111852677\n",
      "Epoch 24/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.4932 - val_loss: 6.2232\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.34718\n",
      "F1 score: 0.2978485296067752\n",
      "Epoch 25/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.4989 - val_loss: 6.1478\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.34718\n",
      "F1 score: 0.24467881477112052\n",
      "Epoch 26/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.5095 - val_loss: 6.5316\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.34718\n",
      "F1 score: 0.2094133594983273\n",
      "Epoch 27/120\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 3.4716 - val_loss: 6.6630\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.34718\n",
      "F1 score: 0.2207895057004329\n",
      "Epoch 28/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.4651 - val_loss: 6.1080\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "F1 score: 0.3352805545662435\n",
      "Epoch 29/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.3738 - val_loss: 6.1180\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3050399316019397\n",
      "Epoch 30/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.3707 - val_loss: 6.1134\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.34718\n",
      "F1 score: 0.30619691034337226\n",
      "Epoch 31/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.3498 - val_loss: 5.8072\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3044575772737193\n",
      "Epoch 32/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.3365 - val_loss: 6.9544\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3293660137424961\n",
      "Epoch 33/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.3471 - val_loss: 5.8460\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3869793027152677\n",
      "Improve F1 score from 0.3657708415004964 to 0.3869793027152677\n",
      "Epoch 34/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 3.3193 - val_loss: 6.2640\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3627430754443161\n",
      "Epoch 35/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.3500 - val_loss: 5.7720\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3431240022892967\n",
      "Epoch 36/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.3421 - val_loss: 6.5262\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.34718\n",
      "F1 score: 0.408282671732483\n",
      "Improve F1 score from 0.3869793027152677 to 0.408282671732483\n",
      "Epoch 37/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 212s 529ms/step - loss: 3.3225 - val_loss: 6.1866\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3708463420495935\n",
      "Epoch 38/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.3283 - val_loss: 6.2437\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "F1 score: 0.38247076503094224\n",
      "Epoch 39/120\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 3.2568 - val_loss: 6.0540\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39090156621732086\n",
      "Epoch 40/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.2688 - val_loss: 6.0754\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4008625369256666\n",
      "Epoch 41/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.2735 - val_loss: 6.0695\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3897993380055974\n",
      "Epoch 42/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.2446 - val_loss: 6.1505\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5.34718\n",
      "F1 score: 0.37706977120593566\n",
      "Epoch 43/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2648 - val_loss: 6.2452\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.34718\n",
      "F1 score: 0.345416708463352\n",
      "Epoch 44/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.2442 - val_loss: 6.1996\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.34718\n",
      "F1 score: 0.36787757884715044\n",
      "Epoch 45/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2483 - val_loss: 5.7138\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3846360990500786\n",
      "Epoch 46/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.2391 - val_loss: 5.7958\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3888279401634745\n",
      "Epoch 47/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2412 - val_loss: 5.9299\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.34718\n",
      "F1 score: 0.35271272577775903\n",
      "Epoch 48/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2309 - val_loss: 5.9904\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "F1 score: 0.36368073153981667\n",
      "Epoch 49/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.2473 - val_loss: 5.9726\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3519926492626569\n",
      "Epoch 50/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.2215 - val_loss: 6.0492\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39834538934954417\n",
      "Epoch 51/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.2117 - val_loss: 6.0752\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 5.34718\n",
      "F1 score: 0.38656011956730885\n",
      "Epoch 52/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.2157 - val_loss: 6.0180\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3869605150698789\n",
      "Epoch 53/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2104 - val_loss: 5.8887\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4188602304061548\n",
      "Improve F1 score from 0.408282671732483 to 0.4188602304061548\n",
      "Epoch 54/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.2071 - val_loss: 6.0787\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40643792736519196\n",
      "Epoch 55/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.2003 - val_loss: 6.1027\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4095767558440042\n",
      "Epoch 56/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.2056 - val_loss: 6.1870\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40344761853823236\n",
      "Epoch 57/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1781 - val_loss: 6.1433\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39289367557018184\n",
      "Epoch 58/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.2127 - val_loss: 6.1226\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "F1 score: 0.40649596737100524\n",
      "Epoch 59/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1872 - val_loss: 6.1353\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 5.34718\n",
      "F1 score: 0.37761961390029725\n",
      "Epoch 60/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.1692 - val_loss: 6.1696\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4082586949237008\n",
      "Epoch 61/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1920 - val_loss: 6.2345\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 5.34718\n",
      "F1 score: 0.38506063208103314\n",
      "Epoch 62/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1946 - val_loss: 6.1983\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4094515298275151\n",
      "Epoch 63/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.1560 - val_loss: 6.1407\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 5.34718\n",
      "F1 score: 0.42896551413837153\n",
      "Improve F1 score from 0.4188602304061548 to 0.42896551413837153\n",
      "Epoch 64/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1750 - val_loss: 6.1448\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 5.34718\n",
      "F1 score: 0.41904009020383376\n",
      "Epoch 65/120\n",
      "400/400 [==============================] - 211s 529ms/step - loss: 3.1680 - val_loss: 6.2375\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 5.34718\n",
      "F1 score: 0.413622407725523\n",
      "Epoch 66/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1612 - val_loss: 6.2723\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4151989289455193\n",
      "Epoch 67/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.1577 - val_loss: 6.1437\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 5.34718\n",
      "F1 score: 0.403625465492404\n",
      "Epoch 68/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1798 - val_loss: 6.3652\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "F1 score: 0.39680052809486555\n",
      "Epoch 69/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1648 - val_loss: 6.3001\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40657373820859827\n",
      "Epoch 70/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.1740 - val_loss: 6.3467\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4087174439262978\n",
      "Epoch 71/120\n",
      "400/400 [==============================] - 211s 526ms/step - loss: 3.1666 - val_loss: 6.3137\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39578082918683616\n",
      "Epoch 72/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1631 - val_loss: 6.1138\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40726292833371175\n",
      "Epoch 73/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1557 - val_loss: 6.3474\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 5.34718\n",
      "F1 score: 0.38561251836616667\n",
      "Epoch 74/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1481 - val_loss: 6.3741\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40900601034040673\n",
      "Epoch 75/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1638 - val_loss: 6.1735\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39720173487845767\n",
      "Epoch 76/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1749 - val_loss: 6.4028\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 5.34718\n",
      "F1 score: 0.40795330213343384\n",
      "Epoch 77/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1588 - val_loss: 6.4045\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 5.34718\n",
      "F1 score: 0.39848032672720746\n",
      "Epoch 78/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1661 - val_loss: 6.1549\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "F1 score: 0.408641886604282\n",
      "Epoch 79/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.1691 - val_loss: 6.1290\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4074305213874762\n",
      "Epoch 80/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.1470 - val_loss: 7.8839\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4046986520475543\n",
      "Epoch 81/120\n",
      "400/400 [==============================] - 213s 533ms/step - loss: 3.1630 - val_loss: 6.3466\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4020465576255424\n",
      "Epoch 82/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.1552 - val_loss: 6.3442\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4099976990221008\n",
      "Epoch 83/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1309 - val_loss: 6.3315\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4073401417974905\n",
      "Epoch 84/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1759 - val_loss: 6.0858\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 5.34718\n",
      "F1 score: 0.3963907121526414\n",
      "Epoch 85/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1583 - val_loss: 6.3245\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4052668329488827\n",
      "Epoch 86/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1359 - val_loss: 6.5264\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 5.34718\n",
      "F1 score: 0.401832665367627\n",
      "Epoch 87/120\n",
      "400/400 [==============================] - 209s 522ms/step - loss: 3.1551 - val_loss: 6.3096\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 5.34718\n",
      "F1 score: 0.41467556116033194\n",
      "Epoch 88/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1593 - val_loss: 6.3023\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 5.34718\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "F1 score: 0.4072741336267843\n",
      "Epoch 89/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.1705 - val_loss: 6.2962\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4007876415514399\n",
      "Epoch 90/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1469 - val_loss: 6.3106\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4125480733444702\n",
      "Epoch 91/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1455 - val_loss: 6.3143\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 5.34718\n",
      "F1 score: 0.4078035686358794\n",
      "Epoch 92/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1430 - val_loss: 5.2476\n",
      "\n",
      "Epoch 00092: val_loss improved from 5.34718 to 5.24762, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.2948570207707531\n",
      "Epoch 93/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1392 - val_loss: 6.3268\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4124922347074815\n",
      "Epoch 94/120\n",
      "400/400 [==============================] - 213s 532ms/step - loss: 3.1711 - val_loss: 6.3391\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4124908513255037\n",
      "Epoch 95/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1592 - val_loss: 6.1840\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4040301334274678\n",
      "Epoch 96/120\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 3.1540 - val_loss: 6.3502\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4141909662898991\n",
      "Epoch 97/120\n",
      "400/400 [==============================] - 213s 534ms/step - loss: 3.1533 - val_loss: 6.5881\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4119184116938567\n",
      "Epoch 98/120\n",
      "400/400 [==============================] - 209s 524ms/step - loss: 3.1391 - val_loss: 6.3554\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 5.24762\n",
      "F1 score: 0.40826879109833714\n",
      "Epoch 99/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1522 - val_loss: 6.3444\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4137782513811169\n",
      "Epoch 100/120\n",
      "400/400 [==============================] - 210s 524ms/step - loss: 3.1505 - val_loss: 6.3449\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 5.24762\n",
      "F1 score: 0.412178479488412\n",
      "Epoch 101/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1517 - val_loss: 6.3602\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4091166297206818\n",
      "Epoch 102/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1542 - val_loss: 6.3662\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 5.24762\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "F1 score: 0.4098973296203786\n",
      "Epoch 103/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1551 - val_loss: 6.3703\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 5.24762\n",
      "F1 score: 0.414372412614604\n",
      "Epoch 104/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1503 - val_loss: 6.3582\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4113001915972374\n",
      "Epoch 105/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1851 - val_loss: 6.3584\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 5.24762\n",
      "F1 score: 0.41131832513978234\n",
      "Epoch 106/120\n",
      "400/400 [==============================] - 211s 527ms/step - loss: 3.1365 - val_loss: 6.3440\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 5.24762\n",
      "F1 score: 0.40862881083877683\n",
      "Epoch 107/120\n",
      "400/400 [==============================] - 209s 523ms/step - loss: 3.1417 - val_loss: 6.3317\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4114074836470146\n",
      "Epoch 108/120\n",
      "400/400 [==============================] - 211s 529ms/step - loss: 3.1502 - val_loss: 6.3555\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4119724153256654\n",
      "Epoch 109/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1474 - val_loss: 6.3567\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4142926989957313\n",
      "Epoch 110/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1527 - val_loss: 6.3680\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 5.24762\n",
      "F1 score: 0.41387014265680105\n",
      "Epoch 111/120\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 3.1691 - val_loss: 6.0937\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 5.24762\n",
      "F1 score: 0.40909767714583256\n",
      "Epoch 112/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1697 - val_loss: 6.3484\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 5.24762\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "F1 score: 0.4142305586315929\n",
      "Epoch 113/120\n",
      "400/400 [==============================] - 214s 534ms/step - loss: 3.1646 - val_loss: 6.3451\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4142305928655598\n",
      "Epoch 114/120\n",
      "400/400 [==============================] - 214s 535ms/step - loss: 3.1598 - val_loss: 6.3552\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 5.24762\n",
      "F1 score: 0.41356639080363006\n",
      "Epoch 115/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1637 - val_loss: 6.3540\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4141822751530543\n",
      "Epoch 116/120\n",
      "400/400 [==============================] - 212s 529ms/step - loss: 3.1715 - val_loss: 6.3535\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4142959049517682\n",
      "Epoch 117/120\n",
      "400/400 [==============================] - 210s 526ms/step - loss: 3.1659 - val_loss: 6.3551\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 5.24762\n",
      "F1 score: 0.4143759928343739\n",
      "Epoch 118/120\n",
      "400/400 [==============================] - 212s 531ms/step - loss: 3.1623 - val_loss: 6.3526\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 5.24762\n",
      "F1 score: 0.41439733034679616\n",
      "Epoch 119/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.1493 - val_loss: 6.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00119: val_loss did not improve from 5.24762\n",
      "F1 score: 0.39456733114849246\n",
      "Epoch 120/120\n",
      "400/400 [==============================] - 212s 530ms/step - loss: 3.1387 - val_loss: 6.3465\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 5.24762\n",
      "F1 score: 0.414381313873212\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 120\n",
    "steps_per_epoch = 400\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset learning rate to 0.001\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:07<00:00, 27.67it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 27.76it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "# images_dir = data_path + 'pascal_dataset'\n",
    "images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "# predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "predictor_sizes = [(18, 18), (9, 9), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir=data_path + 'history/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5', \n",
    "                                   histogram_freq=0, \n",
    "                                   write_graph=False, \n",
    "                                   write_images=False,\n",
    "                                   update_freq='epoch')\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_300, \n",
    "                      label_val, (1, 1977, 14),\n",
    "                      data_path + 'history/new_net/new_share_conv_conf_cic_f1_a_0.35_e_1_ps_ng_0.5.csv',\n",
    "                      '/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_f1_a_0.35_e_1_ps_ng_0.5.h5')\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             reduce_learning_rate,\n",
    "             f1_callback,\n",
    "             tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 3.6248 - val_loss: 4.6458\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.64579, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.4179762281219451\n",
      "Improve F1 score from -inf to 0.4179762281219451\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 58s 4s/step - loss: 3.6241 - val_loss: 4.6493\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.64579\n",
      "F1 score: 0.4239959715403958\n",
      "Improve F1 score from 0.4179762281219451 to 0.4239959715403958\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.3807 - val_loss: 4.6450\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.64579 to 4.64495, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.4280749972041522\n",
      "Improve F1 score from 0.4239959715403958 to 0.4280749972041522\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.3708 - val_loss: 4.5765\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.64495 to 4.57646, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.39409691599315183\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.3931 - val_loss: 4.6222\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4501720503083246\n",
      "Improve F1 score from 0.4280749972041522 to 0.4501720503083246\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 3.3383 - val_loss: 5.0224\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.57646\n",
      "F1 score: 0.3942478655700129\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 3.1266 - val_loss: 5.1372\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.57646\n",
      "F1 score: 0.39693347221431846\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.2043 - val_loss: 4.7768\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4240134625270408\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.1846 - val_loss: 4.9925\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.57646\n",
      "F1 score: 0.43107412351693375\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 3.1442 - val_loss: 4.9992\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4100094934951353\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.0553 - val_loss: 5.2411\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4099679621078541\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 3.0076 - val_loss: 5.1146\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.57646\n",
      "F1 score: 0.40541921693827454\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.1419 - val_loss: 5.3598\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.57646\n",
      "F1 score: 0.409194291127847\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 3.0589 - val_loss: 5.5064\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.57646\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "F1 score: 0.3848140988974745\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.9279 - val_loss: 5.3240\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.57646\n",
      "F1 score: 0.40652822721469156\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.9404 - val_loss: 5.2684\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4133188404252014\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.9087 - val_loss: 5.2916\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4053577212705359\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.9322 - val_loss: 5.3488\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.57646\n",
      "F1 score: 0.39250551863069283\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.8741 - val_loss: 5.2048\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4221549313271489\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.9263 - val_loss: 5.4584\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4166573696860777\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 58s 4s/step - loss: 2.7014 - val_loss: 5.0800\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.57646\n",
      "F1 score: 0.43920064878396625\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.8044 - val_loss: 5.2017\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.57646\n",
      "F1 score: 0.42362442747843154\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.9402 - val_loss: 5.1929\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.57646\n",
      "F1 score: 0.40136408854028643\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.8221 - val_loss: 5.0321\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.57646\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "F1 score: 0.425205127836387\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.6678 - val_loss: 4.9101\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.57646\n",
      "F1 score: 0.43790466191852756\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7046 - val_loss: 5.0547\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4162167810752112\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.7618 - val_loss: 4.8011\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4195587311967504\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.7843 - val_loss: 4.9224\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.57646\n",
      "F1 score: 0.43278807712418205\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.8627 - val_loss: 5.5756\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.57646\n",
      "F1 score: 0.43421071704611003\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.8346 - val_loss: 4.9110\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4290011527329245\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.7068 - val_loss: 5.1330\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4404674663877428\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7977 - val_loss: 4.8899\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.57646\n",
      "F1 score: 0.422999784254974\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6882 - val_loss: 4.8490\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4.57646\n",
      "F1 score: 0.4429925334106769\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7107 - val_loss: 4.7138\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.57646\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "F1 score: 0.4643783516294074\n",
      "Improve F1 score from 0.4501720503083246 to 0.4643783516294074\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.8488 - val_loss: 4.6334\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4.57646\n",
      "F1 score: 0.460788841514855\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.7766 - val_loss: 4.7116\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4.57646\n",
      "F1 score: 0.45830201755728284\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6828 - val_loss: 4.5506\n",
      "\n",
      "Epoch 00037: val_loss improved from 4.57646 to 4.55057, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.4598003787249426\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6636 - val_loss: 4.6975\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4.55057\n",
      "F1 score: 0.46425010518048626\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.7709 - val_loss: 4.6821\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4.55057\n",
      "F1 score: 0.4610411966171118\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.6116 - val_loss: 5.1917\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4.55057\n",
      "F1 score: 0.4629033584341735\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 65s 4s/step - loss: 2.7848 - val_loss: 4.0190\n",
      "\n",
      "Epoch 00041: val_loss improved from 4.55057 to 4.01900, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_0.35_e_1_ps_ng_0.5.h5\n",
      "F1 score: 0.46291312645017246\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7563 - val_loss: 4.5808\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4.01900\n",
      "F1 score: 0.46505736835551076\n",
      "Improve F1 score from 0.4643783516294074 to 0.46505736835551076\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6875 - val_loss: 4.5197\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4765261180424623\n",
      "Improve F1 score from 0.46505736835551076 to 0.4765261180424623\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7508 - val_loss: 4.4435\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4.01900\n",
      "F1 score: 0.474585639651291\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.8248 - val_loss: 4.4649\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4.01900\n",
      "F1 score: 0.46566848668999594\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7266 - val_loss: 4.9250\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4.01900\n",
      "F1 score: 0.46816765313816816\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7253 - val_loss: 4.5558\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4.01900\n",
      "F1 score: 0.45966959708379773\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7400 - val_loss: 4.4969\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4.01900\n",
      "F1 score: 0.47026870484433714\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6294 - val_loss: 4.4860\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4.01900\n",
      "F1 score: 0.47212311966996473\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7164 - val_loss: 4.4842\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4683773391442356\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7193 - val_loss: 4.4704\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 4.01900\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "F1 score: 0.4712889443887864\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6887 - val_loss: 4.4309\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 4.01900\n",
      "F1 score: 0.47412871336838425\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.6316 - val_loss: 4.4386\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4687762303366955\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6447 - val_loss: 4.4075\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4701859687604887\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.6212 - val_loss: 4.3567\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4.01900\n",
      "F1 score: 0.47446777315144073\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6885 - val_loss: 4.4196\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4728439032040653\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.7466 - val_loss: 4.3469\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4732845043883985\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6624 - val_loss: 4.7244\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 4.01900\n",
      "F1 score: 0.48031381955665625\n",
      "Improve F1 score from 0.4765261180424623 to 0.48031381955665625\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6782 - val_loss: 4.3116\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4824871652354721\n",
      "Improve F1 score from 0.48031381955665625 to 0.4824871652354721\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6081 - val_loss: 4.3108\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4866762284753858\n",
      "Improve F1 score from 0.4824871652354721 to 0.4866762284753858\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6411 - val_loss: 4.2913\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 4.01900\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "F1 score: 0.4802113594334487\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.7404 - val_loss: 4.2848\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4905912296915109\n",
      "Improve F1 score from 0.4866762284753858 to 0.4905912296915109\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6288 - val_loss: 4.2897\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4.01900\n",
      "F1 score: 0.48927111746364516\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.5440 - val_loss: 4.2812\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4898140423075367\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.5867 - val_loss: 4.2686\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4837464907754338\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7859 - val_loss: 4.2454\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4852993912989612\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.7842 - val_loss: 4.2310\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4858481359129566\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.5563 - val_loss: 4.2311\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4934003030512597\n",
      "Improve F1 score from 0.4905912296915109 to 0.4934003030512597\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.6271 - val_loss: 4.2208\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 4.01900\n",
      "F1 score: 0.49485058518336744\n",
      "Improve F1 score from 0.4934003030512597 to 0.49485058518336744\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.6436 - val_loss: 4.2258\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 4.01900\n",
      "F1 score: 0.495202846008256\n",
      "Improve F1 score from 0.49485058518336744 to 0.495202846008256\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7490 - val_loss: 4.2240\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 4.01900\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "F1 score: 0.5007127462640509\n",
      "Improve F1 score from 0.495202846008256 to 0.5007127462640509\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.7173 - val_loss: 4.2224\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 4.01900\n",
      "F1 score: 0.49978329683266715\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.6976 - val_loss: 4.2145\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4942492161978123\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7156 - val_loss: 4.2061\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 4.01900\n",
      "F1 score: 0.49449843091543\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6014 - val_loss: 4.1938\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 4.01900\n",
      "F1 score: 0.4963537278349513\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.7173 - val_loss: 4.1884\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5024838875938483\n",
      "Improve F1 score from 0.5007127462640509 to 0.5024838875938483\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.5958 - val_loss: 4.1852\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5030824358301523\n",
      "Improve F1 score from 0.5024838875938483 to 0.5030824358301523\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.5747 - val_loss: 4.2485\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5035100759087973\n",
      "Improve F1 score from 0.5030824358301523 to 0.5035100759087973\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.6408 - val_loss: 4.1711\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5063893362047655\n",
      "Improve F1 score from 0.5035100759087973 to 0.5063893362047655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7650 - val_loss: 4.1644\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 4.01900\n",
      "F1 score: 0.513686556931954\n",
      "Improve F1 score from 0.5063893362047655 to 0.513686556931954\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.6128 - val_loss: 4.1603\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 4.01900\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "F1 score: 0.5176043289367916\n",
      "Improve F1 score from 0.513686556931954 to 0.5176043289367916\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.6536 - val_loss: 4.2225\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5180819660160568\n",
      "Improve F1 score from 0.5176043289367916 to 0.5180819660160568\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6202 - val_loss: 4.2184\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5184470324817241\n",
      "Improve F1 score from 0.5180819660160568 to 0.5184470324817241\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6362 - val_loss: 4.1446\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5188053736175523\n",
      "Improve F1 score from 0.5184470324817241 to 0.5188053736175523\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.5717 - val_loss: 4.1392\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5219267217827721\n",
      "Improve F1 score from 0.5188053736175523 to 0.5219267217827721\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6564 - val_loss: 4.1346\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5222636212239823\n",
      "Improve F1 score from 0.5219267217827721 to 0.5222636212239823\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.7188 - val_loss: 4.7466\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5208032271317508\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6188 - val_loss: 4.1927\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 4.01900\n",
      "F1 score: 0.525155731630477\n",
      "Improve F1 score from 0.5222636212239823 to 0.525155731630477\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6390 - val_loss: 4.1222\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5249090049952413\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.7713 - val_loss: 4.1185\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5251173043986365\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6981 - val_loss: 4.1111\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 4.01900\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "F1 score: 0.5237021481943054\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.7178 - val_loss: 4.1069\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5235504767658031\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.6399 - val_loss: 4.1020\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 4.01900\n",
      "F1 score: 0.524205427982079\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.6096 - val_loss: 4.0980\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5245519463396983\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.8174 - val_loss: 4.0946\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5249796209950139\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6575 - val_loss: 4.0918\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5250981477701347\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.7902 - val_loss: 4.0892\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5280396433642932\n",
      "Improve F1 score from 0.525155731630477 to 0.5280396433642932\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 58s 4s/step - loss: 2.7169 - val_loss: 4.0871\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 4.01900\n",
      "F1 score: 0.529247507987459\n",
      "Improve F1 score from 0.5280396433642932 to 0.529247507987459\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.5811 - val_loss: 4.0852\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5296832897808077\n",
      "Improve F1 score from 0.529247507987459 to 0.5296832897808077\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.7064 - val_loss: 4.0840\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 4.01900\n",
      "F1 score: 0.5297439418062108\n",
      "Improve F1 score from 0.5296832897808077 to 0.5297439418062108\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 100\n",
    "steps_per_epoch = 15\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
