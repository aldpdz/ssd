{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSDLite300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssdlite320PPN_mobilenetv2 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = new_scales\n",
    "aspect_ratios = [[1.0, 0.5, 2.0/3.0],\n",
    "                 [1.0, 0.5, 2.0/3.0, 1.0/3.0, 3.0/4.0],\n",
    "                 [1.0, 0.5, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 2.0/3.0, 1.0/3.0]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True\n",
    "size_classifier = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                alpha=1.0,\n",
    "                expansion=1,\n",
    "                mode='training',\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             558656      input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_expand (Conv2D)     (None, 18, 18, 96)   9216        model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_expand (BatchNorma (None, 18, 18, 96)   384         mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 18, 18, 96)   0           bn13_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_depthwise (Depthwis (None, 18, 18, 96)   864         conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_depthwise (BatchNorma (None, 18, 18, 96)   384         mobl13_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 18, 18, 96)   0           bn13_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_project (Conv2D)    (None, 18, 18, 160)  15360       conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl13_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_expand (Conv2D)     (None, 18, 18, 160)  25600       bn13_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_expand (BatchNorma (None, 18, 18, 160)  640         mobl14_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu (Activation)       (None, 18, 18, 160)  0           bn14_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_depthwise (Depthwis (None, 18, 18, 160)  1440        conv_14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_depthwise (BatchNorma (None, 18, 18, 160)  640         mobl14_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_relu (Activation)    (None, 18, 18, 160)  0           bn14_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_project (Conv2D)    (None, 18, 18, 160)  25600       conv_dw_14_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl14_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_14 (Add)            (None, 18, 18, 160)  0           bn13_conv_bn_project[0][0]       \n",
      "                                                                 bn14_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_expand (Conv2D)     (None, 18, 18, 160)  25600       res_connect_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_expand (BatchNorma (None, 18, 18, 160)  640         mobl15_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu (Activation)       (None, 18, 18, 160)  0           bn15_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_depthwise (Depthwis (None, 18, 18, 160)  1440        conv_15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_depthwise (BatchNorma (None, 18, 18, 160)  640         mobl15_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_relu (Activation)    (None, 18, 18, 160)  0           bn15_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_project (Conv2D)    (None, 18, 18, 160)  25600       conv_dw_15_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl15_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_15 (Add)            (None, 18, 18, 160)  0           res_connect_14[0][0]             \n",
      "                                                                 bn15_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_expand (Conv2D)     (None, 18, 18, 160)  25600       res_connect_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_expand (BatchNorma (None, 18, 18, 160)  640         mobl16_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu (Activation)       (None, 18, 18, 160)  0           bn16_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_depthwise (Depthwis (None, 18, 18, 160)  1440        conv_16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_depthwise (BatchNorma (None, 18, 18, 160)  640         mobl16_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16_relu (Activation)    (None, 18, 18, 160)  0           bn16_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_project (Conv2D)    (None, 18, 18, 320)  51200       conv_dw_16_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_project (BatchNorm (None, 18, 18, 320)  1280        mobl16_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 9, 9, 1280)   409600      bn16_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 9, 9, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_relu (Activation)        (None, 9, 9, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Conv_features (Conv2D)          (None, 9, 9, 256)    327680      Conv_1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn_features (BatchNormalization (None, 9, 9, 256)    1024        Conv_features[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu_features (Activation)      (None, 9, 9, 256)    0           bn_features[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_17 (MaxPooling2D)       (None, 5, 5, 256)    0           relu_features[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_18_2 (MaxPooling2D)     (None, 3, 3, 256)    0           maxpool_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_19_2 (MaxPooling2D)     (None, 2, 2, 256)    0           maxpool_18_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_20_2 (MaxPooling2D)     (None, 1, 1, 256)    0           maxpool_19_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_tower (Conv2D)             multiple             131072      maxpool_17[0][0]                 \n",
      "                                                                 maxpool_18_2[0][0]               \n",
      "                                                                 maxpool_19_2[0][0]               \n",
      "                                                                 maxpool_20_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn_tower (BatchNormalization)   multiple             2048        conv_tower[0][0]                 \n",
      "                                                                 conv_tower[1][0]                 \n",
      "                                                                 conv_tower[2][0]                 \n",
      "                                                                 conv_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "relu_tower (Activation)         multiple             0           bn_tower[0][0]                   \n",
      "                                                                 bn_tower[1][0]                   \n",
      "                                                                 bn_tower[2][0]                   \n",
      "                                                                 bn_tower[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 18, 18, 8)    6920        mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf (Conv2D)       (None, 9, 9, 12)     138252      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "shared_mbox_conf (Conv2D)       multiple             46090       relu_tower[0][0]                 \n",
      "                                                                 relu_tower[1][0]                 \n",
      "                                                                 relu_tower[2][0]                 \n",
      "                                                                 relu_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 18, 18, 16)   13840       mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc (Conv2D)        (None, 9, 9, 24)     276504      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "shared_mbox_loc (Conv2D)        multiple             92180       relu_tower[0][0]                 \n",
      "                                                                 relu_tower[1][0]                 \n",
      "                                                                 relu_tower[2][0]                 \n",
      "                                                                 relu_tower[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1296, 2)      0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 486, 2)       0           conv17_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 125, 2)       0           shared_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 45, 2)        0           shared_mbox_conf[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 20, 2)        0           shared_mbox_conf[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 5, 2)         0           shared_mbox_conf[3][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 18, 18, 4, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox (AnchorBox (None, 9, 9, 6, 8)   0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox (AnchorB (None, 5, 5, 5, 8)   0           shared_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox (AnchorB (None, 3, 3, 5, 8)   0           shared_mbox_loc[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox (AnchorB (None, 2, 2, 5, 8)   0           shared_mbox_loc[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox (AnchorB (None, 1, 1, 5, 8)   0           shared_mbox_loc[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 1977, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1296, 4)      0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 486, 4)       0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 125, 4)       0           shared_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 45, 4)        0           shared_mbox_loc[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 20, 4)        0           shared_mbox_loc[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 5, 4)         0           shared_mbox_loc[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 1296, 8)      0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox_reshape (R (None, 486, 8)       0           conv17_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox_reshape  (None, 125, 8)       0           conv18_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox_reshape  (None, 45, 8)        0           conv19_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox_reshape  (None, 20, 8)        0           conv20_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox_reshape  (None, 5, 8)         0           conv21_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 1977, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 1977, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 1977, 8)      0           conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv17_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv18_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv19_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv20_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv21_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 1977, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,225,754\n",
      "Trainable params: 2,201,626\n",
      "Non-trainable params: 24,128\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:30<00:00, 208.99it/s]\n",
      "Loading images into memory: 100%|██████████| 2097/2097 [00:09<00:00, 216.79it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "images_dir = data_path + 'pascal_dataset'\n",
    "# images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "# predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "predictor_sizes = [(18, 18), (9, 9), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.6,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val.npy')\n",
    "val_images_300 = np.load('../data-cic/preprocess_data/images_val_300x300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir=data_path + 'history/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5', \n",
    "                                   histogram_freq=0, \n",
    "                                   write_graph=False, \n",
    "                                   write_images=False,\n",
    "                                   update_freq='epoch')\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_300, \n",
    "                      label_val, (1, 1977, 14),\n",
    "                      data_path + 'history/new_net/new_share_conv_conf_pascal_f1_a_1.0_e_1_ps_0.6_ng_0.5.csv',\n",
    "                      '/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_f1_a_1.0_e_1_ps_0.6_ng_0.5.h5')\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             reduce_learning_rate,\n",
    "             f1_callback,\n",
    "             tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 8.3028 - val_loss: 7.2161\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.21614, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.1846546259283402\n",
      "Improve F1 score from -inf to 0.1846546259283402\n",
      "Epoch 2/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 4.3024 - val_loss: 6.4653\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.21614 to 6.46528, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.1865561942164499\n",
      "Improve F1 score from 0.1846546259283402 to 0.1865561942164499\n",
      "Epoch 3/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 4.1766 - val_loss: 6.4101\n",
      "\n",
      "Epoch 00003: val_loss improved from 6.46528 to 6.41009, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.12799487056419298\n",
      "Epoch 4/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 3.8801 - val_loss: 9.0080\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 6.41009\n",
      "F1 score: 0.1589379159517374\n",
      "Epoch 5/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 3.7887 - val_loss: 6.3450\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.41009 to 6.34498, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.1531293889425638\n",
      "Epoch 6/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 3.7024 - val_loss: 6.3718\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 6.34498\n",
      "F1 score: 0.15432229130066016\n",
      "Epoch 7/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 3.6514 - val_loss: 6.5193\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 6.34498\n",
      "F1 score: 0.2709633944566136\n",
      "Improve F1 score from 0.1865561942164499 to 0.2709633944566136\n",
      "Epoch 8/120\n",
      "400/400 [==============================] - 217s 544ms/step - loss: 3.6141 - val_loss: 6.6940\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 6.34498\n",
      "F1 score: 0.20018615878215335\n",
      "Epoch 9/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 3.5758 - val_loss: 6.2354\n",
      "\n",
      "Epoch 00009: val_loss improved from 6.34498 to 6.23538, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.1558348540254358\n",
      "Epoch 10/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 3.8461 - val_loss: 8.5261\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 6.23538\n",
      "F1 score: 0.09302486050243547\n",
      "Epoch 11/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 3.4929 - val_loss: 6.2416\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 6.23538\n",
      "F1 score: 0.30992680215533375\n",
      "Improve F1 score from 0.2709633944566136 to 0.30992680215533375\n",
      "Epoch 12/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 3.4676 - val_loss: 5.8143\n",
      "\n",
      "Epoch 00012: val_loss improved from 6.23538 to 5.81429, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.2236484998608387\n",
      "Epoch 13/120\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 3.4295 - val_loss: 5.7011\n",
      "\n",
      "Epoch 00013: val_loss improved from 5.81429 to 5.70115, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.41280476065802596\n",
      "Improve F1 score from 0.30992680215533375 to 0.41280476065802596\n",
      "Epoch 14/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 3.3542 - val_loss: 6.3087\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.70115\n",
      "F1 score: 0.4184119868748303\n",
      "Improve F1 score from 0.41280476065802596 to 0.4184119868748303\n",
      "Epoch 15/120\n",
      "400/400 [==============================] - 211s 528ms/step - loss: 3.3876 - val_loss: 6.2626\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.70115\n",
      "F1 score: 0.4050818142711113\n",
      "Epoch 16/120\n",
      "400/400 [==============================] - 221s 551ms/step - loss: 3.3588 - val_loss: 5.5564\n",
      "\n",
      "Epoch 00016: val_loss improved from 5.70115 to 5.55643, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_pascal_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.44996540775164173\n",
      "Improve F1 score from 0.4184119868748303 to 0.44996540775164173\n",
      "Epoch 17/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 3.3159 - val_loss: 7.5071\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.55643\n",
      "F1 score: 0.42880666415228075\n",
      "Epoch 18/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 3.3124 - val_loss: 5.7051\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.55643\n",
      "F1 score: 0.3968908387006378\n",
      "Epoch 19/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 3.2859 - val_loss: 5.9285\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.55643\n",
      "F1 score: 0.3508833047571785\n",
      "Epoch 20/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 3.3066 - val_loss: 6.0270\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4252060081408222\n",
      "Epoch 21/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 3.2971 - val_loss: 6.2957\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 5.55643\n",
      "F1 score: 0.38800718851844834\n",
      "Epoch 22/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 3.2297 - val_loss: 6.2164\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 5.55643\n",
      "F1 score: 0.348201320903808\n",
      "Epoch 23/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 3.2294 - val_loss: 5.9553\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 5.55643\n",
      "F1 score: 0.3615745410658127\n",
      "Epoch 24/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 3.2426 - val_loss: 6.1595\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 5.55643\n",
      "F1 score: 0.3819051973303818\n",
      "Epoch 25/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 3.1881 - val_loss: 6.1059\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 5.55643\n",
      "F1 score: 0.419327009161509\n",
      "Epoch 26/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 3.2285 - val_loss: 6.0017\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "F1 score: 0.44820277438586525\n",
      "Epoch 27/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 3.0719 - val_loss: 5.8603\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 5.55643\n",
      "F1 score: 0.45722141801330657\n",
      "Improve F1 score from 0.44996540775164173 to 0.45722141801330657\n",
      "Epoch 28/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 3.0558 - val_loss: 5.7018\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4772860594483371\n",
      "Improve F1 score from 0.45722141801330657 to 0.4772860594483371\n",
      "Epoch 29/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.9932 - val_loss: 5.9104\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 5.55643\n",
      "F1 score: 0.44172980358745917\n",
      "Epoch 30/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 3.0073 - val_loss: 5.9660\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4647792235435711\n",
      "Epoch 31/120\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.9989 - val_loss: 5.9462\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 5.55643\n",
      "F1 score: 0.40843145500400824\n",
      "Epoch 32/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.9830 - val_loss: 6.0062\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 5.55643\n",
      "F1 score: 0.47216235582394106\n",
      "Epoch 33/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 2.9939 - val_loss: 6.0722\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4443584912903964\n",
      "Epoch 34/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.9450 - val_loss: 5.8065\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4532845750406556\n",
      "Epoch 35/120\n",
      "400/400 [==============================] - 220s 549ms/step - loss: 2.9415 - val_loss: 5.8186\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4677451949685888\n",
      "Epoch 36/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 217s 542ms/step - loss: 2.9264 - val_loss: 6.0215\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "F1 score: 0.4825652004819685\n",
      "Improve F1 score from 0.4772860594483371 to 0.4825652004819685\n",
      "Epoch 37/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.8275 - val_loss: 5.6618\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4630524684960102\n",
      "Epoch 38/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.8378 - val_loss: 5.6767\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4816292317230594\n",
      "Epoch 39/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.8321 - val_loss: 5.7109\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4801503261918906\n",
      "Epoch 40/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.8113 - val_loss: 5.9056\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 5.55643\n",
      "F1 score: 0.47210959171822736\n",
      "Epoch 41/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.8245 - val_loss: 6.0270\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4995385737828898\n",
      "Improve F1 score from 0.4825652004819685 to 0.4995385737828898\n",
      "Epoch 42/120\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.8163 - val_loss: 5.8070\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 5.55643\n",
      "F1 score: 0.489924682612845\n",
      "Epoch 43/120\n",
      "400/400 [==============================] - 221s 552ms/step - loss: 2.8285 - val_loss: 5.9464\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49842464300510353\n",
      "Epoch 44/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 2.8027 - val_loss: 6.1694\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4901683452601852\n",
      "Epoch 45/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.8350 - val_loss: 6.1363\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 5.55643\n",
      "F1 score: 0.508060516200954\n",
      "Improve F1 score from 0.4995385737828898 to 0.508060516200954\n",
      "Epoch 46/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.7730 - val_loss: 6.0336\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "F1 score: 0.47612313537675993\n",
      "Epoch 47/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.7869 - val_loss: 6.7185\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49074598934357155\n",
      "Epoch 48/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.7479 - val_loss: 6.1517\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4908195006196053\n",
      "Epoch 49/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.7275 - val_loss: 5.9817\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49119828677695754\n",
      "Epoch 50/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.7260 - val_loss: 5.8986\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5018103206439697\n",
      "Epoch 51/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.7515 - val_loss: 5.8199\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4986108884962968\n",
      "Epoch 52/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.7442 - val_loss: 6.0222\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4863855448745792\n",
      "Epoch 53/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.7220 - val_loss: 5.9606\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4922057853369994\n",
      "Epoch 54/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7270 - val_loss: 5.8846\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4925728120237729\n",
      "Epoch 55/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.7287 - val_loss: 5.8444\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 5.55643\n",
      "F1 score: 0.485436486282713\n",
      "Epoch 56/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7080 - val_loss: 6.0482\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "F1 score: 0.5060536568216305\n",
      "Epoch 57/120\n",
      "400/400 [==============================] - 217s 544ms/step - loss: 2.7095 - val_loss: 6.0094\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4991142510649064\n",
      "Epoch 58/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.7005 - val_loss: 5.9668\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49085276663671573\n",
      "Epoch 59/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.6991 - val_loss: 6.0403\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49125936846714835\n",
      "Epoch 60/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6798 - val_loss: 5.9702\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49430270791115083\n",
      "Epoch 61/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.6916 - val_loss: 5.9767\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4994817388503497\n",
      "Epoch 62/120\n",
      "400/400 [==============================] - 217s 541ms/step - loss: 2.6808 - val_loss: 6.0541\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4903620456831205\n",
      "Epoch 63/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.6808 - val_loss: 6.1189\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5016129968609622\n",
      "Epoch 64/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6754 - val_loss: 6.0198\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5005122632530303\n",
      "Epoch 65/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.7051 - val_loss: 6.0339\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49779588213380843\n",
      "Epoch 66/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6812 - val_loss: 6.1040\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "F1 score: 0.5012252892920533\n",
      "Epoch 67/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.6920 - val_loss: 6.0952\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5075833378285562\n",
      "Epoch 68/120\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.6984 - val_loss: 6.1157\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4952585137701015\n",
      "Epoch 69/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6630 - val_loss: 6.0844\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4920741148619921\n",
      "Epoch 70/120\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.6654 - val_loss: 6.0662\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5011604787288476\n",
      "Epoch 71/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6751 - val_loss: 6.0217\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49634583153208556\n",
      "Epoch 72/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.6819 - val_loss: 6.0376\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49538136882695477\n",
      "Epoch 73/120\n",
      "400/400 [==============================] - 219s 548ms/step - loss: 2.6728 - val_loss: 5.7843\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4883799031706943\n",
      "Epoch 74/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.6821 - val_loss: 6.0289\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 5.55643\n",
      "F1 score: 0.48931928035269107\n",
      "Epoch 75/120\n",
      "400/400 [==============================] - 217s 544ms/step - loss: 2.6812 - val_loss: 6.0086\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4999133662164742\n",
      "Epoch 76/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6608 - val_loss: 6.0302\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5018005695299635\n",
      "Epoch 77/120\n",
      "400/400 [==============================] - 217s 541ms/step - loss: 2.6555 - val_loss: 6.0697\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 5.55643\n",
      "F1 score: 0.501970324163039\n",
      "Epoch 78/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6579 - val_loss: 6.0384\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49983978229861287\n",
      "Epoch 79/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6549 - val_loss: 6.0853\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5001790507814097\n",
      "Epoch 80/120\n",
      "400/400 [==============================] - 215s 537ms/step - loss: 2.6709 - val_loss: 6.0906\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 5.55643\n",
      "F1 score: 0.50220997820981\n",
      "Epoch 81/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6345 - val_loss: 5.6497\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49989248981754564\n",
      "Epoch 82/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6719 - val_loss: 6.0669\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4944594296852902\n",
      "Epoch 83/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6457 - val_loss: 6.0902\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 5.55643\n",
      "F1 score: 0.491670515747064\n",
      "Epoch 84/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.6364 - val_loss: 6.0758\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49493844874082454\n",
      "Epoch 85/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6719 - val_loss: 6.0907\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4994055546152533\n",
      "Epoch 86/120\n",
      "400/400 [==============================] - 217s 541ms/step - loss: 2.6605 - val_loss: 6.0961\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "F1 score: 0.49520866207043585\n",
      "Epoch 87/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6276 - val_loss: 6.1020\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49841065841321197\n",
      "Epoch 88/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6661 - val_loss: 6.1175\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5031622009128127\n",
      "Epoch 89/120\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.6875 - val_loss: 6.0833\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49689913984668005\n",
      "Epoch 90/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6558 - val_loss: 6.0938\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5034963811708374\n",
      "Epoch 91/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6557 - val_loss: 6.0841\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5010718576202559\n",
      "Epoch 92/120\n",
      "400/400 [==============================] - 220s 549ms/step - loss: 2.6221 - val_loss: 6.0936\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4976183855255266\n",
      "Epoch 93/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6577 - val_loss: 6.1068\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49681354174430625\n",
      "Epoch 94/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6456 - val_loss: 6.0940\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49612448766680917\n",
      "Epoch 95/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6669 - val_loss: 6.0895\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5037846176711351\n",
      "Epoch 96/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6506 - val_loss: 6.3429\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "F1 score: 0.4958417783058744\n",
      "Epoch 97/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6469 - val_loss: 6.0952\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49608402448226313\n",
      "Epoch 98/120\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.6515 - val_loss: 6.0860\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49715359161014844\n",
      "Epoch 99/120\n",
      "400/400 [==============================] - 214s 536ms/step - loss: 2.6362 - val_loss: 6.0756\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49728725584258987\n",
      "Epoch 100/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6445 - val_loss: 6.0812\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5007773517545403\n",
      "Epoch 101/120\n",
      "400/400 [==============================] - 218s 545ms/step - loss: 2.6445 - val_loss: 6.0960\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4981918111916262\n",
      "Epoch 102/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.6325 - val_loss: 6.0990\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49784586723994917\n",
      "Epoch 103/120\n",
      "400/400 [==============================] - 219s 546ms/step - loss: 2.6527 - val_loss: 6.1105\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4978451181942816\n",
      "Epoch 104/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6304 - val_loss: 6.0984\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4981269862785345\n",
      "Epoch 105/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6425 - val_loss: 6.1088\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5000047005264416\n",
      "Epoch 106/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.6372 - val_loss: 6.1564\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 5.55643\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "F1 score: 0.4974447478197171\n",
      "Epoch 107/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6211 - val_loss: 6.1033\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49703918150060294\n",
      "Epoch 108/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6492 - val_loss: 6.3231\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49726252923868935\n",
      "Epoch 109/120\n",
      "400/400 [==============================] - 218s 546ms/step - loss: 2.6483 - val_loss: 6.0967\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4972245091230809\n",
      "Epoch 110/120\n",
      "400/400 [==============================] - 218s 544ms/step - loss: 2.6659 - val_loss: 6.0997\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4971606519078832\n",
      "Epoch 111/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6460 - val_loss: 6.1025\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49829240981227896\n",
      "Epoch 112/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6221 - val_loss: 6.0964\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4974903515857474\n",
      "Epoch 113/120\n",
      "400/400 [==============================] - 217s 543ms/step - loss: 2.6491 - val_loss: 6.0935\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49856207786171647\n",
      "Epoch 114/120\n",
      "400/400 [==============================] - 217s 542ms/step - loss: 2.6035 - val_loss: 6.0939\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 5.55643\n",
      "F1 score: 0.4984141978824023\n",
      "Epoch 115/120\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.6740 - val_loss: 6.0950\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49823163799541537\n",
      "Epoch 116/120\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 2.6705 - val_loss: 6.0933\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 5.55643\n",
      "F1 score: 0.49766650237337606\n",
      "Epoch 117/120\n",
      "400/400 [==============================] - 216s 541ms/step - loss: 2.6619 - val_loss: 6.0937\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5003192352530876\n",
      "Epoch 118/120\n",
      "400/400 [==============================] - 215s 538ms/step - loss: 2.6397 - val_loss: 6.0888\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5001096459549113\n",
      "Epoch 119/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 217s 541ms/step - loss: 2.6366 - val_loss: 6.0858\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5000444714032621\n",
      "Epoch 120/120\n",
      "400/400 [==============================] - 216s 540ms/step - loss: 2.6451 - val_loss: 6.0774\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 5.55643\n",
      "F1 score: 0.5001508373001626\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 120\n",
    "steps_per_epoch = 400\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset learning rate to 0.001\n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:07<00:00, 27.97it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 27.68it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "# images_dir = data_path + 'udacity_driving_datasets'\n",
    "# images_dir = data_path + 'pascal_dataset'\n",
    "images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/udc.csv'\n",
    "# train_labels_filename = preprocess_path + '/cic_pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/cic_pascal_val.csv'\n",
    "# train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "# val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Optional: Convert the dataset into an HDF5 dataset. This will require more disk space, but will\n",
    "# speed up the training. Doing this is not relevant in case you activated the `load_images_into_memory`\n",
    "# option in the constructor, because in that cas the images are in memory already anyway. If you don't\n",
    "# want to create HDF5 datasets, comment out the subsequent two function calls.\n",
    "\n",
    "# train_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_train.h5',\n",
    "#                                   resize=False,\n",
    "#                                   variable_image_size=True,\n",
    "#                                   verbose=True)\n",
    "\n",
    "# val_dataset.create_hdf5_dataset(file_path='dataset_udacity_traffic_val.h5',\n",
    "#                                 resize=False,\n",
    "#                                 variable_image_size=True,\n",
    "#                                 verbose=True)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "# predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "#                    model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "predictor_sizes = [(18, 18), (9, 9), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.6,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the model.\n",
    "model_checkpoint = ModelCheckpoint(filepath='/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename=data_path + 'history/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                         factor=0.5,\n",
    "                                         patience=10,\n",
    "                                         verbose=1,\n",
    "                                         min_delta=0.001,\n",
    "                                         cooldown=0,\n",
    "                                         min_lr=0.000001)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir=data_path + 'history/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5', \n",
    "                                   histogram_freq=0, \n",
    "                                   write_graph=False, \n",
    "                                   write_images=False,\n",
    "                                   update_freq='epoch')\n",
    "\n",
    "f1_callback = f1_call(0.20, \n",
    "                      0.45, \n",
    "                      200, \n",
    "                      normalize_coords, \n",
    "                      img_height, \n",
    "                      img_width, \n",
    "                      val_images_300, \n",
    "                      label_val, (1, 1977, 14),\n",
    "                      data_path + 'history/new_net/new_share_conv_conf_cic_f1_a_1.0_e_1_ps_0.6_ng_0.5.csv',\n",
    "                      '/home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_f1_a_1.0_e_1_ps_0.6_ng_0.5.h5')\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             reduce_learning_rate,\n",
    "             f1_callback,\n",
    "             tbCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 67s 4s/step - loss: 3.7976 - val_loss: 3.8489\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.84893, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5551128088251638\n",
      "Improve F1 score from -inf to 0.5551128088251638\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 3.2883 - val_loss: 3.6780\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.84893 to 3.67796, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.565694846216734\n",
      "Improve F1 score from 0.5551128088251638 to 0.565694846216734\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 3.0651 - val_loss: 3.8893\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5268576084955289\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 3.0715 - val_loss: 3.8543\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5379744609788939\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 3.1520 - val_loss: 3.7424\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5677732246811937\n",
      "Improve F1 score from 0.565694846216734 to 0.5677732246811937\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 3.1098 - val_loss: 3.8777\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5156943336184864\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.9604 - val_loss: 3.8688\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5335110630146315\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.9016 - val_loss: 3.7738\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5150939344734164\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.8534 - val_loss: 3.9820\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5232047759610566\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.6783 - val_loss: 4.1576\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5292968947668356\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.9966 - val_loss: 4.0587\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5256586113315629\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.6275 - val_loss: 4.3841\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.67796\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "F1 score: 0.45618236291709546\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6480 - val_loss: 4.1645\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.67796\n",
      "F1 score: 0.5005761953873078\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.4616 - val_loss: 4.1519\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.67796\n",
      "F1 score: 0.4633033399466557\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.6071 - val_loss: 4.1220\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.67796\n",
      "F1 score: 0.45529285213868087\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.5315 - val_loss: 4.2481\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.67796\n",
      "F1 score: 0.43878407666709673\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.5769 - val_loss: 4.0918\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.67796\n",
      "F1 score: 0.46122812482175013\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.4804 - val_loss: 4.0933\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.67796\n",
      "F1 score: 0.48223229458304834\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.5476 - val_loss: 4.0500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.67796\n",
      "F1 score: 0.4819887866735427\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.5522 - val_loss: 3.9886\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.67796\n",
      "F1 score: 0.501483888261228\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.4719 - val_loss: 4.0062\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.67796\n",
      "F1 score: 0.46961533204291717\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.4439 - val_loss: 3.9334\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.67796\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "F1 score: 0.4731219602586056\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.4188 - val_loss: 3.8491\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.67796\n",
      "F1 score: 0.4720838291071452\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.2910 - val_loss: 3.8630\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.67796\n",
      "F1 score: 0.4801463461870358\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.3550 - val_loss: 3.7613\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.67796\n",
      "F1 score: 0.4936549302199482\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.4045 - val_loss: 3.7195\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.67796\n",
      "F1 score: 0.49344799623270874\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.3811 - val_loss: 3.6139\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.67796 to 3.61392, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5239140877704392\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.3371 - val_loss: 3.7258\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.61392\n",
      "F1 score: 0.491427431848608\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2151 - val_loss: 3.6337\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.61392\n",
      "F1 score: 0.527047003771808\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3773 - val_loss: 3.6105\n",
      "\n",
      "Epoch 00030: val_loss improved from 3.61392 to 3.61051, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5116369138539885\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3482 - val_loss: 3.6381\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.61051\n",
      "F1 score: 0.5129301199652051\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3127 - val_loss: 3.5432\n",
      "\n",
      "Epoch 00032: val_loss improved from 3.61051 to 3.54319, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5339314691620923\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.2415 - val_loss: 3.5902\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5246180261863824\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2555 - val_loss: 3.5962\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5094997603735036\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.3722 - val_loss: 3.6558\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5160150880248148\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.3732 - val_loss: 3.6247\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5104453214261917\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2451 - val_loss: 3.6284\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5230770407244646\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1225 - val_loss: 3.5441\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5487510958832049\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.3232 - val_loss: 3.5594\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.54319\n",
      "F1 score: 0.5220668773956086\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3628 - val_loss: 3.4927\n",
      "\n",
      "Epoch 00040: val_loss improved from 3.54319 to 3.49269, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5270571064971726\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.3803 - val_loss: 3.4030\n",
      "\n",
      "Epoch 00041: val_loss improved from 3.49269 to 3.40298, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5757506924029524\n",
      "Improve F1 score from 0.5677732246811937 to 0.5757506924029524\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2839 - val_loss: 3.4263\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.40298\n",
      "F1 score: 0.544837116281343\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1965 - val_loss: 3.4846\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.40298\n",
      "F1 score: 0.5610766346753725\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.3359 - val_loss: 3.5365\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.40298\n",
      "F1 score: 0.5464448546893831\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1476 - val_loss: 3.4648\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.40298\n",
      "F1 score: 0.5543532414777196\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 70s 5s/step - loss: 2.3426 - val_loss: 3.4600\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.40298\n",
      "F1 score: 0.5355184374028313\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2111 - val_loss: 3.3803\n",
      "\n",
      "Epoch 00047: val_loss improved from 3.40298 to 3.38032, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5604976636686956\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.3385 - val_loss: 3.3783\n",
      "\n",
      "Epoch 00048: val_loss improved from 3.38032 to 3.37827, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5679943161127604\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.3251 - val_loss: 3.5068\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.37827\n",
      "F1 score: 0.5586279999435194\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.1475 - val_loss: 3.4195\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.37827\n",
      "F1 score: 0.56062728683473\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.3102 - val_loss: 3.4398\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.37827\n",
      "F1 score: 0.5531156666391636\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.2900 - val_loss: 3.3083\n",
      "\n",
      "Epoch 00052: val_loss improved from 3.37827 to 3.30826, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5821481135993148\n",
      "Improve F1 score from 0.5757506924029524 to 0.5821481135993148\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.2264 - val_loss: 3.4247\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.30826\n",
      "F1 score: 0.564546059966011\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.2793 - val_loss: 3.2979\n",
      "\n",
      "Epoch 00054: val_loss improved from 3.30826 to 3.29789, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5909655945824003\n",
      "Improve F1 score from 0.5821481135993148 to 0.5909655945824003\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1901 - val_loss: 3.3928\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5745355476613474\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.1583 - val_loss: 3.4277\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5742819518350242\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1916 - val_loss: 3.3328\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5825190204307498\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.3005 - val_loss: 3.3581\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.29789\n",
      "F1 score: 0.581938431300792\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2456 - val_loss: 3.3613\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5810936596934513\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1161 - val_loss: 3.3763\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5895921200158212\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.2006 - val_loss: 3.3243\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5857684843355369\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.0914 - val_loss: 3.3285\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5917753394489641\n",
      "Improve F1 score from 0.5909655945824003 to 0.5917753394489641\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.2485 - val_loss: 3.3692\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5691686475315082\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1027 - val_loss: 3.3243\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.29789\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "F1 score: 0.5786987637181169\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0660 - val_loss: 3.3407\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5777401276834847\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0414 - val_loss: 3.3446\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.29789\n",
      "F1 score: 0.5847396741631016\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0756 - val_loss: 3.2930\n",
      "\n",
      "Epoch 00067: val_loss improved from 3.29789 to 3.29299, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5873143168144473\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0687 - val_loss: 3.2483\n",
      "\n",
      "Epoch 00068: val_loss improved from 3.29299 to 3.24827, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5977722555354795\n",
      "Improve F1 score from 0.5917753394489641 to 0.5977722555354795\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.1180 - val_loss: 3.2743\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.24827\n",
      "F1 score: 0.5882551624419964\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.0690 - val_loss: 3.3509\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.24827\n",
      "F1 score: 0.5946286026225988\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0273 - val_loss: 3.2298\n",
      "\n",
      "Epoch 00071: val_loss improved from 3.24827 to 3.22979, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.5950790669759168\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.1935 - val_loss: 3.2179\n",
      "\n",
      "Epoch 00072: val_loss improved from 3.22979 to 3.21786, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.602161221673728\n",
      "Improve F1 score from 0.5977722555354795 to 0.602161221673728\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1501 - val_loss: 3.2230\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.21786\n",
      "F1 score: 0.5998778137167482\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0708 - val_loss: 3.2034\n",
      "\n",
      "Epoch 00074: val_loss improved from 3.21786 to 3.20345, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6019804871675405\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 61s 4s/step - loss: 2.0924 - val_loss: 3.2925\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.20345\n",
      "F1 score: 0.6004075861413728\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.1005 - val_loss: 3.1857\n",
      "\n",
      "Epoch 00076: val_loss improved from 3.20345 to 3.18572, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.614539563195212\n",
      "Improve F1 score from 0.602161221673728 to 0.614539563195212\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.0170 - val_loss: 3.2502\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.18572\n",
      "F1 score: 0.6043790901023995\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 1.9518 - val_loss: 3.1996\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.18572\n",
      "F1 score: 0.6227541051219481\n",
      "Improve F1 score from 0.614539563195212 to 0.6227541051219481\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0330 - val_loss: 3.1896\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.18572\n",
      "F1 score: 0.6090879804960279\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.0071 - val_loss: 3.1760\n",
      "\n",
      "Epoch 00080: val_loss improved from 3.18572 to 3.17599, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.607672869104853\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1985 - val_loss: 3.1868\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.17599\n",
      "F1 score: 0.6079653986770861\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1358 - val_loss: 3.1741\n",
      "\n",
      "Epoch 00082: val_loss improved from 3.17599 to 3.17408, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6079528132411955\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 60s 4s/step - loss: 2.1352 - val_loss: 3.1725\n",
      "\n",
      "Epoch 00083: val_loss improved from 3.17408 to 3.17248, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6051792883801024\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.0190 - val_loss: 3.2204\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.17248\n",
      "F1 score: 0.6068278221722766\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0821 - val_loss: 3.1203\n",
      "\n",
      "Epoch 00085: val_loss improved from 3.17248 to 3.12027, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6075184463301042\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 65s 4s/step - loss: 2.0136 - val_loss: 3.1135\n",
      "\n",
      "Epoch 00086: val_loss improved from 3.12027 to 3.11353, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6142978482354131\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.0552 - val_loss: 3.0956\n",
      "\n",
      "Epoch 00087: val_loss improved from 3.11353 to 3.09555, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6299593707728879\n",
      "Improve F1 score from 0.6227541051219481 to 0.6299593707728879\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 2.0424 - val_loss: 3.2499\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.09555\n",
      "F1 score: 0.6229043862772903\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 68s 5s/step - loss: 2.2171 - val_loss: 3.0698\n",
      "\n",
      "Epoch 00089: val_loss improved from 3.09555 to 3.06978, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6218134129292351\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 64s 4s/step - loss: 2.1026 - val_loss: 3.1128\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6098361377204607\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 59s 4s/step - loss: 2.0134 - val_loss: 3.2812\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6224183349595492\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.2084 - val_loss: 3.0807\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6164188524474731\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1039 - val_loss: 3.1137\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6180548913563738\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1164 - val_loss: 3.0927\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6211900418568416\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 1.9094 - val_loss: 3.1270\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6380747606799468\n",
      "Improve F1 score from 0.6299593707728879 to 0.6380747606799468\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 66s 4s/step - loss: 2.1457 - val_loss: 3.0772\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6370685155336733\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.0664 - val_loss: 3.1091\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.06978\n",
      "F1 score: 0.6308389739383371\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 62s 4s/step - loss: 2.1521 - val_loss: 3.0487\n",
      "\n",
      "Epoch 00098: val_loss improved from 3.06978 to 3.04875, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.6326584768594039\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 63s 4s/step - loss: 1.9550 - val_loss: 3.0376\n",
      "\n",
      "Epoch 00099: val_loss improved from 3.04875 to 3.03765, saving model to /home/aldo/Documents/weights/models/new_net/new_share_conv_conf_cic_a_1.0_e_1_ps_0.6_ng_0.5.h5\n",
      "F1 score: 0.629512751234167\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 67s 4s/step - loss: 2.1817 - val_loss: 3.1202\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.03765\n",
      "F1 score: 0.6346614367264777\n"
     ]
    }
   ],
   "source": [
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch   = 0\n",
    "final_epoch     = 100\n",
    "steps_per_epoch = 15\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=final_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                              initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
