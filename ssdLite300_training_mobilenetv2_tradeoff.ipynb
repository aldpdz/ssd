{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from extra_files import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSDLite300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssdlite320_mobilenetv2 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "new_scales = [0.15, 0.33, 0.47, 0.61, 0.76, 0.90, 1.05]\n",
    "scales = new_scales\n",
    "aspect_ratios = [[1.0, 0.5, 2.0/3.0],\n",
    "                 [1.0, 0.5, 2.0/3.0, 1.0/3.0, 3.0/4.0],\n",
    "                 [1.0, 2.0, 0.5, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 2.0/3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True\n",
    "list_alpha = [1.0, 0.35]\n",
    "list_expansion = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:30<00:00, 213.91it/s]\n",
      "Loading images into memory: 100%|██████████| 2097/2097 [00:08<00:00, 235.50it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  2097\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset_pascal = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset_pascal = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "images_dir = data_path + 'pascal_dataset'\n",
    "\n",
    "# Ground truth\n",
    "train_labels_filename = preprocess_path + '/pascal_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/pascal_val.csv'\n",
    "\n",
    "train_dataset_pascal.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset_pascal.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size_pascal = train_dataset_pascal.get_dataset_size()\n",
    "val_dataset_size_pascal   = val_dataset_pascal.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size_pascal))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size_pascal))\n",
    "\n",
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [(18, 18),\n",
    "                   (9, 9),\n",
    "                   (5, 5),\n",
    "                   (3, 3),\n",
    "                   (2, 2),\n",
    "                   (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.6,\n",
    "                                    neg_iou_limit=0.3,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator_pascal = train_dataset_pascal.generate(batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              transformations=[ssd_data_augmentation],\n",
    "                                              label_encoder=ssd_input_encoder,\n",
    "                                              returns={'processed_images',\n",
    "                                                       'encoded_labels'},\n",
    "                                              keep_images_without_gt=False)\n",
    "\n",
    "val_generator_pascal = val_dataset_pascal.generate(batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          transformations=[convert_to_3_channels,\n",
    "                                                           resize],\n",
    "                                          label_encoder=ssd_input_encoder,\n",
    "                                          returns={'processed_images',\n",
    "                                                   'encoded_labels'},\n",
    "                                          keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size_pascal = train_dataset_pascal.get_dataset_size()\n",
    "val_dataset_size_pascal   = val_dataset_pascal.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size_pascal))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size_pascal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 210/210 [00:07<00:00, 27.76it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:01<00:00, 27.58it/s]\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n",
      "Number of images in the training dataset:\t   210\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset_cic = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset_cic = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "images_dir = data_path + 'images'\n",
    "\n",
    "# Ground truth\n",
    "train_labels_filename = preprocess_path + '/cic_train.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val.csv'\n",
    "\n",
    "train_dataset_cic.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset_cic.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size_cic = train_dataset_cic.get_dataset_size()\n",
    "val_dataset_size_cic   = val_dataset_cic.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size_cic))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size_cic))\n",
    "\n",
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [(18, 18),\n",
    "                   (9, 9),\n",
    "                   (5, 5),\n",
    "                   (3, 3),\n",
    "                   (2, 2),\n",
    "                   (1, 1)]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.6,\n",
    "                                    neg_iou_limit=0.3,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator_cic = train_dataset_cic.generate(batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            transformations=[ssd_data_augmentation],\n",
    "                                            label_encoder=ssd_input_encoder,\n",
    "                                            returns={'processed_images',\n",
    "                                                     'encoded_labels'},\n",
    "                                            keep_images_without_gt=False)\n",
    "\n",
    "val_generator_cic = val_dataset_cic.generate(batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        transformations=[convert_to_3_channels,\n",
    "                                                         resize],\n",
    "                                        label_encoder=ssd_input_encoder,\n",
    "                                        returns={'processed_images',\n",
    "                                                 'encoded_labels'},\n",
    "                                        keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size_cic = train_dataset_cic.get_dataset_size()\n",
    "val_dataset_size_cic   = val_dataset_cic.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size_cic))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size_cic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_val = np.load('../data-cic/preprocess_data/label_val.npy')\n",
    "val_images_300 = np.load('../data-cic/preprocess_data/images_val_300x300.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_callbacks(path_weights, name_weights, path_logger, path_tensorboard, path_f1, save_f1):\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "    model_checkpoint = ModelCheckpoint(filepath=path_weights + name_weights,\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=1,\n",
    "                                       save_best_only=True,\n",
    "                                       save_weights_only=False,\n",
    "                                       mode='auto',\n",
    "                                       period=1)\n",
    "\n",
    "    csv_logger = CSVLogger(filename= path_logger,\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "    reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                             factor=0.5,\n",
    "                                             patience=10,\n",
    "                                             verbose=1,\n",
    "                                             min_delta=0.001,\n",
    "                                             cooldown=0,\n",
    "                                             min_lr=0.000001)\n",
    "    \n",
    "    tbCallBack = TensorBoard(log_dir=path_tensorboard, \n",
    "                                       histogram_freq=0, \n",
    "                                       write_graph=False, \n",
    "                                       write_images=False,\n",
    "                                       update_freq='epoch')\n",
    "\n",
    "\n",
    "    f1_callback = f1_call(0.20, \n",
    "                          0.45, \n",
    "                          200, \n",
    "                          normalize_coords, \n",
    "                          img_height, \n",
    "                          img_width, \n",
    "                          val_images_300, \n",
    "                          label_val, (1, 2006, 14),\n",
    "                          path_f1,\n",
    "                          save_f1)\n",
    "\n",
    "    callbacks = [model_checkpoint,\n",
    "                 csv_logger,\n",
    "                 reduce_learning_rate,\n",
    "                 f1_callback,\n",
    "                 tbCallBack]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to train different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---->Training model with alpha 1.0 and expansion 1 with pascal\n",
      "Number of parameters: 2618612\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 236s 590ms/step - loss: 8.1856 - val_loss: 6.7928\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.79276, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.2213778944620361\n",
      "Improve F1 score from -inf to 0.2213778944620361\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 4.1244 - val_loss: 4.0912\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.79276 to 4.09125, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.25732879272339787\n",
      "Improve F1 score from 0.2213778944620361 to 0.25732879272339787\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 226s 565ms/step - loss: 3.7622 - val_loss: 3.7950\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.09125 to 3.79505, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.32982168028958325\n",
      "Improve F1 score from 0.25732879272339787 to 0.32982168028958325\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 3.5635 - val_loss: 3.9629\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.79505\n",
      "F1 score: 0.38989913270436555\n",
      "Improve F1 score from 0.32982168028958325 to 0.38989913270436555\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 219s 547ms/step - loss: 3.4922 - val_loss: 3.6990\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.79505 to 3.69902, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.40342906223779607\n",
      "Improve F1 score from 0.38989913270436555 to 0.40342906223779607\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 223s 558ms/step - loss: 3.3831 - val_loss: 3.6106\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.69902 to 3.61059, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.34900526360960415\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 231s 578ms/step - loss: 3.2633 - val_loss: 3.6017\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.61059 to 3.60167, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.40414421411543733\n",
      "Improve F1 score from 0.40342906223779607 to 0.40414421411543733\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 228s 571ms/step - loss: 3.2268 - val_loss: 3.6475\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.60167\n",
      "F1 score: 0.41263869781960183\n",
      "Improve F1 score from 0.40414421411543733 to 0.41263869781960183\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 230s 576ms/step - loss: 3.2024 - val_loss: 3.9104\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.60167\n",
      "F1 score: 0.4205126844243963\n",
      "Improve F1 score from 0.41263869781960183 to 0.4205126844243963\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 230s 575ms/step - loss: 3.1179 - val_loss: 3.5449\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.60167 to 3.54493, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.4096390921392087\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 231s 577ms/step - loss: 3.1094 - val_loss: 3.0006\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.54493 to 3.00060, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.43789341753112865\n",
      "Improve F1 score from 0.4205126844243963 to 0.43789341753112865\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 227s 568ms/step - loss: 3.1016 - val_loss: 2.9265\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.00060 to 2.92651, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.4209313745771491\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 227s 567ms/step - loss: 3.0384 - val_loss: 2.9673\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.92651\n",
      "F1 score: 0.4423030209566441\n",
      "Improve F1 score from 0.43789341753112865 to 0.4423030209566441\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 226s 564ms/step - loss: 3.0119 - val_loss: 3.2147\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.92651\n",
      "F1 score: 0.41113029268835616\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 223s 558ms/step - loss: 2.9620 - val_loss: 2.9701\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.92651\n",
      "F1 score: 0.43329738959538155\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 229s 572ms/step - loss: 2.9624 - val_loss: 2.9624\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.92651\n",
      "F1 score: 0.3837486684933764\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 225s 562ms/step - loss: 2.9565 - val_loss: 3.1525\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.92651\n",
      "F1 score: 0.31704549431394624\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 2.9129 - val_loss: 2.8763\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.92651 to 2.87633, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.4525599316738746\n",
      "Improve F1 score from 0.4423030209566441 to 0.4525599316738746\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 224s 561ms/step - loss: 2.8706 - val_loss: 2.7918\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.87633 to 2.79182, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_1.0_exp_1.h5\n",
      "F1 score: 0.4513945409812202\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 2.8583 - val_loss: 2.8660\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.79182\n",
      "F1 score: 0.4742138661863165\n",
      "Improve F1 score from 0.4525599316738746 to 0.4742138661863165\n",
      "\n",
      "---->Training model with alpha 1.0 and expansion 1 with cic\n",
      "Epoch 1/20\n",
      "15/15 [==============================] - 65s 4s/step - loss: 3.6029 - val_loss: 3.5332\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.53315, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_cic_1.0_exp_1.h5\n",
      "F1 score: 0.4740805721092179\n",
      "Improve F1 score from -inf to 0.4740805721092179\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 61s 4s/step - loss: 3.1808 - val_loss: 3.2369\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.53315 to 3.23688, saving model to /home/aldo/Documents/weights/models/last_models/2pos_4_alpha_1.5_pascal_cic_1.0_exp_1.h5\n",
      "F1 score: 0.5078670661774083\n",
      "Improve F1 score from 0.4740805721092179 to 0.5078670661774083\n",
      "Epoch 3/20\n",
      "12/15 [=======================>......] - ETA: 11s - loss: 3.0758"
     ]
    }
   ],
   "source": [
    "for alpha in list_alpha:\n",
    "    for expansion in list_expansion:\n",
    "        # 1: Build the Keras model.\n",
    "\n",
    "        K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "        model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                        n_classes=n_classes,\n",
    "                        alpha=alpha,\n",
    "                        expansion=expansion,\n",
    "                        mode='training',\n",
    "                        scales=scales,\n",
    "                        aspect_ratios_per_layer=aspect_ratios,\n",
    "                        two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                        steps=steps,\n",
    "                        offsets=offsets,\n",
    "                        clip_boxes=clip_boxes,\n",
    "                        variances=variances,\n",
    "                        normalize_coords=normalize_coords,\n",
    "                        subtract_mean=mean_color,\n",
    "                        divide_by_stddev=divide_by_stddev,\n",
    "                        swap_channels=swap_channels)\n",
    "\n",
    "        print('\\n---->Training model with alpha', alpha, 'and expansion', expansion, 'with pascal')\n",
    "        print('Number of parameters:', model.count_params())\n",
    "        \n",
    "        # Train over pascal\n",
    "        adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "        model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "        \n",
    "        # set callbacks\n",
    "        str_alpha = str(alpha)\n",
    "        str_exp = str(expansion)\n",
    "        callbacks_pascal =  return_callbacks('/home/aldo/Documents/weights/models/last_models/', \n",
    "                              '2pos_4_alpha_1.5_pascal_' + str_alpha + '_exp_' + str_exp + '.h5',\n",
    "                              data_path + 'history/last_models/2pos_4_alpha_1.5_pascal_alpha_' + str_alpha + '_exp_' + str_exp + '.csv',\n",
    "                              data_path + 'history/last_models/tensorboard/pascal/2pos_4_alpha_1.5' + str_alpha + '_exp_' + str_exp +'/pascal_' + str_alpha + '_exp_' + str_exp,\n",
    "                              data_path + 'history/last_models/2pos_4_alpha_1.5_pascal_f1_' + str_alpha + '_exp_' + str_exp + '.csv',\n",
    "                              '/home/aldo/Documents/weights/models/last_models/' + '2pos_4_alpha_1.5_pascal_f1_' + str_alpha + '_exp_' + str_exp + '.h5' )\n",
    "        # If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "        initial_epoch   = 0\n",
    "        final_epoch     = 20\n",
    "        steps_per_epoch = 400\n",
    "\n",
    "        history = model.fit_generator(generator=train_generator_pascal,\n",
    "                                      steps_per_epoch=steps_per_epoch,\n",
    "                                      epochs=final_epoch,\n",
    "                                      callbacks=callbacks_pascal,\n",
    "                                      validation_data=val_generator_pascal,\n",
    "                                      validation_steps=ceil(val_dataset_size_pascal/batch_size),\n",
    "                                      initial_epoch=initial_epoch)\n",
    "            \n",
    "        print('\\n---->Training model with alpha', alpha, 'and expansion', expansion, 'with cic')\n",
    "        # Train over cic\n",
    "        # Reset learning rate to 0.0005\n",
    "        adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "        model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "        \n",
    "        callbacks_cic =  return_callbacks('/home/aldo/Documents/weights/models/last_models/', \n",
    "                              '2pos_4_alpha_1.5_pascal_cic_' + str_alpha + '_exp_' + str_exp + '.h5',\n",
    "                              data_path + 'history/last_models/2pos_4_alpha_1.5_pascal_cic_alpha_' + str_alpha + '_exp_' + str_exp + '.csv',\n",
    "                              data_path + 'history/last_models/tensorboard/cic/2pos_4_alpha_1.5' + str_alpha + '_exp_' + str_exp +'/cic' + str_alpha + '_exp_' + str_exp,                              \n",
    "                              data_path + 'history/last_models/2pos_4_alpha_1.5_pascal_cic_f1_' + str_alpha + '_exp_' + str_exp + '.csv',\n",
    "                              '/home/aldo/Documents/weights/models/last_models/' + '2pos_4_alpha_1.5_pascal_cic_f1_' + str_alpha + '_exp_' + str_exp + '.h5')\n",
    "        \n",
    "        initial_epoch   = 0\n",
    "        final_epoch     = 20\n",
    "        steps_per_epoch = 15\n",
    "\n",
    "        history = model.fit_generator(generator=train_generator_cic,\n",
    "                                      steps_per_epoch=steps_per_epoch,\n",
    "                                      epochs=final_epoch,\n",
    "                                      callbacks=callbacks_cic,\n",
    "                                      validation_data=val_generator_cic,\n",
    "                                      validation_steps=ceil(val_dataset_size_cic/batch_size),\n",
    "                                      initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
